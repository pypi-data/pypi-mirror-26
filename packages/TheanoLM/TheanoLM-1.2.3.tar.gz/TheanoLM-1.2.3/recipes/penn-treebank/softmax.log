/l/senarvi/theanolm-recipes/penn-treebank/nnlm.vocab
THEANO_FLAGS=floatX=float32,device=cuda0,optimizer_excluding=local_gpua_multinomial_wor
Reading vocabulary from /l/senarvi/theanolm-recipes/penn-treebank/nnlm.vocab.
Computing unigram probabilities for out-of-shortlist words.
Number of words in vocabulary: 10001
Number of words in shortlist: 10001
Number of word classes: 10001
2017-10-18 01:11:13,327 train: TRAINING OPTIONS
2017-10-18 01:11:13,328 train: stopping_criterion: no-improvement
2017-10-18 01:11:13,328 train: batch_size: 32
2017-10-18 01:11:13,328 train: max_epochs: 15
2017-10-18 01:11:13,328 train: min_epochs: 1
2017-10-18 01:11:13,328 train: patience: 0
2017-10-18 01:11:13,328 train: sequence_length: 25
2017-10-18 01:11:13,328 train: validation_frequency: 1
2017-10-18 01:11:13,328 train: max_annealing_count: 0
2017-10-18 01:11:13,328 train: OPTIMIZATION OPTIONS
2017-10-18 01:11:13,328 train: learning_rate: 1.0
2017-10-18 01:11:13,328 train: max_gradient_norm: 5.0
2017-10-18 01:11:13,328 train: momentum: 0.9
2017-10-18 01:11:13,328 train: sqr_gradient_decay_rate: 0.999
2017-10-18 01:11:13,328 train: num_noise_samples: 1
2017-10-18 01:11:13,328 train: method: adagrad
2017-10-18 01:11:13,329 train: weights: [ 1.]
2017-10-18 01:11:13,329 train: epsilon: 1e-06
2017-10-18 01:11:13,329 train: noise_sharing: None
2017-10-18 01:11:13,329 train: gradient_decay_rate: 0.9
Creating trainer.
Computing the number of mini-batches in training data.
2017-10-18 01:11:14,867 __init__: One epoch of training data contains 1778 mini-batch updates.
2017-10-18 01:11:14,868 __init__: Class unigram log probabilities are in the range [-13.786758, -2.951697].
2017-10-18 01:11:14,869 __init__: Finding sentence start positions in /teamwork/t40511_asr/c/penn-treebank-project/ptb.train.txt.
2017-10-18 01:11:14,893 _reset: Generating a random order of input lines.
Building neural network.
2017-10-18 01:11:14,921 __init__: Creating layers.
2017-10-18 01:11:14,921 __init__: - NetworkInput name=word_input inputs=[] size=10001 activation=tanh devices=[]
2017-10-18 01:11:14,921 __init__: - ProjectionLayer name=projection_layer inputs=[word_input] size=100 activation=tanh devices=[None]
2017-10-18 01:11:15,001 add:      * layers/projection_layer/W size=1000100 type=float32 device=None
2017-10-18 01:11:15,001 __init__: - LSTMLayer name=hidden_layer inputs=[projection_layer] size=256 activation=tanh devices=[None]
2017-10-18 01:11:15,010 add:      * layers/hidden_layer/layer_input/W size=102400 type=float32 device=None
2017-10-18 01:11:15,522 add:      * layers/hidden_layer/step_input/W size=262144 type=float32 device=None
2017-10-18 01:11:15,523 add:      * layers/hidden_layer/layer_input/b size=1024 type=float32 device=None
2017-10-18 01:11:15,523 __init__: - SoftmaxLayer name=output_layer inputs=[hidden_layer] size=10001 activation=tanh devices=[None]
2017-10-18 01:11:15,770 add:      * layers/output_layer/input/W size=2560256 type=float32 device=None
2017-10-18 01:11:15,770 add:      * layers/output_layer/input/b size=10001 type=float32 device=None
2017-10-18 01:11:15,770 __init__: Total number of parameters: 3935925
Building optimizer.
2017-10-18 01:11:18,329 add:      * layers/hidden_layer/layer_input/W_sum_sqr_gradient size=102400 type=float32 device=None
2017-10-18 01:11:18,329 add:      * layers/output_layer/input/b_sum_sqr_gradient size=10001 type=float32 device=None
2017-10-18 01:11:18,330 add:      * layers/hidden_layer/layer_input/b_sum_sqr_gradient size=1024 type=float32 device=None
2017-10-18 01:11:18,332 add:      * layers/projection_layer/W_sum_sqr_gradient size=1000100 type=float32 device=None
2017-10-18 01:11:18,337 add:      * layers/output_layer/input/W_sum_sqr_gradient size=2560256 type=float32 device=None
2017-10-18 01:11:18,338 add:      * layers/hidden_layer/step_input/W_sum_sqr_gradient size=262144 type=float32 device=None
Building text scorer for cross-validation.
Validation text: /teamwork/t40511_asr/c/penn-treebank-project/ptb.valid.txt
Training neural network.
2017-10-18 01:12:11,217 _log_update: [200] (11.2 %) of epoch 1 -- lr = 1, duration = 12.3 ms
2017-10-18 01:12:36,000 _log_update: [400] (22.5 %) of epoch 1 -- lr = 1, duration = 12.3 ms
2017-10-18 01:13:00,785 _log_update: [600] (33.7 %) of epoch 1 -- lr = 1, duration = 12.3 ms
2017-10-18 01:13:25,571 _log_update: [800] (45.0 %) of epoch 1 -- lr = 1, duration = 12.3 ms
2017-10-18 01:13:50,354 _log_update: [1000] (56.2 %) of epoch 1 -- lr = 1, duration = 12.3 ms
2017-10-18 01:14:15,136 _log_update: [1200] (67.5 %) of epoch 1 -- lr = 1, duration = 12.2 ms
2017-10-18 01:14:39,933 _log_update: [1400] (78.7 %) of epoch 1 -- lr = 1, duration = 12.3 ms
2017-10-18 01:15:04,718 _log_update: [1600] (90.0 %) of epoch 1 -- lr = 1, duration = 12.3 ms
2017-10-18 01:15:29,724 _validate: [1772] First validation sample, perplexity 169.91.
2017-10-18 01:15:41,033 _validate: [1775] Center of validation, perplexity 170.33.
2017-10-18 01:15:52,457 _validate: [1778] Last validation sample, perplexity 169.62.
2017-10-18 01:15:52,482 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-10-18 01:15:52,482 _log_validation: [1778] Validation set cost history: [169.9]
2017-10-18 01:15:52,483 _reset: Generating a random order of input lines.
Finished training epoch 1 in 0 hours 4.1 minutes. Best validation perplexity 169.91.
2017-10-18 01:15:55,181 _log_update: [22] (1.2 %) of epoch 2 -- lr = 1, duration = 12.2 ms
2017-10-18 01:16:19,956 _log_update: [222] (12.5 %) of epoch 2 -- lr = 1, duration = 12.2 ms
2017-10-18 01:16:44,725 _log_update: [422] (23.7 %) of epoch 2 -- lr = 1, duration = 12.3 ms
2017-10-18 01:17:09,501 _log_update: [622] (35.0 %) of epoch 2 -- lr = 1, duration = 12.4 ms
2017-10-18 01:17:34,273 _log_update: [822] (46.2 %) of epoch 2 -- lr = 1, duration = 12.2 ms
2017-10-18 01:17:59,042 _log_update: [1022] (57.5 %) of epoch 2 -- lr = 1, duration = 12.3 ms
2017-10-18 01:18:23,813 _log_update: [1222] (68.7 %) of epoch 2 -- lr = 1, duration = 12.3 ms
2017-10-18 01:18:48,581 _log_update: [1422] (80.0 %) of epoch 2 -- lr = 1, duration = 12.3 ms
2017-10-18 01:19:13,356 _log_update: [1622] (91.2 %) of epoch 2 -- lr = 1, duration = 12.3 ms
2017-10-18 01:19:35,622 _validate: [1772] First validation sample, perplexity 145.11.
2017-10-18 01:19:46,932 _validate: [1775] Center of validation, perplexity 145.31.
2017-10-18 01:19:58,252 _validate: [1778] Last validation sample, perplexity 145.08.
2017-10-18 01:19:58,269 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-10-18 01:19:58,269 _log_validation: [1778] Validation set cost history: 169.9 [145.2]
2017-10-18 01:19:58,270 _reset: Generating a random order of input lines.
Finished training epoch 2 in 0 hours 4.1 minutes. Best validation perplexity 145.21.
2017-10-18 01:20:03,521 _log_update: [44] (2.5 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:20:27,425 _log_update: [244] (13.7 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:20:51,320 _log_update: [444] (25.0 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:21:15,241 _log_update: [644] (36.2 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:21:39,152 _log_update: [844] (47.5 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:22:03,057 _log_update: [1044] (58.7 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:22:26,957 _log_update: [1244] (70.0 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:22:50,861 _log_update: [1444] (81.2 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:23:14,776 _log_update: [1644] (92.5 %) of epoch 3 -- lr = 1, duration = 11.8 ms
2017-10-18 01:23:33,767 _validate: [1772] First validation sample, perplexity 141.34.
2017-10-18 01:23:45,067 _validate: [1775] Center of validation, perplexity 141.48.
2017-10-18 01:23:56,380 _validate: [1778] Last validation sample, perplexity 141.23.
2017-10-18 01:23:56,397 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-10-18 01:23:56,397 _log_validation: [1778] Validation set cost history: 169.9 145.2 [141.4]
2017-10-18 01:23:56,398 _reset: Generating a random order of input lines.
Finished training epoch 3 in 0 hours 4.0 minutes. Best validation perplexity 141.37.
2017-10-18 01:24:04,261 _log_update: [66] (3.7 %) of epoch 4 -- lr = 1, duration = 11.8 ms
2017-10-18 01:24:28,165 _log_update: [266] (15.0 %) of epoch 4 -- lr = 1, duration = 11.9 ms
2017-10-18 01:24:52,076 _log_update: [466] (26.2 %) of epoch 4 -- lr = 1, duration = 11.8 ms
2017-10-18 01:25:15,979 _log_update: [666] (37.5 %) of epoch 4 -- lr = 1, duration = 11.8 ms
2017-10-18 01:25:39,880 _log_update: [866] (48.7 %) of epoch 4 -- lr = 1, duration = 11.9 ms
2017-10-18 01:26:03,812 _log_update: [1066] (60.0 %) of epoch 4 -- lr = 1, duration = 11.8 ms
2017-10-18 01:26:27,709 _log_update: [1266] (71.2 %) of epoch 4 -- lr = 1, duration = 11.8 ms
2017-10-18 01:26:51,602 _log_update: [1466] (82.5 %) of epoch 4 -- lr = 1, duration = 11.8 ms
2017-10-18 01:27:15,501 _log_update: [1666] (93.7 %) of epoch 4 -- lr = 1, duration = 11.8 ms
2017-10-18 01:27:31,854 _validate: [1772] First validation sample, perplexity 146.23.
2017-10-18 01:27:43,162 _validate: [1775] Center of validation, perplexity 146.23.
2017-10-18 01:27:54,473 _validate: [1778] Last validation sample, perplexity 146.48.
2017-10-18 01:27:54,473 _log_validation: [1778] Validation set cost history: 169.9 145.2 [141.4] 146.2
2017-10-18 01:27:54,475 set_state: layers/projection_layer/W <- array(10001, 100)
2017-10-18 01:27:54,475 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-10-18 01:27:54,476 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-10-18 01:27:54,476 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-10-18 01:27:54,477 set_state: layers/output_layer/input/b <- array(10001,)
2017-10-18 01:27:54,480 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-10-18 01:27:54,481 _reset_state: [1775] (99.83 %) of epoch 3
2017-10-18 01:27:54,482 _log_validation: [1775] Validation set cost history: 169.9 145.2 [141.4]
2017-10-18 01:27:54,482 set_state: Restored iterator to line 42000 of 42068.
2017-10-18 01:27:54,485 set_state: layers/output_layer/input/W_sum_sqr_gradient <- array(256, 10001)
2017-10-18 01:27:54,486 set_state: layers/hidden_layer/step_input/W_sum_sqr_gradient <- array(256, 1024)
2017-10-18 01:27:54,487 set_state: layers/hidden_layer/layer_input/b_sum_sqr_gradient <- array(1024,)
2017-10-18 01:27:54,487 set_state: layers/hidden_layer/layer_input/W_sum_sqr_gradient <- array(100, 1024)
2017-10-18 01:27:54,487 set_state: layers/output_layer/input/b_sum_sqr_gradient <- array(10001,)
2017-10-18 01:27:54,489 set_state: layers/projection_layer/W_sum_sqr_gradient <- array(10001, 100)
Model performance stopped improving. Decreasing learning rate from 1.0 to 0.5 and resetting state to 100 % of epoch 3.
2017-10-18 01:27:54,490 _reset: Generating a random order of input lines.
Finished training epoch 3 in 0 hours 4.0 minutes. Best validation perplexity 141.37.
2017-10-18 01:28:04,987 _log_update: [88] (4.9 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:28:28,901 _log_update: [288] (16.2 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:28:52,810 _log_update: [488] (27.4 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:29:16,724 _log_update: [688] (38.7 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:29:40,635 _log_update: [888] (49.9 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:30:04,546 _log_update: [1088] (61.2 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:30:28,458 _log_update: [1288] (72.4 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:30:52,366 _log_update: [1488] (83.7 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:31:16,285 _log_update: [1688] (94.9 %) of epoch 4 -- lr = 0.5, duration = 11.8 ms
2017-10-18 01:31:30,012 _validate: [1772] First validation sample, perplexity 143.14.
2017-10-18 01:31:41,312 _validate: [1775] Center of validation, perplexity 143.01.
2017-10-18 01:31:52,625 _validate: [1778] Last validation sample, perplexity 143.02.
2017-10-18 01:31:52,625 _log_validation: [1778] Validation set cost history: 169.9 145.2 [141.4] 143.0
2017-10-18 01:31:52,627 set_state: layers/projection_layer/W <- array(10001, 100)
2017-10-18 01:31:52,628 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-10-18 01:31:52,628 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-10-18 01:31:52,629 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-10-18 01:31:52,629 set_state: layers/output_layer/input/b <- array(10001,)
2017-10-18 01:31:52,632 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-10-18 01:31:52,634 _reset_state: [1775] (99.83 %) of epoch 3
2017-10-18 01:31:52,634 _log_validation: [1775] Validation set cost history: 169.9 145.2 [141.4]
2017-10-18 01:31:52,635 set_state: Restored iterator to line 42000 of 42068.
2017-10-18 01:31:52,638 set_state: layers/output_layer/input/W_sum_sqr_gradient <- array(256, 10001)
2017-10-18 01:31:52,639 set_state: layers/hidden_layer/step_input/W_sum_sqr_gradient <- array(256, 1024)
2017-10-18 01:31:52,639 set_state: layers/hidden_layer/layer_input/b_sum_sqr_gradient <- array(1024,)
2017-10-18 01:31:52,640 set_state: layers/hidden_layer/layer_input/W_sum_sqr_gradient <- array(100, 1024)
2017-10-18 01:31:52,640 set_state: layers/output_layer/input/b_sum_sqr_gradient <- array(10001,)
2017-10-18 01:31:52,641 set_state: layers/projection_layer/W_sum_sqr_gradient <- array(10001, 100)
Model performance stopped improving. Decreasing learning rate from 0.5 to 0.25 and resetting state to 100 % of epoch 3.
Finished training epoch 3 in 0 hours 4.0 minutes. Best validation perplexity 141.37.
Training finished in 0 hours 20.1 minutes.
2017-10-18 01:31:52,644 set_state: layers/projection_layer/W <- array(10001, 100)
2017-10-18 01:31:52,644 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-10-18 01:31:52,645 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-10-18 01:31:52,646 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-10-18 01:31:52,646 set_state: layers/output_layer/input/b <- array(10001,)
2017-10-18 01:31:52,649 set_state: layers/output_layer/input/W <- array(256, 10001)
Best validation set perplexity: 141.476881898
train finished.
Computing evaluation set perplexity.
Reading vocabulary from network state.
Number of words in vocabulary: 10001
Number of words in shortlist: 10001
Number of word classes: 10001
Building neural network.
Restoring neural network state.
Building text scorer.
Scoring text.
Number of sentences: 3761
Number of words: 86191
Number of tokens: 86191
Number of predicted probabilities: 82430
Number of excluded (OOV) words: 0
Number of zero probabilities: 0
Cross entropy (base e): 4.780168400024186
Perplexity: 119.12440890915127
