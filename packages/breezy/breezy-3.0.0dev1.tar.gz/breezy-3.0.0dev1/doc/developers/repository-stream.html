<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.14: http://docutils.sourceforge.net/" />
<title>Repository Streams</title>
<link rel="stylesheet" href="../default.css" type="text/css" />
</head>
<body>
<div class="document" id="repository-streams">
<h1 class="title">Repository Streams</h1>

<div class="section" id="status">
<h1><a class="toc-backref" href="#id2">Status</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Date:</th><td class="field-body">2008-04-11</td>
</tr>
</tbody>
</table>
<p>This document describes the proposed programming interface for streaming
data from and into repositories. This programming interface should allow
a single interface for pulling data from and inserting data into a Bazaar
repository.</p>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#status" id="id2">Status</a></li>
<li><a class="reference internal" href="#motivation" id="id3">Motivation</a></li>
<li><a class="reference internal" href="#use-cases" id="id4">Use Cases</a><ul>
<li><a class="reference internal" href="#fetch-operations" id="id5">Fetch operations</a><ul>
<li><a class="reference internal" href="#smart-server-operations" id="id6">Smart server operations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#bundles" id="id7">Bundles</a></li>
<li><a class="reference internal" href="#data-conversion" id="id8">Data conversion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#characteristics" id="id9">Characteristics</a><ul>
<li><a class="reference internal" href="#single-round-trip" id="id10">Single round trip</a></li>
<li><a class="reference internal" href="#forward-only-reads" id="id11">Forward-only reads</a></li>
</ul>
</li>
<li><a class="reference internal" href="#serialisation" id="id12">Serialisation</a><ul>
<li><a class="reference internal" href="#weaves" id="id13">Weaves</a></li>
<li><a class="reference internal" href="#id1" id="id14">Bundles</a></li>
</ul>
</li>
<li><a class="reference internal" href="#specification" id="id15">Specification</a><ul>
<li><a class="reference internal" href="#requesting-a-stream" id="id16">Requesting a stream</a></li>
<li><a class="reference internal" href="#structure-of-a-stream" id="id17">Structure of a stream</a></li>
<li><a class="reference internal" href="#consuming-a-stream" id="id18">Consuming a stream</a><ul>
<li><a class="reference internal" href="#factory-metadata" id="id19">factory metadata</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="motivation">
<h1><a class="toc-backref" href="#id3">Motivation</a></h1>
<p>To eliminate the current requirement that extracting data from a
repository requires either using a slow format, or knowing the format of
both the source repository and the target repository.</p>
</div>
<div class="section" id="use-cases">
<h1><a class="toc-backref" href="#id4">Use Cases</a></h1>
<p>Here's a brief description of use cases this interface is intended to
support.</p>
<div class="section" id="fetch-operations">
<h2><a class="toc-backref" href="#id5">Fetch operations</a></h2>
<p>We fetch data between repositories as part of push/pull/branch operations.
Fetching data is currently an very interactive process with lots of
requests. For performance having the data be supplied in a stream will
improve push and pull to remote servers. For purely local operations the
streaming logic should help reduce memory pressure. In fetch operations
we always know the formats of both the source and target.</p>
<div class="section" id="smart-server-operations">
<h3><a class="toc-backref" href="#id6">Smart server operations</a></h3>
<p>With the smart server we support one streaming format, but this is only
usable when both the client and server have the same model of data, and
requires non-optimal IO ordering for pack to pack operations. Ideally we
can both provide optimal IO ordering the pack to pack case, and correct
ordering for pack to knits.</p>
</div>
</div>
<div class="section" id="bundles">
<h2><a class="toc-backref" href="#id7">Bundles</a></h2>
<p>Bundles also create a stream of data for revisions from a repository.
Unlike fetch operations we do not know the format of the target at the
time the stream is created. It would be good to be able to treat bundles
as frozen branches and repositories, so a serialised stream should be
suitable for this.</p>
</div>
<div class="section" id="data-conversion">
<h2><a class="toc-backref" href="#id8">Data conversion</a></h2>
<p>At this point we are not trying to integrate data conversion into this
interface, though it is likely possible.</p>
</div>
</div>
<div class="section" id="characteristics">
<h1><a class="toc-backref" href="#id9">Characteristics</a></h1>
<p>Some key aspects of the described interface are discussed in this section.</p>
<div class="section" id="single-round-trip">
<h2><a class="toc-backref" href="#id10">Single round trip</a></h2>
<p>All users of this should be able to create an appropriate stream from a
single round trip.</p>
</div>
<div class="section" id="forward-only-reads">
<h2><a class="toc-backref" href="#id11">Forward-only reads</a></h2>
<p>There should be no need to seek in a stream when inserting data from it
into a repository. This places an ordering constraint on streams which
some repositories do not need.</p>
</div>
</div>
<div class="section" id="serialisation">
<h1><a class="toc-backref" href="#id12">Serialisation</a></h1>
<p>At this point serialisation of a repository stream has not been specified.
Some considerations to bear in mind about serialisation are worth noting
however.</p>
<div class="section" id="weaves">
<h2><a class="toc-backref" href="#id13">Weaves</a></h2>
<p>While there shouldn't be too many users of weave repositories anymore,
avoiding pathological behaviour when a weave is being read is a good idea.
Having the weave itself embedded in the stream is very straight forward
and does not need expensive on the fly extraction and re-diffing to take
place.</p>
</div>
<div class="section" id="id1">
<h2><a class="toc-backref" href="#id14">Bundles</a></h2>
<p>Being able to perform random reads from a repository stream which is a
bundle would allow stacking a bundle and a real repository together. This
will need the pack container format to be used in such a way that we can
avoid reading more data than needed within the pack container's readv
interface.</p>
</div>
</div>
<div class="section" id="specification">
<h1><a class="toc-backref" href="#id15">Specification</a></h1>
<p>This describes the interface for requesting a stream, and the programming
interface a stream must provide. Streams that have been serialised should
expose the same interface.</p>
<div class="section" id="requesting-a-stream">
<h2><a class="toc-backref" href="#id16">Requesting a stream</a></h2>
<p>To request a stream, three parameters are needed:</p>
<blockquote>
<ul class="simple">
<li>A revision search to select the revisions to include.</li>
<li>A data ordering flag. There are two values for this - 'unordered' and
'topological'. 'unordered' streams are useful when inserting into
repositories that have the ability to perform atomic insertions.
'topological' streams are useful when converting data, or when
inserting into repositories that cannot perform atomic insertions (such
as knit or weave based repositories).</li>
<li>A complete_inventory flag. When provided this flag signals the stream
generator to include all the data needed to construct the inventory of
each revision included in the stream, rather than just deltas. This is
useful when converting data from a repository with a different
inventory serialisation, as pure deltas would not be able to be
reconstructed.</li>
</ul>
</blockquote>
</div>
<div class="section" id="structure-of-a-stream">
<h2><a class="toc-backref" href="#id17">Structure of a stream</a></h2>
<p>A stream is an object. It can be consistency checked via the <tt class="docutils literal">check</tt>
method (which consumes the stream). The <tt class="docutils literal">iter_contents</tt> method can be
used to iterate the contents of the stream. The contents of the stream are
a series of top level records, each of which contains one or more
bytestrings (potentially as a delta against another item in the
repository) and some optional metadata.</p>
</div>
<div class="section" id="consuming-a-stream">
<h2><a class="toc-backref" href="#id18">Consuming a stream</a></h2>
<p>To consume a stream, obtain an iterator from the streams
<tt class="docutils literal">iter_contents</tt> method. This iterator will yield the top level records.
Each record has two attributes. One is <tt class="docutils literal">key_prefix</tt> which is a tuple key
prefix for the names of each of the bytestrings in the record. The other
attribute is <tt class="docutils literal">entries</tt>, an iterator of the individual items in the
record. Each item that the iterator yields is a factory which has metadata
about the entry and the ability to return the compressed bytes. This
factory can be decorated to allow obtaining different representations (for
example from a compressed knit fulltext to a plain fulltext).</p>
<p>In pseudocode:</p>
<pre class="literal-block">
stream = repository.get_repository_stream(search, UNORDERED, False)
for record in stream.iter_contents():
    for factory in record.entries:
        compression = factory.storage_kind
        print &quot;Object %s, compression type %s, %d bytes long.&quot; % (
            record.key_prefix + factory.key,
            compression, len(factory.get_bytes_as(compression)))
</pre>
<p>This structure should allow stream adapters to be written which can coerce
all records to the type of compression that a particular client needs. For
instance, inserting into weaves requires fulltexts, so a stream would be
adapted for weaves by an adapter that takes a stream, and the target
weave, and then uses the target weave to reconstruct full texts (which is
all that the weave inserter would ask for). In a similar approach, a
stream could internally delta compress many fulltexts and be able to
answer both fulltext and compressed record requests without extra IO.</p>
<div class="section" id="factory-metadata">
<h3><a class="toc-backref" href="#id19">factory metadata</a></h3>
<dl class="docutils">
<dt>Valid attributes on the factory are:</dt>
<dd><ul class="first last simple">
<li>sha1: Optional ascii representation of the sha1 of the bytestring (after
delta reconstruction).</li>
<li>storage_kind: Required kind of storage compression that has been used
on the bytestring. One of <tt class="docutils literal">mpdiff</tt>, <tt class="docutils literal"><span class="pre">knit-annotated-ft</span></tt>,
<tt class="docutils literal"><span class="pre">knit-annotated-delta</span></tt>, <tt class="docutils literal"><span class="pre">knit-ft</span></tt>, <tt class="docutils literal"><span class="pre">knit-delta</span></tt>, <tt class="docutils literal">fulltext</tt>.</li>
<li>parents: Required graph parents to associate with this bytestring.</li>
<li>compressor_data: Required opaque data relevant to the storage_kind.
(This is set to None when the compressor has no special state needed)</li>
<li>key: The key for this bytestring. Like each parent this is a tuple that
should have the key_prefix prepended to it to give the unified
repository key name.</li>
</ul>
</dd>
</dl>
<!-- vim: ft=rst tw=74 ai -->
</div>
</div>
</div>
</div>
</body>
</html>
