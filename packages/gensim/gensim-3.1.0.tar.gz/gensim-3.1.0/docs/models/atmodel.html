<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">




<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <!-- Google Tag Manager - JD-20170831 --> 
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MP366CC');</script>
    <!-- End Google Tag Manager -->

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta property="description" content="Efficient topic modelling of text semantics in Python." />
    <meta property="og:title" content="gensim: topic modelling for humans" />
    <meta property="og:description" content="Efficient topic modelling in Python" />

    
      <title>gensim: models.atmodel – Author-topic models</title>

    
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/jquery.qtip.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/anythingslider.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/>

  </head>

  <body>
    <!-- Google Tag Manager (noscript) - JD-20170831 -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MP366CC"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

    <div id="topwrap">
      
      <div id="top1">
        <div id="left1">
          <h1 class="h1gensim">
            <img src="../_static/images/logo-gensim_compact.png" alt="gensim logo" title="Gensim - topic modelling for humans" />
          </h1>
        </div>

        <div id="middleright">
          <div id="middle1">
            <div id="gensim"><a href="../index.html"><img src="../_static/images/gensim_compact.png" alt="gensim" title="Gensim home" /></a></div>
            <div id="tagline"><img src="../_static/images/tagline_compact.png" alt="gensim tagline" /></div>
          </div>
          <div id="right1">
            <div class="consulting-banner">
              <h3><a href="http://rare-technologies.com/">Get Expert Help</a></h3>
              <p>• machine learning, NLP, data mining</p>
              <p>• custom SW design, development, optimizations</p>
              <p>• corporate trainings &amp; IT consulting</p>
            </div>
          </div>
        </div>
      </div>
     

      
      <div id="menu">
        <div id="indentation1">
          <ul class="menubuttons">
            <li class="menubutton"><a href="../index.html">Home</a></li>
            <li class="menubutton"><a href="../tutorial.html">Tutorials</a></li>
            <li class="menubutton"><a href="../install.html">Install</a></li>
            <li class="menubutton"><a href="../support.html">Support</a></li>
            <li class="menubutton"><a href="../apiref.html">API</a></li>
            <li class="menubutton"><a href="../about.html">About</a></li>
          </ul>
        </div>
      </div>
      

      <div class="clearer"></div>
    </div>

    
  <script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
    URL_ROOT: '../',
    VERSION: '3.1.0',
    COLLAPSE_INDEX: false,
    FILE_SUFFIX: '.html',
    HAS_SOURCE: true
  };
  </script>
    <script type="text/javascript" src="../_static/js/jquery-1.9.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.qtip.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-migrate-1.1.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.anythingslider.min.js"></script>

    
    <div class="document">
      
        <div id="thinbanner">
          <div id="bodythinbanner">
            <span class="h2gensim">models.atmodel – Author-topic models</span>
          </div>
        </div>
        <div class="obsah">
          <div class="obsahwrapper">
            
  <div class="section" id="module-gensim.models.atmodel">
<span id="models-atmodel-author-topic-models"></span><h1><code class="xref py py-mod docutils literal"><span class="pre">models.atmodel</span></code> – Author-topic models<a class="headerlink" href="#module-gensim.models.atmodel" title="Permalink to this headline">¶</a></h1>
<p>Author-topic model in Python.</p>
<p>This module trains the author-topic model on documents and corresponding author-document
dictionaries. The training is online and is constant in memory w.r.t. the number of
documents. The model is <em>not</em> constant in memory w.r.t. the number of authors.</p>
<p>The model can be updated with additional documents after training has been completed. It is
also possible to continue training on the existing data.</p>
<p>The model is closely related to Latent Dirichlet Allocation. The AuthorTopicModel class
inherits the LdaModel class, and its usage is thus similar.</p>
<p>Distributed computation and multiprocessing is not implemented at the moment, but may be
coming in the future.</p>
<p>The model was introduced by Rosen-Zvi and co-authors in 2004 (<a class="reference external" href="https://mimno.infosci.cornell.edu/info6150/readings/398.pdf">https://mimno.infosci.cornell.edu/info6150/readings/398.pdf</a>).</p>
<p>A tutorial can be found at <a class="reference external" href="https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks/atmodel_tutorial.ipynb">https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks/atmodel_tutorial.ipynb</a>.</p>
<dl class="class">
<dt id="gensim.models.atmodel.AuthorTopicModel">
<em class="property">class </em><code class="descclassname">gensim.models.atmodel.</code><code class="descname">AuthorTopicModel</code><span class="sig-paren">(</span><em>corpus=None</em>, <em>num_topics=100</em>, <em>id2word=None</em>, <em>author2doc=None</em>, <em>doc2author=None</em>, <em>chunksize=2000</em>, <em>passes=1</em>, <em>iterations=50</em>, <em>decay=0.5</em>, <em>offset=1.0</em>, <em>alpha='symmetric'</em>, <em>eta='symmetric'</em>, <em>update_every=1</em>, <em>eval_every=10</em>, <em>gamma_threshold=0.001</em>, <em>serialized=False</em>, <em>serialization_path=None</em>, <em>minimum_probability=0.01</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="ldamodel.html#gensim.models.ldamodel.LdaModel" title="gensim.models.ldamodel.LdaModel"><code class="xref py py-class docutils literal"><span class="pre">gensim.models.ldamodel.LdaModel</span></code></a></p>
<p>The constructor estimates the author-topic model parameters based
on a training corpus:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AuthorTopicModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">author2doc</span><span class="o">=</span><span class="n">author2doc</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">id2word</span><span class="p">)</span>
</pre></div>
</div>
<p>The model can be updated (trained) with new documents via</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">other_corpus</span><span class="p">,</span> <span class="n">other_author2doc</span><span class="p">)</span>
</pre></div>
</div>
<p>Model persistency is achieved through its <cite>load</cite>/<cite>save</cite> methods.</p>
<p>If the iterable corpus and one of author2doc/doc2author dictionaries are given,
start training straight away. If not given, the model is left untrained
(presumably because you want to call the <cite>update</cite> method manually).</p>
<p><cite>num_topics</cite> is the number of requested latent topics to be extracted from
the training corpus.</p>
<p><cite>id2word</cite> is a mapping from word ids (integers) to words (strings). It is
used to determine the vocabulary size, as well as for debugging and topic
printing.</p>
<p><cite>author2doc</cite> is a dictionary where the keys are the names of authors, and the
values are lists of documents that the author contributes to.</p>
<p><cite>doc2author</cite> is a dictionary where the keys are document IDs (indexes to corpus)
and the values are lists of author names. I.e. this is the reverse mapping of
<cite>author2doc</cite>. Only one of the two, <cite>author2doc</cite> and <cite>doc2author</cite> have to be
supplied.</p>
<p><cite>passes</cite> is the number of times the model makes a pass over the entire trianing
data.</p>
<p><cite>iterations</cite> is the maximum number of times the model loops over each document
(M-step). The iterations stop when convergence is reached.</p>
<p><cite>chunksize</cite> controls the size of the mini-batches.</p>
<p><cite>alpha</cite> and <cite>eta</cite> are hyperparameters that affect sparsity of the author-topic
(theta) and topic-word (lambda) distributions. Both default to a symmetric
1.0/num_topics prior.</p>
<p><cite>alpha</cite> can be set to an explicit array = prior of your choice. It also
support special values of ‘asymmetric’ and ‘auto’: the former uses a fixed
normalized asymmetric 1.0/topicno prior, the latter learns an asymmetric
prior directly from your data.</p>
<p><cite>eta</cite> can be a scalar for a symmetric prior over topic/word
distributions, or a vector of shape num_words, which can be used to
impose (user defined) asymmetric priors over the word distribution.
It also supports the special value ‘auto’, which learns an asymmetric
prior over words directly from your data. <cite>eta</cite> can also be a matrix
of shape num_topics x num_words, which can be used to impose
asymmetric priors over the word distribution on a per-topic basis
(can not be learned from data).</p>
<p>Calculate and log perplexity estimate from the latest mini-batch every
<cite>eval_every</cite> model updates. Set to None to disable perplexity estimation.</p>
<p><cite>decay</cite> and <cite>offset</cite> parameters are the same as Kappa and Tau_0 in
Hoffman et al, respectively. <cite>decay</cite> controls how quickly old documents are
forgotten, while <cite>offset</cite> down-weights early iterations.</p>
<p><cite>minimum_probability</cite> controls filtering the topics returned for a document (bow).</p>
<p><cite>random_state</cite> can be an integer or a numpy.random.RandomState object. Set the
state of the random number generator inside the author-topic model, to ensure
reproducibility of your experiments, for example.</p>
<p><cite>serialized</cite> indicates whether the input corpora to the model are simple
in-memory lists (<cite>serialized = False</cite>) or saved to the hard-drive
(<cite>serialized = True</cite>). Note that this behaviour is quite different from
other Gensim models. If your data is too large to fit in to memory, use
this functionality. Note that calling <cite>AuthorTopicModel.update</cite> with new
data may be cumbersome as it requires all the existing data to be
re-serialized.</p>
<p><cite>serialization_path</cite> must be set to a filepath, if <cite>serialized = True</cite> is
used. Use, for example, <cite>serialization_path = /tmp/serialized_model.mm</cite> or use your
working directory by setting <cite>serialization_path = serialized_model.mm</cite>. An existing
file <em>cannot</em> be overwritten; either delete the old file or choose a different
name.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AuthorTopicModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">author2doc</span><span class="o">=</span><span class="n">author2doc</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">id2word</span><span class="p">)</span>  <span class="c1"># train model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">corpus2</span><span class="p">)</span>  <span class="c1"># update the author-topic model with additional documents</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AuthorTopicModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">author2doc</span><span class="o">=</span><span class="n">author2doc</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">id2word</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">eval_every</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># train asymmetric alpha from data</span>
</pre></div>
</div>
<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.bound">
<code class="descname">bound</code><span class="sig-paren">(</span><em>chunk</em>, <em>chunk_doc_idx=None</em>, <em>subsample_ratio=1.0</em>, <em>author2doc=None</em>, <em>doc2author=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.bound" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the variational bound of documents from <cite>corpus</cite>:
E_q[log p(corpus)] - E_q[log q(corpus)]</p>
<p>There are basically two use cases of this method:
1. <cite>chunk</cite> is a subset of the training corpus, and <cite>chunk_doc_idx</cite> is provided,
indicating the indexes of the documents in the training corpus.
2. <cite>chunk</cite> is a test set (held-out data), and author2doc and doc2author
corrsponding to this test set are provided. There must not be any new authors
passed to this method. <cite>chunk_doc_idx</cite> is not needed in this case.</p>
<p>To obtain the per-word bound, compute:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">corpus_words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cnt</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">corpus</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cnt</span> <span class="ow">in</span> <span class="n">document</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">bound</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">author2doc</span><span class="o">=</span><span class="n">author2doc</span><span class="p">,</span> <span class="n">doc2author</span><span class="o">=</span><span class="n">doc2author</span><span class="p">)</span> <span class="o">/</span> <span class="n">corpus_words</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.clear">
<code class="descname">clear</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear model state (free up some memory). Used in the distributed algo.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.compute_phinorm">
<code class="descname">compute_phinorm</code><span class="sig-paren">(</span><em>expElogthetad</em>, <em>expElogbetad</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.compute_phinorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficiently computes the normalizing factor in phi.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.diff">
<code class="descname">diff</code><span class="sig-paren">(</span><em>other</em>, <em>distance='kullback_leibler'</em>, <em>num_words=100</em>, <em>n_ann_terms=10</em>, <em>diagonal=False</em>, <em>annotation=True</em>, <em>normed=True</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.diff" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate difference topic2topic between two Lda models
<cite>other</cite> instances of <cite>LdaMulticore</cite> or <cite>LdaModel</cite>
<cite>distance</cite> is function that will be applied to calculate difference between any topic pair.
Available values: <cite>kullback_leibler</cite>, <cite>hellinger</cite>, <cite>jaccard</cite> and <cite>jensen_shannon</cite>
<cite>num_words</cite> is quantity of most relevant words that used if distance == <cite>jaccard</cite> (also used for annotation)
<cite>n_ann_terms</cite> is max quantity of words in intersection/symmetric difference between topics (used for annotation)
<cite>diagonal</cite> set to True if the difference is required only between the identical topic no.s (returns diagonal of diff matrix)
<cite>annotation</cite> whether the intersection or difference of words between two topics should be returned
Returns a matrix Z with shape (m1.num_topics, m2.num_topics), where Z[i][j] - difference between topic_i and topic_j
and matrix annotation (if True) with shape (m1.num_topics, m2.num_topics, 2, None),
where:</p>
<blockquote>
<div>annotation[i][j] = [[<cite>int_1</cite>, <cite>int_2</cite>, …], [<cite>diff_1</cite>, <cite>diff_2</cite>, …]] and
<cite>int_k</cite> is word from intersection of <cite>topic_i</cite> and <cite>topic_j</cite> and
<cite>diff_l</cite> is word from symmetric difference of <cite>topic_i</cite> and <cite>topic_j</cite>
<cite>normed</cite> is a flag. If <cite>true</cite>, matrix Z will be normalized</div></blockquote>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">LdaMulticore</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path_1</span><span class="p">),</span> <span class="n">LdaMulticore</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path_2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mdiff</span><span class="p">,</span> <span class="n">annotation</span> <span class="o">=</span> <span class="n">m1</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">m2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">mdiff</span><span class="p">)</span> <span class="c1"># get matrix with difference for each topic pair from `m1` and `m2`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">annotation</span><span class="p">)</span> <span class="c1"># get array with positive/negative words for each topic pair from `m1` and `m2`</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.do_estep">
<code class="descname">do_estep</code><span class="sig-paren">(</span><em>chunk</em>, <em>author2doc</em>, <em>doc2author</em>, <em>rhot</em>, <em>state=None</em>, <em>chunk_doc_idx=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.do_estep" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference on a chunk of documents, and accumulate the collected
sufficient statistics in <cite>state</cite> (or <cite>self.state</cite> if None).</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.do_mstep">
<code class="descname">do_mstep</code><span class="sig-paren">(</span><em>rho</em>, <em>other</em>, <em>extra_pass=False</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.do_mstep" title="Permalink to this definition">¶</a></dt>
<dd><p>M step: use linear interpolation between the existing topics and
collected sufficient statistics in <cite>other</cite> to update the topics.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.extend_corpus">
<code class="descname">extend_corpus</code><span class="sig-paren">(</span><em>corpus</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.extend_corpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Add new documents in <cite>corpus</cite> to <cite>self.corpus</cite>. If serialization is used,
then the entire corpus (<cite>self.corpus</cite>) is re-serialized and the new documents
are added in the process. If serialization is not used, the corpus, as a list
of documents, is simply extended.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.get_author_topics">
<code class="descname">get_author_topics</code><span class="sig-paren">(</span><em>author_name</em>, <em>minimum_probability=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.get_author_topics" title="Permalink to this definition">¶</a></dt>
<dd><p>Return topic distribution the given author, as a list of
(topic_id, topic_probability) 2-tuples.
Ignore topics with very low probability (below <cite>minimum_probability</cite>).</p>
<p>Obtaining topic probabilities of each word, as in LDA (via <cite>per_word_topics</cite>),
is not supported.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.get_document_topics">
<code class="descname">get_document_topics</code><span class="sig-paren">(</span><em>word_id</em>, <em>minimum_probability=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.get_document_topics" title="Permalink to this definition">¶</a></dt>
<dd><p>This method overwrites <cite>LdaModel.get_document_topics</cite> and simply raises an
exception. <cite>get_document_topics</cite> is not valid for the author-topic model,
use <cite>get_author_topics</cite> instead.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.get_term_topics">
<code class="descname">get_term_topics</code><span class="sig-paren">(</span><em>word_id</em>, <em>minimum_probability=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.get_term_topics" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>word_id</strong> (<em>int</em>) – ID of the word to get topic probabilities for.</li>
<li><strong>minimum_probability</strong> (<em>float</em>) – Only include topic probabilities above this
value (None by default). If set to None, use 1e-8 to prevent including 0s.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The most likely topics for the given word. Each topic is represented
as a tuple of <cite>(topic_id, term_probability)</cite>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.get_topic_terms">
<code class="descname">get_topic_terms</code><span class="sig-paren">(</span><em>topicid</em>, <em>topn=10</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.get_topic_terms" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>topn</strong> (<em>int</em>) – Only return 2-tuples for the topn most probable words
(ignore the rest).</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>(word_id, probability)</cite> 2-tuples for the most probable words
in topic with id <cite>topicid</cite>.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.get_topics">
<code class="descname">get_topics</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.get_topics" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><cite>num_topics</cite> x <cite>vocabulary_size</cite> array of floats which represents
the term topic matrix learned during inference.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">np.ndarray</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>chunk</em>, <em>author2doc</em>, <em>doc2author</em>, <em>rhot</em>, <em>collect_sstats=False</em>, <em>chunk_doc_idx=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a chunk of sparse document vectors, update gamma (parameters
controlling the topic weights) for each author corresponding to the
documents in the chunk.</p>
<p>The whole input chunk of document is assumed to fit in RAM; chunking of
a large corpus must be done earlier in the pipeline.</p>
<p>If <cite>collect_sstats</cite> is True, also collect sufficient statistics needed
to update the model’s topic-word distributions, and return a 2-tuple
<cite>(gamma_chunk, sstats)</cite>. Otherwise, return <cite>(gamma_chunk, None)</cite>.
<cite>gamma_cunk</cite> is of shape <cite>len(chunk_authors) x self.num_topics</cite>, where
<cite>chunk_authors</cite> is the number of authors in the documents in the
current chunk.</p>
<p>Avoids computing the <cite>phi</cite> variational parameter directly using the
optimization presented in <strong>Lee, Seung: Algorithms for non-negative matrix factorization, NIPS 2001</strong>.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.init_dir_prior">
<code class="descname">init_dir_prior</code><span class="sig-paren">(</span><em>prior</em>, <em>name</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.init_dir_prior" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.init_empty_corpus">
<code class="descname">init_empty_corpus</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.init_empty_corpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize an empty corpus. If the corpora are to be treated as lists, simply
initialize an empty list. If serialization is used, initialize an empty corpus
of the class <cite>gensim.corpora.MmCorpus</cite>.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>fname</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a previously saved object from file (also see <cite>save</cite>).</p>
<p>Large arrays can be memmap’ed back as read-only (shared memory) by setting <cite>mmap=’r’</cite>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">LdaModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">mmap</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.log_perplexity">
<code class="descname">log_perplexity</code><span class="sig-paren">(</span><em>chunk</em>, <em>chunk_doc_idx=None</em>, <em>total_docs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.log_perplexity" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate and return per-word likelihood bound, using the <cite>chunk</cite> of
documents as evaluation corpus. Also output the calculated statistics. incl.
perplexity=2^(-bound), to log at INFO level.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.print_topic">
<code class="descname">print_topic</code><span class="sig-paren">(</span><em>topicno</em>, <em>topn=10</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.print_topic" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a single topic as a formatted string. See <cite>show_topic()</cite> for parameters.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lsimodel</span><span class="o">.</span><span class="n">print_topic</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="go">&#39;-0.340 * &quot;category&quot; + 0.298 * &quot;$M$&quot; + 0.183 * &quot;algebra&quot; + -0.174 * &quot;functor&quot; + -0.168 * &quot;operator&quot;&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.print_topics">
<code class="descname">print_topics</code><span class="sig-paren">(</span><em>num_topics=20</em>, <em>num_words=10</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.print_topics" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <cite>show_topics()</cite> that prints the <cite>num_words</cite> most
probable words for <cite>topics</cite> number of topics to log.
Set <cite>topics=-1</cite> to print all topics.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>fname</em>, <em>ignore=('state'</em>, <em>'dispatcher')</em>, <em>separately=None</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the model to file.</p>
<p>Large internal arrays may be stored into separate files, with <cite>fname</cite> as prefix.</p>
<p><cite>separately</cite> can be used to define which arrays should be stored in separate files.</p>
<p><cite>ignore</cite> parameter can be used to define which variables should be ignored, i.e. left
out from the pickled lda model. By default the internal <cite>state</cite> is ignored as it uses
its own serialisation not the one provided by <cite>LdaModel</cite>. The <cite>state</cite> and <cite>dispatcher</cite>
will be added to any ignore parameter defined.</p>
<p>Note: do not save as a compressed file if you intend to load the file back with <cite>mmap</cite>.</p>
<p>Note: If you intend to use models across Python 2/3 versions there are a few things to
keep in mind:</p>
<blockquote>
<div><ol class="arabic simple">
<li>The pickled Python dictionaries will not work across Python versions</li>
<li>The <cite>save</cite> method does not automatically save all np arrays using np, only
those ones that exceed <cite>sep_limit</cite> set in <cite>gensim.utils.SaveLoad.save</cite>. The main
concern here is the <cite>alpha</cite> array if for instance using <cite>alpha=’auto’</cite>.</li>
</ol>
</div></blockquote>
<p>Please refer to the wiki recipes section (<a class="reference external" href="https://github.com/piskvorky/gensim/wiki/Recipes-&amp;-FAQ#q9-how-do-i-load-a-model-in-python-3-that-was-trained-and-saved-using-python-2">https://github.com/piskvorky/gensim/wiki/Recipes-&amp;-FAQ#q9-how-do-i-load-a-model-in-python-3-that-was-trained-and-saved-using-python-2</a>)
for an example on how to work around these issues.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.show_topic">
<code class="descname">show_topic</code><span class="sig-paren">(</span><em>topicid</em>, <em>topn=10</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.show_topic" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>topn</strong> (<em>int</em>) – Only return 2-tuples for the topn most probable words
(ignore the rest).</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">of <cite>(word, probability)</cite> 2-tuples for the most probable
words in topic <cite>topicid</cite>.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.show_topics">
<code class="descname">show_topics</code><span class="sig-paren">(</span><em>num_topics=10</em>, <em>num_words=10</em>, <em>log=False</em>, <em>formatted=True</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.show_topics" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_topics</strong> (<em>int</em>) – show results for first <cite>num_topics</cite> topics.
Unlike LSA, there is no natural ordering between the topics in LDA.
The returned <cite>num_topics &lt;= self.num_topics</cite> subset of all topics is
therefore arbitrary and may change between two LDA training runs.</li>
<li><strong>num_words</strong> (<em>int</em>) – include top <cite>num_words</cite> with highest probabilities in topic.</li>
<li><strong>log</strong> (<em>bool</em>) – If True, log output in addition to returning it.</li>
<li><strong>formatted</strong> (<em>bool</em>) – If True, format topics as strings, otherwise return them as
<cite>(word, probability)</cite> 2-tuples.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><cite>num_words</cite> most significant words for <cite>num_topics</cite> number of topics
(10 words for top 10 topics, by default).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.sync_state">
<code class="descname">sync_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.sync_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.top_topics">
<code class="descname">top_topics</code><span class="sig-paren">(</span><em>corpus=None</em>, <em>texts=None</em>, <em>dictionary=None</em>, <em>window_size=None</em>, <em>coherence='u_mass'</em>, <em>topn=20</em>, <em>processes=-1</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.top_topics" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the coherence for each topic; default is Umass coherence.</p>
<p>See the <code class="xref py py-class docutils literal"><span class="pre">gensim.models.CoherenceModel</span></code> constructor for more info on the
parameters and the different coherence metrics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">tuples with <cite>(topic_repr, coherence_score)</cite>, where <cite>topic_repr</cite> is a list
of representations of the <cite>topn</cite> terms for the topic. The terms are represented
as tuples of <cite>(membership_in_topic, token)</cite>. The <cite>coherence_score</cite> is a float.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.update">
<code class="descname">update</code><span class="sig-paren">(</span><em>corpus=None</em>, <em>author2doc=None</em>, <em>doc2author=None</em>, <em>chunksize=None</em>, <em>decay=None</em>, <em>offset=None</em>, <em>passes=None</em>, <em>update_every=None</em>, <em>eval_every=None</em>, <em>iterations=None</em>, <em>gamma_threshold=None</em>, <em>chunks_as_numpy=False</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the model with new documents, by EM-iterating over <cite>corpus</cite> until
the topics converge (or until the maximum number of allowed iterations
is reached). <cite>corpus</cite> must be an iterable (repeatable stream of documents),</p>
<p>This update also supports updating an already trained model (<cite>self</cite>)
with new documents from <cite>corpus</cite>; the two models are then merged in
proportion to the number of old vs. new documents. This feature is still
experimental for non-stationary input streams.</p>
<p>For stationary input (no topic drift in new documents), on the other hand,
this equals the online update of Hoffman et al. and is guaranteed to
converge for any <cite>decay</cite> in (0.5, 1.0&gt;. Additionally, for smaller
<cite>corpus</cite> sizes, an increasing <cite>offset</cite> may be beneficial (see
Table 1 in Hoffman et al.)</p>
<p>If update is called with authors that already exist in the model, it will
resume training on not only new documents for that author, but also the
previously seen documents. This is necessary for those authors’ topic
distributions to converge.</p>
<p>Every time <cite>update(corpus, author2doc)</cite> is called, the new documents are
to appended to all the previously seen documents, and author2doc is
combined with the previously seen authors.</p>
<p>To resume training on all the data seen by the model, simply call
<cite>update()</cite>.</p>
<p>It is not possible to add new authors to existing documents, as all
documents in <cite>corpus</cite> are assumed to be new documents.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>corpus</strong> (<em>gensim corpus</em>) – The corpus with which the author-topic model should be updated.</li>
<li><strong>author2doc</strong> (<a class="reference internal" href="../corpora/dictionary.html#module-gensim.corpora.dictionary" title="gensim.corpora.dictionary: Construct word&lt;-&gt;id mappings"><em>dictionary</em></a>) – author to document mapping corresponding to indexes in input
corpus.</li>
<li><strong>doc2author</strong> (<a class="reference internal" href="../corpora/dictionary.html#module-gensim.corpora.dictionary" title="gensim.corpora.dictionary: Construct word&lt;-&gt;id mappings"><em>dictionary</em></a>) – document to author mapping corresponding to indexes in input
corpus.</li>
<li><strong>chunks_as_numpy</strong> (<em>bool</em>) – Whether each chunk passed to <cite>.inference</cite> should be a np
array of not. np can in some settings turn the term IDs
into floats, these will be converted back into integers in
inference, which incurs a performance hit. For distributed
computing it may be desirable to keep the chunks as np
arrays.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>For other parameter settings, see <a class="reference internal" href="#gensim.models.atmodel.AuthorTopicModel" title="gensim.models.atmodel.AuthorTopicModel"><code class="xref py py-class docutils literal"><span class="pre">AuthorTopicModel</span></code></a> constructor.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.update_alpha">
<code class="descname">update_alpha</code><span class="sig-paren">(</span><em>gammat</em>, <em>rho</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.update_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Update parameters for the Dirichlet prior on the per-document
topic weights <cite>alpha</cite> given the last <cite>gammat</cite>.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicModel.update_eta">
<code class="descname">update_eta</code><span class="sig-paren">(</span><em>lambdat</em>, <em>rho</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicModel.update_eta" title="Permalink to this definition">¶</a></dt>
<dd><p>Update parameters for the Dirichlet prior on the per-topic
word weights <cite>eta</cite> given the last <cite>lambdat</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="gensim.models.atmodel.AuthorTopicState">
<em class="property">class </em><code class="descclassname">gensim.models.atmodel.</code><code class="descname">AuthorTopicState</code><span class="sig-paren">(</span><em>eta</em>, <em>lambda_shape</em>, <em>gamma_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="ldamodel.html#gensim.models.ldamodel.LdaState" title="gensim.models.ldamodel.LdaState"><code class="xref py py-class docutils literal"><span class="pre">gensim.models.ldamodel.LdaState</span></code></a></p>
<p>NOTE: distributed mode not available yet in the author-topic model. This AuthorTopicState
object is kept so that when the time comes to imlement it, it will be easier.</p>
<p>Encapsulate information for distributed computation of AuthorTopicModel objects.</p>
<p>Objects of this class are sent over the network, so try to keep them lean to
reduce traffic.</p>
<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.blend">
<code class="descname">blend</code><span class="sig-paren">(</span><em>rhot</em>, <em>other</em>, <em>targetsize=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.blend" title="Permalink to this definition">¶</a></dt>
<dd><p>Given LdaState <cite>other</cite>, merge it with the current state. Stretch both to
<cite>targetsize</cite> documents before merging, so that they are of comparable
magnitude.</p>
<p>Merging is done by average weighting: in the extremes, <cite>rhot=0.0</cite> means
<cite>other</cite> is completely ignored; <cite>rhot=1.0</cite> means <cite>self</cite> is completely ignored.</p>
<p>This procedure corresponds to the stochastic gradient update from Hoffman
et al., algorithm 2 (eq. 14).</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.blend2">
<code class="descname">blend2</code><span class="sig-paren">(</span><em>rhot</em>, <em>other</em>, <em>targetsize=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.blend2" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternative, more simple blend.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.get_Elogbeta">
<code class="descname">get_Elogbeta</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.get_Elogbeta" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.get_lambda">
<code class="descname">get_lambda</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.get_lambda" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>fname</em>, <em>mmap=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a previously saved object from file (also see <cite>save</cite>).</p>
<p>If the object was saved with large arrays stored separately, you can load
these arrays via mmap (shared memory) using <cite>mmap=’r’</cite>. Default: don’t use
mmap, load large arrays as normal objects.</p>
<p>If the file being loaded is compressed (either ‘.gz’ or ‘.bz2’), then
<cite>mmap=None</cite> must be set.  Load will raise an <cite>IOError</cite> if this condition
is encountered.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.merge">
<code class="descname">merge</code><span class="sig-paren">(</span><em>other</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.merge" title="Permalink to this definition">¶</a></dt>
<dd><p>Merge the result of an E step from one node with that of another node
(summing up sufficient statistics).</p>
<p>The merging is trivial and after merging all cluster nodes, we have the
exact same result as if the computation was run on a single node (no
approximation).</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare the state for a new EM iteration (reset sufficient stats).</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.atmodel.AuthorTopicState.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>fname_or_handle</em>, <em>separately=None</em>, <em>sep_limit=10485760</em>, <em>ignore=frozenset([])</em>, <em>pickle_protocol=2</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.AuthorTopicState.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the object to file (also see <cite>load</cite>).</p>
<p><cite>fname_or_handle</cite> is either a string specifying the file name to
save to, or an open file-like object which can be written to. If
the object is a file handle, no special array handling will be
performed; all attributes will be saved to the same file.</p>
<p>If <cite>separately</cite> is None, automatically detect large
numpy/scipy.sparse arrays in the object being stored, and store
them into separate files. This avoids pickle memory errors and
allows mmap’ing large arrays back on load efficiently.</p>
<p>You can also set <cite>separately</cite> manually, in which case it must be
a list of attribute names to be stored in separate files. The
automatic check is not performed in this case.</p>
<p><cite>ignore</cite> is a set of attribute names to <em>not</em> serialize (file
handles, caches etc). On subsequent load() these attributes will
be set to None.</p>
<p><cite>pickle_protocol</cite> defaults to 2 so the pickled object can be imported
in both Python 2 and 3.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="gensim.models.atmodel.construct_author2doc">
<code class="descclassname">gensim.models.atmodel.</code><code class="descname">construct_author2doc</code><span class="sig-paren">(</span><em>doc2author</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.construct_author2doc" title="Permalink to this definition">¶</a></dt>
<dd><p>Make a mapping from author IDs to document IDs.</p>
</dd></dl>

<dl class="function">
<dt id="gensim.models.atmodel.construct_doc2author">
<code class="descclassname">gensim.models.atmodel.</code><code class="descname">construct_doc2author</code><span class="sig-paren">(</span><em>corpus</em>, <em>author2doc</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.atmodel.construct_doc2author" title="Permalink to this definition">¶</a></dt>
<dd><p>Make a mapping from document IDs to author IDs.</p>
</dd></dl>

</div>


          </div>
        </div>
      

      <div class="clearer"></div>
    </div>
    

    
    <div id="footer">
      <div id="footerwrapper">
        <div id="footerleft">
          <img src="../_static/images/logo-gensim.png" class="smallerlogo" alt="smaller gensim logo" />
          <a href="../index.html"><img src="../_static/images/gensim-footer.png" alt="gensim footer image" title="Gensim home" /></a>

          <div class="copyright">
            &copy; Copyright 2009-now, <a href="mailto:radimrehurek@seznam.cz" style="color:white"> Radim Řehůřek</a>
            <br />
              Last updated on Nov 06, 2017.
          </div>
        </div>

        <div id="footermiddleright">
          <div id="footermiddle">
            <ul class="navigation">
              <li><a href="../index.html">
                Home
              </a></li>
              <li>|</li>
              <li><a href="../tutorial.html">
                Tutorials
              </a></li>
              <li>|</li>
              <li><a href="../install.html">
                Install
              </a></li>
              <li>|</li>
              <li><a href="../support.html">
                Support
              </a></li>
              <li>|</li>
              <li><a href="../apiref.html">
                API
              </a></li>
              <li>|</li>
              <li><a href="../about.html">
                About
              </a></li>
            </ul>

            <div class="tweetodsazeni">
              <div class="tweet">
                <a href="https://twitter.com/radimrehurek" target="_blank" style="color: white">Tweet @RadimRehurek</a>
              </div>
            </div>

          </div>

          <div id="footerright">
            <div class="footernadpis">
              Support:
            </div>
            <div class="googlegroupsodsazeni">
              <a href="https://groups.google.com/group/gensim" class="googlegroups">
                Stay informed via gensim mailing list:
              </a>

              <form action="http://groups.google.com/group/gensim/boxsubscribe">
                <input type="text" name="email" placeholder="your@email.com" size="28" />
                <input type="submit" name="sub" value="Subscribe" />
              </form>

            </div>

            <div class="addthis_toolbox addthis_default_style addthis_32x32_style"
                addthis:title="#gensim"
                addthis:description="Efficient Topic Modelling in Python"
                style="margin:20px 0 0 0">
              <a class="addthis_button_preferred_1"></a>
              <a class="addthis_button_preferred_2"></a>
              <a class="addthis_button_preferred_3"></a>
              <a class="addthis_button_preferred_4"></a>
              <a class="addthis_button_compact"></a>
              <a class="addthis_counter addthis_bubble_style"></a>
            </div>
          </div>

        </div>
      </div>
    </div>
    

    <script type="text/javascript">
      (function() {
      var at = document.createElement('script'); at.type = 'text/javascript'; at.async = true;
      at.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 's7.addthis.com/js/250/addthis_widget.js#pubid=ra-4d738b9b1d31ccbd';
      var sat = document.getElementsByTagName('script')[0]; sat.parentNode.insertBefore(at, sat);
      })();
    </script>

  </body>
</html>