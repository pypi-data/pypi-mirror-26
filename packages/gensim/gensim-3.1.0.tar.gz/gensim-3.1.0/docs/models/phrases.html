<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">




<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <!-- Google Tag Manager - JD-20170831 --> 
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MP366CC');</script>
    <!-- End Google Tag Manager -->

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta property="description" content="Efficient topic modelling of text semantics in Python." />
    <meta property="og:title" content="gensim: topic modelling for humans" />
    <meta property="og:description" content="Efficient topic modelling in Python" />

    
      <title>gensim: models.phrases – Phrase (collocation) detection</title>

    
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/jquery.qtip.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/anythingslider.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/>

  </head>

  <body>
    <!-- Google Tag Manager (noscript) - JD-20170831 -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MP366CC"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

    <div id="topwrap">
      
      <div id="top1">
        <div id="left1">
          <h1 class="h1gensim">
            <img src="../_static/images/logo-gensim_compact.png" alt="gensim logo" title="Gensim - topic modelling for humans" />
          </h1>
        </div>

        <div id="middleright">
          <div id="middle1">
            <div id="gensim"><a href="../index.html"><img src="../_static/images/gensim_compact.png" alt="gensim" title="Gensim home" /></a></div>
            <div id="tagline"><img src="../_static/images/tagline_compact.png" alt="gensim tagline" /></div>
          </div>
          <div id="right1">
            <div class="consulting-banner">
              <h3><a href="http://rare-technologies.com/">Get Expert Help</a></h3>
              <p>• machine learning, NLP, data mining</p>
              <p>• custom SW design, development, optimizations</p>
              <p>• corporate trainings &amp; IT consulting</p>
            </div>
          </div>
        </div>
      </div>
     

      
      <div id="menu">
        <div id="indentation1">
          <ul class="menubuttons">
            <li class="menubutton"><a href="../index.html">Home</a></li>
            <li class="menubutton"><a href="../tutorial.html">Tutorials</a></li>
            <li class="menubutton"><a href="../install.html">Install</a></li>
            <li class="menubutton"><a href="../support.html">Support</a></li>
            <li class="menubutton"><a href="../apiref.html">API</a></li>
            <li class="menubutton"><a href="../about.html">About</a></li>
          </ul>
        </div>
      </div>
      

      <div class="clearer"></div>
    </div>

    
  <script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
    URL_ROOT: '../',
    VERSION: '3.1.0',
    COLLAPSE_INDEX: false,
    FILE_SUFFIX: '.html',
    HAS_SOURCE: true
  };
  </script>
    <script type="text/javascript" src="../_static/js/jquery-1.9.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.qtip.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-migrate-1.1.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.anythingslider.min.js"></script>

    
    <div class="document">
      
        <div id="thinbanner">
          <div id="bodythinbanner">
            <span class="h2gensim">models.phrases – Phrase (collocation) detection</span>
          </div>
        </div>
        <div class="obsah">
          <div class="obsahwrapper">
            
  <div class="section" id="module-gensim.models.phrases">
<span id="models-phrases-phrase-collocation-detection"></span><h1><code class="xref py py-mod docutils literal"><span class="pre">models.phrases</span></code> – Phrase (collocation) detection<a class="headerlink" href="#module-gensim.models.phrases" title="Permalink to this headline">¶</a></h1>
<p>Automatically detect common phrases (multiword expressions) from a stream of sentences.</p>
<p>The phrases are collocations (frequently co-occurring tokens). See <a class="footnote-reference" href="#id2" id="id1">[1]</a> for the
exact formula.</p>
<p>For example, if your input stream (=an iterable, with each value a list of token strings) looks like:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">sentence_stream</span><span class="p">))</span>
<span class="go">[[u&#39;the&#39;, u&#39;mayor&#39;, u&#39;of&#39;, u&#39;new&#39;, u&#39;york&#39;, u&#39;was&#39;, u&#39;there&#39;],</span>
<span class="go"> [u&#39;machine&#39;, u&#39;learning&#39;, u&#39;can&#39;, u&#39;be&#39;, u&#39;useful&#39;, u&#39;sometimes&#39;],</span>
<span class="go"> ...,</span>
<span class="go">]</span>
</pre></div>
</div>
<p>you’d train the detector with:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">sentence_stream</span><span class="p">)</span>
</pre></div>
</div>
<p>and then create a performant Phraser object to transform any sentence (list of token strings) using the standard gensim syntax:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">phrases</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sent</span> <span class="o">=</span> <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;mayor&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;new&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;york&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;there&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">bigram</span><span class="p">[</span><span class="n">sent</span><span class="p">])</span>
<span class="go">[u&#39;the&#39;, u&#39;mayor&#39;, u&#39;of&#39;, u&#39;new_york&#39;, u&#39;was&#39;, u&#39;there&#39;]</span>
</pre></div>
</div>
<p>(note <cite>new_york</cite> became a single token). As usual, you can also transform an entire
sentence stream using:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">bigram</span><span class="p">[</span><span class="n">any_sentence_stream</span><span class="p">]))</span>
<span class="go">[[u&#39;the&#39;, u&#39;mayor&#39;, u&#39;of&#39;, u&#39;new_york&#39;, u&#39;was&#39;, u&#39;there&#39;],</span>
<span class="go"> [u&#39;machine_learning&#39;, u&#39;can&#39;, u&#39;be&#39;, u&#39;useful&#39;, u&#39;sometimes&#39;],</span>
<span class="go"> ...,</span>
<span class="go">]</span>
</pre></div>
</div>
<p>You can also continue updating the collocation counts with new sentences, by:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bigram</span><span class="o">.</span><span class="n">add_vocab</span><span class="p">(</span><span class="n">new_sentence_stream</span><span class="p">)</span>
</pre></div>
</div>
<p>These <strong>phrase streams are meant to be used during text preprocessing, before
converting the resulting tokens into vectors using `Dictionary`</strong>. See the
<a class="reference internal" href="word2vec.html#module-gensim.models.word2vec" title="gensim.models.word2vec: Deep learning with word2vec"><code class="xref py py-mod docutils literal"><span class="pre">gensim.models.word2vec</span></code></a> module for an example application of using phrase detection.</p>
<p>The detection can also be <strong>run repeatedly</strong>, to get phrases longer than
two tokens (e.g. <cite>new_york_times</cite>):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">trigram</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">bigram</span><span class="p">[</span><span class="n">sentence_stream</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sent</span> <span class="o">=</span> <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;new&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;york&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;times&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;newspaper&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">trigram</span><span class="p">[</span><span class="n">bigram</span><span class="p">[</span><span class="n">sent</span><span class="p">]])</span>
<span class="go">[u&#39;the&#39;, u&#39;new_york_times&#39;, u&#39;is&#39;, u&#39;a&#39;, u&#39;newspaper&#39;]</span>
</pre></div>
</div>
<p>The common_terms parameter add a way to give special treatment to common terms (aka stop words)
such that their presence between two words
won’t prevent bigram detection.
It allows to detect expressions like “bank of america” or “eye of the beholder”.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">common_terms</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;of&quot;</span><span class="p">,</span> <span class="s2">&quot;with&quot;</span><span class="p">,</span> <span class="s2">&quot;without&quot;</span><span class="p">,</span> <span class="s2">&quot;and&quot;</span><span class="p">,</span> <span class="s2">&quot;or&quot;</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ct_phrases</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">sentence_stream</span><span class="p">,</span> <span class="n">common_terms</span><span class="o">=</span><span class="n">common_terms</span><span class="p">)</span>
</pre></div>
</div>
<p>The phraser will of course inherit the common_terms from Phrases.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ct_bigram</span> <span class="o">=</span> <span class="n">Phraser</span><span class="p">(</span><span class="n">ct_phrases</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sent</span> <span class="o">=</span> <span class="p">[</span><span class="sa">u</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;mayor&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;shows&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;his&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;lack&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="sa">u</span><span class="s1">&#39;interest&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">bigram</span><span class="p">[</span><span class="n">sent</span><span class="p">])</span>
<span class="go">[u&#39;the&#39;, u&#39;mayor&#39;, u&#39;shows&#39;, u&#39;his&#39;, u&#39;lack_of_interest&#39;]</span>
</pre></div>
</div>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean.
Distributed Representations of Words and Phrases and their Compositionality.
In Proceedings of NIPS, 2013.</td></tr>
</tbody>
</table>
<dl class="class">
<dt id="gensim.models.phrases.Phraser">
<em class="property">class </em><code class="descclassname">gensim.models.phrases.</code><code class="descname">Phraser</code><span class="sig-paren">(</span><em>phrases_model</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gensim.models.phrases.SentenceAnalyzer" title="gensim.models.phrases.SentenceAnalyzer"><code class="xref py py-class docutils literal"><span class="pre">gensim.models.phrases.SentenceAnalyzer</span></code></a>, <a class="reference internal" href="../interfaces.html#gensim.interfaces.TransformationABC" title="gensim.interfaces.TransformationABC"><code class="xref py py-class docutils literal"><span class="pre">gensim.interfaces.TransformationABC</span></code></a></p>
<p>Minimal state &amp; functionality to apply results of a Phrases model to tokens.</p>
<p>After the one-time initialization, a Phraser will be much smaller and
somewhat faster than using the full Phrases model.</p>
<p>Reflects the results of the source model’s <cite>min_count</cite>, <cite>threshold</cite>, and
<cite>scoring</cite> settings. (You can tamper with those &amp; create a new Phraser to try
other values.)</p>
<dl class="method">
<dt id="gensim.models.phrases.Phraser.analyze_sentence">
<code class="descname">analyze_sentence</code><span class="sig-paren">(</span><em>sentence</em>, <em>threshold</em>, <em>common_terms</em>, <em>scorer</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser.analyze_sentence" title="Permalink to this definition">¶</a></dt>
<dd><p>Analyze a sentence</p>
<p><cite>sentence</cite> a token list representing the sentence to be analyzed.</p>
<p><cite>threshold</cite> the minimum score for a bigram to be taken into account</p>
<p><cite>common_terms</cite> the list of common terms, they have a special treatment</p>
<p><cite>scorer</cite> the scorer function, as given to Phrases</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phraser.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>fname</em>, <em>mmap=None</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a previously saved object from file (also see <cite>save</cite>).</p>
<p>If the object was saved with large arrays stored separately, you can load
these arrays via mmap (shared memory) using <cite>mmap=’r’</cite>. Default: don’t use
mmap, load large arrays as normal objects.</p>
<p>If the file being loaded is compressed (either ‘.gz’ or ‘.bz2’), then
<cite>mmap=None</cite> must be set.  Load will raise an <cite>IOError</cite> if this condition
is encountered.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phraser.pseudocorpus">
<code class="descname">pseudocorpus</code><span class="sig-paren">(</span><em>phrases_model</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser.pseudocorpus" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phraser.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>fname_or_handle</em>, <em>separately=None</em>, <em>sep_limit=10485760</em>, <em>ignore=frozenset([])</em>, <em>pickle_protocol=2</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the object to file (also see <cite>load</cite>).</p>
<p><cite>fname_or_handle</cite> is either a string specifying the file name to
save to, or an open file-like object which can be written to. If
the object is a file handle, no special array handling will be
performed; all attributes will be saved to the same file.</p>
<p>If <cite>separately</cite> is None, automatically detect large
numpy/scipy.sparse arrays in the object being stored, and store
them into separate files. This avoids pickle memory errors and
allows mmap’ing large arrays back on load efficiently.</p>
<p>You can also set <cite>separately</cite> manually, in which case it must be
a list of attribute names to be stored in separate files. The
automatic check is not performed in this case.</p>
<p><cite>ignore</cite> is a set of attribute names to <em>not</em> serialize (file
handles, caches etc). On subsequent load() these attributes will
be set to None.</p>
<p><cite>pickle_protocol</cite> defaults to 2 so the pickled object can be imported
in both Python 2 and 3.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phraser.score_item">
<code class="descname">score_item</code><span class="sig-paren">(</span><em>worda</em>, <em>wordb</em>, <em>components</em>, <em>scorer</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phraser.score_item" title="Permalink to this definition">¶</a></dt>
<dd><p>score is retained from original dataset</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="gensim.models.phrases.Phrases">
<em class="property">class </em><code class="descclassname">gensim.models.phrases.</code><code class="descname">Phrases</code><span class="sig-paren">(</span><em>sentences=None</em>, <em>min_count=5</em>, <em>threshold=10.0</em>, <em>max_vocab_size=40000000</em>, <em>delimiter='_'</em>, <em>progress_per=10000</em>, <em>scoring='default'</em>, <em>common_terms=frozenset([])</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gensim.models.phrases.SentenceAnalyzer" title="gensim.models.phrases.SentenceAnalyzer"><code class="xref py py-class docutils literal"><span class="pre">gensim.models.phrases.SentenceAnalyzer</span></code></a>, <a class="reference internal" href="../interfaces.html#gensim.interfaces.TransformationABC" title="gensim.interfaces.TransformationABC"><code class="xref py py-class docutils literal"><span class="pre">gensim.interfaces.TransformationABC</span></code></a></p>
<p>Detect phrases, based on collected collocation counts. Adjacent words that appear
together more frequently than expected are joined together with the <cite>_</cite> character.</p>
<p>It can be used to generate phrases on the fly, using the <cite>phrases[sentence]</cite>
and <cite>phrases[corpus]</cite> syntax.</p>
<p>Initialize the model from an iterable of <cite>sentences</cite>. Each sentence must be
a list of words (unicode strings) that will be used for training.</p>
<p>The <cite>sentences</cite> iterable can be simply a list, but for larger corpora,
consider a generator that streams the sentences directly from disk/network,
without storing everything in RAM. See <code class="xref py py-class docutils literal"><span class="pre">BrownCorpus</span></code>,
<code class="xref py py-class docutils literal"><span class="pre">Text8Corpus</span></code> or <code class="xref py py-class docutils literal"><span class="pre">LineSentence</span></code> in the <a class="reference internal" href="word2vec.html#module-gensim.models.word2vec" title="gensim.models.word2vec: Deep learning with word2vec"><code class="xref py py-mod docutils literal"><span class="pre">gensim.models.word2vec</span></code></a>
module for such examples.</p>
<p><cite>min_count</cite> ignore all words and bigrams with total collected count lower
than this.</p>
<p><cite>threshold</cite> represents a score threshold for forming the phrases (higher means
fewer phrases). A phrase of words <cite>a</cite> followed by <cite>b</cite> is accepted if the score of the
phrase is greater than threshold. see the <cite>scoring</cite> setting.</p>
<p><cite>max_vocab_size</cite> is the maximum size of the vocabulary. Used to control
pruning of less common words, to keep memory under control. The default
of 40M needs about 3.6GB of RAM; increase/decrease <cite>max_vocab_size</cite> depending
on how much available memory you have.</p>
<p><cite>delimiter</cite> is the glue character used to join collocation tokens, and
should be a byte string (e.g. b’_’).</p>
<p><cite>scoring</cite> specifies how potential phrases are scored for comparison to the <cite>threshold</cite>
setting. <cite>scoring</cite> can be set with either a string that refers to a built-in scoring function,
or with a function with the expected parameter names. Two built-in scoring functions are available
by setting <cite>scoring</cite> to a string:</p>
<dl class="docutils">
<dt>‘default’: from “Efficient Estimaton of Word Representations in Vector Space” by</dt>
<dd>Mikolov, et. al.:
(count(worda followed by wordb) - min_count) * N /
(count(worda) * count(wordb)) &gt; threshold`, where <cite>N</cite> is the total vocabulary size.</dd>
<dt>‘npmi’: normalized pointwise mutual information, from “Normalized (Pointwise) Mutual</dt>
<dd>Information in Colocation Extraction” by Gerlof Bouma:
ln(prop(worda followed by wordb) / (prop(worda)*prop(wordb))) /
- ln(prop(worda followed by wordb)
where prop(n) is the count of n / the count of everything in the entire corpus.</dd>
</dl>
<p>‘npmi’ is more robust when dealing with common words that form part of common bigrams, and
ranges from -1 to 1, but is slower to calculate than the default.</p>
<p>To use a custom scoring function, create a function with the following parameters and set the <cite>scoring</cite>
parameter to the custom function. You must use all the parameters in your function call, even if the
function does not require all the parameters.</p>
<blockquote>
<div>worda_count: number of occurrances in <cite>sentences</cite> of the first token in the phrase being scored
wordb_count: number of occurrances in <cite>sentences</cite> of the second token in the phrase being scored
bigram_count: number of occurrances in <cite>sentences</cite> of the phrase being scored
len_vocab: the number of unique tokens in <cite>sentences</cite>
min_count: the <cite>min_count</cite> setting of the Phrases class
corpus_word_count: the total number of (non-unique) tokens in <cite>sentences</cite></div></blockquote>
<p>A scoring function without any of these parameters (even if the parameters are not used) will
raise a ValueError on initialization of the Phrases class. The scoring function must be picklable.</p>
<p><cite>common_terms</cite> is an optionnal list of “stop words” that won’t affect frequency count
of expressions containing them.</p>
<dl class="method">
<dt id="gensim.models.phrases.Phrases.add_vocab">
<code class="descname">add_vocab</code><span class="sig-paren">(</span><em>sentences</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.add_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Merge the collected counts <cite>vocab</cite> into this phrase detector.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phrases.analyze_sentence">
<code class="descname">analyze_sentence</code><span class="sig-paren">(</span><em>sentence</em>, <em>threshold</em>, <em>common_terms</em>, <em>scorer</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.analyze_sentence" title="Permalink to this definition">¶</a></dt>
<dd><p>Analyze a sentence</p>
<p><cite>sentence</cite> a token list representing the sentence to be analyzed.</p>
<p><cite>threshold</cite> the minimum score for a bigram to be taken into account</p>
<p><cite>common_terms</cite> the list of common terms, they have a special treatment</p>
<p><cite>scorer</cite> the scorer function, as given to Phrases</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phrases.export_phrases">
<code class="descname">export_phrases</code><span class="sig-paren">(</span><em>sentences</em>, <em>out_delimiter=' '</em>, <em>as_tuples=False</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.export_phrases" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate an iterator that contains all phrases in given ‘sentences’</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sentences</span> <span class="o">=</span> <span class="n">Text8Corpus</span><span class="p">(</span><span class="n">path_to_corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bigram</span> <span class="o">=</span> <span class="n">Phrases</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">phrase</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">bigram</span><span class="o">.</span><span class="n">export_phrases</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">u</span><span class="s1">&#39;</span><span class="si">{0}</span><span class="s1">   </span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">phrase</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

<span class="go">  then you can debug the threshold with generated tsv</span>
</pre></div>
</div>
</dd></dl>

<dl class="staticmethod">
<dt id="gensim.models.phrases.Phrases.learn_vocab">
<em class="property">static </em><code class="descname">learn_vocab</code><span class="sig-paren">(</span><em>sentences</em>, <em>max_vocab_size</em>, <em>delimiter='_'</em>, <em>progress_per=10000</em>, <em>common_terms=frozenset([])</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.learn_vocab" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect unigram/bigram counts from the <cite>sentences</cite> iterable.</p>
</dd></dl>

<dl class="classmethod">
<dt id="gensim.models.phrases.Phrases.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.load" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Load a previously saved Phrases class. Handles backwards compatibility from older Phrases versions which did not support</dt>
<dd>pluggable scoring functions. Otherwise, relies on utils.load</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phrases.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>fname_or_handle</em>, <em>separately=None</em>, <em>sep_limit=10485760</em>, <em>ignore=frozenset([])</em>, <em>pickle_protocol=2</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the object to file (also see <cite>load</cite>).</p>
<p><cite>fname_or_handle</cite> is either a string specifying the file name to
save to, or an open file-like object which can be written to. If
the object is a file handle, no special array handling will be
performed; all attributes will be saved to the same file.</p>
<p>If <cite>separately</cite> is None, automatically detect large
numpy/scipy.sparse arrays in the object being stored, and store
them into separate files. This avoids pickle memory errors and
allows mmap’ing large arrays back on load efficiently.</p>
<p>You can also set <cite>separately</cite> manually, in which case it must be
a list of attribute names to be stored in separate files. The
automatic check is not performed in this case.</p>
<p><cite>ignore</cite> is a set of attribute names to <em>not</em> serialize (file
handles, caches etc). On subsequent load() these attributes will
be set to None.</p>
<p><cite>pickle_protocol</cite> defaults to 2 so the pickled object can be imported
in both Python 2 and 3.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.Phrases.score_item">
<code class="descname">score_item</code><span class="sig-paren">(</span><em>worda</em>, <em>wordb</em>, <em>components</em>, <em>scorer</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.Phrases.score_item" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="gensim.models.phrases.SentenceAnalyzer">
<em class="property">class </em><code class="descclassname">gensim.models.phrases.</code><code class="descname">SentenceAnalyzer</code><a class="headerlink" href="#gensim.models.phrases.SentenceAnalyzer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="gensim.models.phrases.SentenceAnalyzer.analyze_sentence">
<code class="descname">analyze_sentence</code><span class="sig-paren">(</span><em>sentence</em>, <em>threshold</em>, <em>common_terms</em>, <em>scorer</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.SentenceAnalyzer.analyze_sentence" title="Permalink to this definition">¶</a></dt>
<dd><p>Analyze a sentence</p>
<p><cite>sentence</cite> a token list representing the sentence to be analyzed.</p>
<p><cite>threshold</cite> the minimum score for a bigram to be taken into account</p>
<p><cite>common_terms</cite> the list of common terms, they have a special treatment</p>
<p><cite>scorer</cite> the scorer function, as given to Phrases</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.phrases.SentenceAnalyzer.score_item">
<code class="descname">score_item</code><span class="sig-paren">(</span><em>worda</em>, <em>wordb</em>, <em>components</em>, <em>scorer</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.SentenceAnalyzer.score_item" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="gensim.models.phrases.npmi_scorer">
<code class="descclassname">gensim.models.phrases.</code><code class="descname">npmi_scorer</code><span class="sig-paren">(</span><em>worda_count</em>, <em>wordb_count</em>, <em>bigram_count</em>, <em>len_vocab</em>, <em>min_count</em>, <em>corpus_word_count</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.npmi_scorer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="gensim.models.phrases.original_scorer">
<code class="descclassname">gensim.models.phrases.</code><code class="descname">original_scorer</code><span class="sig-paren">(</span><em>worda_count</em>, <em>wordb_count</em>, <em>bigram_count</em>, <em>len_vocab</em>, <em>min_count</em>, <em>corpus_word_count</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.original_scorer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="gensim.models.phrases.pseudocorpus">
<code class="descclassname">gensim.models.phrases.</code><code class="descname">pseudocorpus</code><span class="sig-paren">(</span><em>source_vocab</em>, <em>sep</em>, <em>common_terms=frozenset([])</em><span class="sig-paren">)</span><a class="headerlink" href="#gensim.models.phrases.pseudocorpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Feeds source_vocab’s compound keys back to it, to discover phrases</p>
</dd></dl>

</div>


          </div>
        </div>
      

      <div class="clearer"></div>
    </div>
    

    
    <div id="footer">
      <div id="footerwrapper">
        <div id="footerleft">
          <img src="../_static/images/logo-gensim.png" class="smallerlogo" alt="smaller gensim logo" />
          <a href="../index.html"><img src="../_static/images/gensim-footer.png" alt="gensim footer image" title="Gensim home" /></a>

          <div class="copyright">
            &copy; Copyright 2009-now, <a href="mailto:radimrehurek@seznam.cz" style="color:white"> Radim Řehůřek</a>
            <br />
              Last updated on Nov 06, 2017.
          </div>
        </div>

        <div id="footermiddleright">
          <div id="footermiddle">
            <ul class="navigation">
              <li><a href="../index.html">
                Home
              </a></li>
              <li>|</li>
              <li><a href="../tutorial.html">
                Tutorials
              </a></li>
              <li>|</li>
              <li><a href="../install.html">
                Install
              </a></li>
              <li>|</li>
              <li><a href="../support.html">
                Support
              </a></li>
              <li>|</li>
              <li><a href="../apiref.html">
                API
              </a></li>
              <li>|</li>
              <li><a href="../about.html">
                About
              </a></li>
            </ul>

            <div class="tweetodsazeni">
              <div class="tweet">
                <a href="https://twitter.com/radimrehurek" target="_blank" style="color: white">Tweet @RadimRehurek</a>
              </div>
            </div>

          </div>

          <div id="footerright">
            <div class="footernadpis">
              Support:
            </div>
            <div class="googlegroupsodsazeni">
              <a href="https://groups.google.com/group/gensim" class="googlegroups">
                Stay informed via gensim mailing list:
              </a>

              <form action="http://groups.google.com/group/gensim/boxsubscribe">
                <input type="text" name="email" placeholder="your@email.com" size="28" />
                <input type="submit" name="sub" value="Subscribe" />
              </form>

            </div>

            <div class="addthis_toolbox addthis_default_style addthis_32x32_style"
                addthis:title="#gensim"
                addthis:description="Efficient Topic Modelling in Python"
                style="margin:20px 0 0 0">
              <a class="addthis_button_preferred_1"></a>
              <a class="addthis_button_preferred_2"></a>
              <a class="addthis_button_preferred_3"></a>
              <a class="addthis_button_preferred_4"></a>
              <a class="addthis_button_compact"></a>
              <a class="addthis_counter addthis_bubble_style"></a>
            </div>
          </div>

        </div>
      </div>
    </div>
    

    <script type="text/javascript">
      (function() {
      var at = document.createElement('script'); at.type = 'text/javascript'; at.async = true;
      at.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 's7.addthis.com/js/250/addthis_widget.js#pubid=ra-4d738b9b1d31ccbd';
      var sat = document.getElementsByTagName('script')[0]; sat.parentNode.insertBefore(at, sat);
      })();
    </script>

  </body>
</html>