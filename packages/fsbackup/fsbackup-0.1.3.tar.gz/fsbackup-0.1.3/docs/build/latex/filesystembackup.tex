%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional\else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
\fi\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}

\usepackage{geometry}
\usepackage{multirow}
\usepackage{eqparbox}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{filesystem backup Documentation}
\date{Nov 09, 2017}
\release{0.1.2}
\author{Miguel Garcia}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{Overview}
\label{\detokenize{index:module-fsbackup-multi-volume-backup-for-large-filesystems}}\label{\detokenize{index:overview}}
A command-line script in Python is provided, to manage backups for large filesystems in multiple external disks.

It is intended as a minimalist system, to get the job done but with no GUI or other niceties. At least not yet!
I just wanted to sleep well at night.


\section{Motivation}
\label{\detokenize{index:motivation}}

\subsection{The Problem}
\label{\detokenize{index:the-problem}}
For more than a decade I had being gathering content and
storing it in external drives.
For backup purposes I used to buy them in pairs, so that one would work as the other's mirror.
Of course the solution was far from ideal, there were tv-series, movies, and documentaries in most disks,
sparsed pretty much randomly, and when the number of disks reached 15 (plus backups) even finding content was a pain.
I had simple text files with the file contents of each disk, which needed to be updated, etc.


\subsection{An Improvement}
\label{\detokenize{index:an-improvement}}
A friend talked to me about a NAS he had recently acquired. After little consideration I realized I had been needing
one myself for a long time, just did not know such a thing existed. Taking into account the size of the files I already had,
plus reasonable mid-term foreseable needs, I bought a 6-slots NAS and put 8GB disks in it (5 of them currently).

Now the content was neatly organised, easy to find and maintain.

I was using RAID5, which is nice, but in several forums I found the clear warning
that \sphinxhref{https://serverfault.com/questions/2888/why-is-raid-not-a-backup}{RAID does not work as backup}, so I started worring.
I had the need of a real backup, and a bunch of external drives which content was already in the NAS.
Obviously they might be used to backup content, but I could not bring myself to even try to micro-manage it.
It would be particularly hard because some folders are way bigger that the external drives, so they would have to be split manually.


\section{Backup System Overview}
\label{\detokenize{index:backup-system-overview}}
The idea behind the implementation of \sphinxstylestrong{fsbackup} is pretty simple, and everything gets done by the \sphinxcode{fsbck} command.
Given a list of one or more paths that we want backed-up, the backup system works in three stages.


\subsection{Stage 1}
\label{\detokenize{index:stage-1}}
A command (intended to be scheduled nightly) keeps a collection in a \sphinxhref{https://www.mongodb.com/}{mongoDB} database updated with
the absolute path, size, last modification timestamp and a hash function (currently SHA-256) of each file in that list of paths.
They are interpreted as file-trees, so all the content buried in those paths is included.
It can be done with something like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{refreshHashes} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{n}{conn\PYGZus{}multimedia}\PYG{o}{.}\PYG{n}{json}
\end{sphinxVerbatim}

Only new files, or files with a more recent modification timestamp than the one in the database have their hash function recalculated
(since it is really time-consuming). As you might have guessed, the \sphinxcode{db} argument refers
to a \sphinxhref{https://en.wikipedia.org/wiki/JSON}{json} file with information regarding the location
of the filesystem, as well as mongoDB collections where the information is stored.


\subsection{Stage 2}
\label{\detokenize{index:stage-2}}
External hard disks work as backup volumes, containing files renamed with their hash function. The folder structure in the original filesystem
is not replicated, all files are at root level. Except that, using git-style, they are divided in folders according to the first
letters in the hash, to avoid having thousands of files in the same directory.

In order to update the backup, we can mount a disk that works as backup volume (say, it is in G:), and run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{processDrive} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{n}{conn\PYGZus{}multimedia}\PYG{o}{.}\PYG{n}{json} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{n}{G}
\end{sphinxVerbatim}

This action:
\begin{itemize}
\item {} 
Removes from the volume files that are not necessary anymore.

\item {} 
Copies new files that were not backed-up yet.

\item {} 
Provides a backup status report, with:
\begin{itemize}
\item {} 
the number of files/size pending backup (if there was not enough room in that volume).

\item {} 
a summary of the number of files/size in each volume.

\item {} 
a file per volume is created with the detailed absolute paths of each file backed-up in it.

\end{itemize}

\end{itemize}

For this to work properly, another collection in the database stores the hashes backed in each volume.


\subsection{Stage 3}
\label{\detokenize{index:stage-3}}
If/when the time comes information needs to be retrieved from the volumes, the script handles that as well. For instance, the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{checkout} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{n}{conn\PYGZus{}multimedia}\PYG{o}{.}\PYG{n}{json} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{n}{G} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{sourcepath}\PYG{o}{=}\PYG{o}{/}\PYG{o}{/}\PYG{n}{Zeycus}\PYG{o}{/}\PYG{n}{multimedia}\PYG{o}{/}\PYG{n}{movies} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{destpath}\PYG{o}{=}\PYG{n}{F}\PYG{p}{:}\PYGZbs{}\PYG{n}{chekouts}\PYGZbs{}\PYG{n}{movies}
\end{sphinxVerbatim}

recovers the relevant information in the actual (G:) volume for a particular folder. In a worst-case scenario, to recover all the files
you'd have to do this for every volume.


\section{So, how do I start?}
\label{\detokenize{index:so-how-do-i-start}}
In a nutshell:
\begin{enumerate}
\item {} 
Get a mongoDB server connection and create a database there. It could be local, mongoDB hosting (like \sphinxhref{https://mlab.com/}{mlab} , just to name one), etc.

\item {} 
Build a JSON config\_file for the filesystem you want backed-up. For instance:

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{n+nt}{\PYGZdq{}connstr\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}mongodb://myuser:mypwd@ds21135.mlab.com:34562/fsbackup\PYGZus{}tvs761\PYGZus{}main\PYGZdq{}}\PYG{p}{,}
  \PYG{n+nt}{\PYGZdq{}paths\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{}ZEYCUS\PYGZhy{}TVS671\PYGZbs{}\PYGZbs{}Multimedia\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{}ZEYCUS\PYGZhy{}TVS671\PYGZbs{}\PYGZbs{}Resources\PYGZdq{}}
  \PYG{p}{]}\PYG{p}{,}
  \PYG{n+nt}{\PYGZdq{}reportpref\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}F:\PYGZbs{}\PYGZbs{}Dropbox\PYGZbs{}\PYGZbs{}fsbackup\PYGZbs{}\PYGZbs{}reports\PYGZbs{}\PYGZbs{}main\PYGZus{}\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

where \sphinxcode{connstr} is the conection string to your mongoDB database (in this case, \sphinxcode{fsbackup\_tvs761\_main}). More details in the documentation.
Make sure the path in \sphinxcode{reportpref} actually exists, reporting files are created there. In this case,
\sphinxcode{F:\textbackslash{}\textbackslash{}Dropbox\textbackslash{}\textbackslash{}fsbackup\textbackslash{}\textbackslash{}reports}.
\begin{enumerate}
\setcounter{enumi}{2}
\item {} 
Create the actual collections in the database with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{createDatabase} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{force}
\end{sphinxVerbatim}

\item {} 
Gather the current filesystem information with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{refreshHashes} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\end{enumerate}

The first time hashes are calculated for all files, so this may take \sphinxstylestrong{long}.
\begin{enumerate}
\setcounter{enumi}{4}
\item {} 
Connect a formated external drive. Assuming it gets mounted in \sphinxcode{driveLetter}, execute:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{processDrive} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{driveLetter}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\end{enumerate}

This fills the volume with backup data. When finished, a message will clarify whether more volumes are needed to go on
with the backup.


\section{Collaboration}
\label{\detokenize{index:collaboration}}
You may wish to improve or add features, in that case you are more than welcome, feel free to contact me at \sphinxhref{mailto:zeycus@gmail.com}{zeycus@gmail.com}.


\chapter{Database Structure}
\label{\detokenize{index:database-structure}}
Information regarding the filesystem to be backed-up, and the current content
of volumes, is stored in a \sphinxhref{https://www.mongodb.com/}{mongoDB} database.


\section{Filesystem}
\label{\detokenize{index:filesystem}}
The collection that stores the information about the files currently in the filesystem is (uninspiredly!) named \sphinxcode{files}.
The entries/documents in it have the form:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZus{}id}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{ObjectId}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{59e0a71c2afc32cfc4e7fa48}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{filename}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+sa}{r}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s+s2}{ZEYCUS\PYGZhy{}TVS671}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{Multimedia}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{video}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{animePlex}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{Shin Chan}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{Season 01}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{Shin Chan \PYGZhy{} S01E613.mp4}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hash}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{4a7facfe42e8ff8812f9cab058bf79981974d9e2e300d56217d675ec5987cf05}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{timestamp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1197773340}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{size}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{68097104}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

where:
\begin{itemize}
\item {} 
The \sphinxcode{filename} field is the absolute path of the file.

\item {} 
The \sphinxcode{hash} field is the SHA-256 hash of the file.

\item {} 
\sphinxcode{timestamp} is the file's last-modified timestamp.

\item {} 
\sphinxcode{size} is the size of the file in bytes, obtained with \sphinxcode{os.stat(fn).st\_mtime}.

\end{itemize}

The fields used for look-up are \sphinxcode{filename} and \sphinxcode{hash}, so the collection should have an index on each of them.
The one on \sphinxcode{filename} should have \sphinxcode{unique=True}, to ensure no filename is added twice %
\begin{footnote}[2]\sphinxAtStartFootnote
This is not true for \sphinxcode{hash}, because we need to be able to backup systems that contain the same file in different locations.
I was surprised to find that I had about a 5\% of file redundancy in number of files, it turned out that some tiny files were necessary in many locations.
%
\end{footnote} .

The class that manages this collection is {\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxcode{FileDB}}}}.


\section{Volumes}
\label{\detokenize{index:volumes}}
On the other hand, the present state of backup volumes is stored in the collection \sphinxcode{volumes},
with entries like

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZus{}id}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{ObjectId}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{59e484603e12972bd4209fbe}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{volume}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{3EC0BECC}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hash}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{0017eef276f4247807fa3f4e565b8c925a2db0f8bfbb020248ad6c3df6a6ea77}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{size}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{97092}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

where:
\begin{itemize}
\item {} 
The \sphinxcode{volume} is the volume SerialNumber.

\item {} 
The \sphinxcode{hash} field is the SHA-256 hash of the file.

\item {} 
\sphinxcode{size} is the size of the file in bytes.

\end{itemize}

This entry is saying that volume 3EC0BECC contains a file with the given hash, and filesize 97,092 bytes.

There should be a a unique index on field \sphinxcode{hash} %
\begin{footnote}[1]\sphinxAtStartFootnote
In fact, this enforces that only one volume may contain a file with a specific hash. If the backup
methods are working correctly this should be the case. If the same file is found in different
folders in the filesystem, or with different names, no space is wasted and just one copy will
be present in backup volumes.
%
\end{footnote} .

The methods that add/remove files from a volume (see class {\hyperref[\detokenize{index:fsbackup.hashVolume.HashVolume}]{\sphinxcrossref{\sphinxcode{HashVolume}}}})
also update this collection, so that it remains up-to-date.


\chapter{Volume Content}
\label{\detokenize{index:volume-content}}
Volumes contain backups of the files in the filesystem: files with the same content. However, they are renamed with the hash of the content.
This means that no information regarding the filename in the real filesystem, or the path where it is located, can be found in the volumes (that information is stored in the \sphinxcode{files} collection in the database).
All the files in the volume are placed in the root of the filesystem, but classified with their first 3 letters to avoid the problems associated with having too many files in the same folder.
An actual volume looks like this:
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{volume_screenshot}.png}
\caption{Content of a backup volume.}\label{\detokenize{index:id8}}\end{figure}


\chapter{Filesystem config files}
\label{\detokenize{index:filesystem-config-files}}
The information about filesystems that we want backed-up is gathered in JSON files,
one per filesystem. For instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{n+nt}{\PYGZdq{}connstr\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}mongodb://myuser:mypwd@ds21135.mlab.com:34562/fsbackup\PYGZus{}tvs761\PYGZus{}main\PYGZdq{}}\PYG{p}{,}
  \PYG{n+nt}{\PYGZdq{}paths\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{}ZEYCUS\PYGZhy{}TVS671\PYGZbs{}\PYGZbs{}Multimedia\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}\PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{}ZEYCUS\PYGZhy{}TVS671\PYGZbs{}\PYGZbs{}Resources\PYGZdq{}}
  \PYG{p}{]}\PYG{p}{,}
  \PYG{n+nt}{\PYGZdq{}reportpref\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}F:\PYGZbs{}\PYGZbs{}Dropbox\PYGZbs{}\PYGZbs{}fsbackup\PYGZbs{}\PYGZbs{}reports\PYGZbs{}\PYGZbs{}main\PYGZus{}\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

The information is as follows:
\begin{description}
\item[{\sphinxcode{connstr}}] \leavevmode
The connection string to the mongoDB database.

\item[{\sphinxcode{paths}}] \leavevmode
The list of paths in the filesystem that we want backed-up. So far I've been using absolute paths myself,
but I think that paths relative to the location of the config file work as well. But I have not tested
it that heavily.

\item[{\sphinxcode{reportpref}}] \leavevmode
Prefix for reports. All files created by the \sphinxcode{backupStatus} command are created with that prefix.

\end{description}


\chapter{Detailed command usage}
\label{\detokenize{index:detailed-command-usage}}
Everything works via the \sphinxcode{fsbck} command. If the installation is correct, it should be available no matter what the active directory is.
In this section, the basic usage is shown, but the full detail and optional parameters can be found in {\hyperref[\detokenize{index:module-fsbackup.commands}]{\sphinxcrossref{\sphinxcode{commands}}}} module documentation.


\section{Database Creation}
\label{\detokenize{index:database-creation}}
It is achieved with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{createDatabase} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

If the database containing the two necessary collections \sphinxcode{files} and \sphinxcode{volumes} do not exist, they are created.
Otherwise the execution fails. If you want it rebuild, add the \sphinxcode{-{-}force} flag.


\section{Create reports for backup status}
\label{\detokenize{index:create-reports-for-backup-status}}
With:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{backupStatus} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

several text files are created (with different level of detail) regarding the status of the backup:
\begin{itemize}
\item {} 
size and number of files in each backup volume

\item {} 
size and number of files not yet backed-up

\item {} 
size and number of files in the volumes than are no longer necessary

\item {} 
explicit list of files in each volume

\end{itemize}

An example of the files created:
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{reportfiles_screenshot}.png}
\caption{Files created by \sphinxcode{backupStatus}.}\label{\detokenize{index:id9}}\end{figure}

Contrary to what it might seem, this operation is fairly quick.


\section{Database \sphinxstyleliteralintitle{files} update}
\label{\detokenize{index:database-files-update}}
This command updates the database information to match the current state of the filesystem.
If files are modified their hash is recalculated, if files were removed their entries are eliminated from
the database, and new files require new entries.

This is achieved with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{refreshHashes} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

For large filesystems the calculation of hashes is time-consuming. The first calculation for my NAS took nearly
a whole week, so I prefer to perform this process dayly, in scheduled task at night,
and a \sphinxcode{backupStatus} immediatly after it.


\section{Volume update}
\label{\detokenize{index:volume-update}}
This is the way content gets actually backed-up. Suppose you have a volume with available space on it, or if you are going to create
a new volume, just a formated external drive. When connected, it is assigned a drive letter, say J: %
\begin{footnote}[3]\sphinxAtStartFootnote
I realize this is terribly Windows-oriented. For linux systems it would be rather similar, if/when Linux support is provided this documentation should be improved.
%
\end{footnote} . Then
to perform the update use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{updateVolume} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{n}{J}
\end{sphinxVerbatim}

New files are added to the volume, until it is full or all of them are processed, a text message tells which of the two.

\begin{sphinxadmonition}{warning}{Warning:}
Be sure that the \sphinxcode{files} information is updated (via command \sphinxcode{refreshHashes}) before invoking a volume update. Otherwise, when the script tries to copy a file that the database is mentioning, it might not be physically there anymore, and thus exceptions would arise. There is no problem, however, if the only difference is that new files were created.
\end{sphinxadmonition}


\section{Volume clensing}
\label{\detokenize{index:volume-clensing}}
When you remove files from your backed-up filesystem, copies of them remain in backup volumes. There is no harm in it,
just the waste of space. As time passes, the wasted space in volumes could amount to something. With:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{cleanVolume} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{driveLetter}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

the files in the volume than are not shown as necessary by the database are removed.


\section{Volume processing}
\label{\detokenize{index:volume-processing}}
In the first days, when I wanted to update a volume I found myself always performing:
\begin{enumerate}
\item {} 
volume clensing

\item {} 
volume update

\item {} 
backuptatus reports regeneration

\end{enumerate}

I created a batch, but after a while I decided an additional command was in order to do it all: \sphinxcode{processDrive}. With:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{processDrive} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{driveLetter}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

those three tasks are performed. This keeps the volumes clean of old files, the system fully updated and the status reports
reflecting the current backup status.

In a day-to-day basis this is almost the only command you need (if the \sphinxcode{refreshHashes} is taken care of by an scheduled task).
Of course, you could manually run \sphinxcode{refreshHashes} before processing a drive, just to make sure the database is up-to-date.


\section{Information recovery from volumes}
\label{\detokenize{index:information-recovery-from-volumes}}
All the burden of keeping the filesystem updated has a single purpose: to be able to recover content from the backup volumes
when necessary. This operation may be infrequent, but it is arguably the most important. It is currently performed with the
\sphinxcode{checkout} command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{updateVolume} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{driveLetter}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{sourcepath}\PYG{o}{=}\PYGZbs{}\PYGZbs{}\PYG{n}{ZEYCUS}\PYG{o}{\PYGZhy{}}\PYG{n}{TVS671}\PYGZbs{}\PYG{n}{Multimedia}\PYGZbs{}\PYG{n}{video}\PYGZbs{}\PYG{n}{seriesPlex}\PYGZbs{}\PYG{n}{Monk} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{destpath}\PYG{o}{=}\PYG{n}{F}\PYG{p}{:}\PYGZbs{}\PYG{n}{temp}\PYGZbs{}\PYG{n}{Monk}
\end{sphinxVerbatim}

This process finds all the files in the volume that are a backup of a file in the given \sphinxcode{sourcepath} (or in a subfolder),
and copies them recreating the folder structure within the path \sphinxcode{destpath}.

Needless to say, to recover the whole folder content you need to process all the volumes containing at least one relevant file. It is possible to see which volumes
are involved by searching the backup-status report files. Or just process them all, it takes very little time if no content is necessary.


\section{Recalculation of Volume Information}
\label{\detokenize{index:recalculation-of-volume-information}}
The operations that add and remove files from the volume in same time update the database.
So, theoretically, the database is always up-to-date. I have not found a single case in which this was not the case,
but nevertheless implemented:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{extractVolumeInfo} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{driveLetter}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

What this does is to remove from the \sphinxcode{volumes} collection all the entries associated to the present volume, then
it is traversed and an entry is created for each actual file found.


\section{Volume Integrity Check}
\label{\detokenize{index:volume-integrity-check}}
In case we want to make sure that a backup volume is OK, we can perform an integrity check with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fsbck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{integrityCheck} \PYG{o}{\PYGZhy{}}\PYG{n}{db}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{config\PYGZus{}file}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{drive}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{driveLetter}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

This is a time consuming operation that actually compares each file of the volume with its counterpart in the actual filesystem
(if it was not deleted). For 3TB disks it is taking me over a day.

\begin{sphinxadmonition}{warning}{Warning:}
This is supposed to be done after a \sphinxcode{refreshHashes}. Otherwise the information in the DDBB might not reflect the actual state of the filesystem.
\end{sphinxadmonition}


\chapter{Observations}
\label{\detokenize{index:observations}}

\section{Volume identification}
\label{\detokenize{index:volume-identification}}
Volumes are not numbered, instead they are identified by a unique identifier. For now it is their filesystem \sphinxhref{https://en.wikipedia.org/wiki/Volume\_serial\_number}{volume serial number}.
This means you never need to process the volumes in any order, nor when you update them.

For instance, suppose you remove some huge files from your filesystem (who would want to see \sphinxstylestrong{THAT} tv-show again!?). As a consequence the backupstatus report
shows that a volume contains now 300GB of removable files. You could choose this volume for your next \sphinxcode{processDrive}: useless content will be dropped, making room and using it for fresh file backups.


\section{Volume content}
\label{\detokenize{index:id5}}
Files are not backed-up in any order. The system just aims to have each file backed-up in a (single) volume. This means content is more or less randomly
divided among volumes.


\chapter{Please, \sphinxstylestrong{be aware}!}
\label{\detokenize{index:please-be-aware}}
\begin{sphinxadmonition}{warning}{Warning:}
To be able to use mongoDB, we must have a connection to a mongoDB server. It could be our own machine, a hosting service, etc.
\end{sphinxadmonition}

If you are new to mongoDB, several tutorials are available, \sphinxhref{https://www.hongkiat.com/blog/webdev-with-mongodb-part1/}{this} is one of them. There are also many mongoDB-hosting services that provide free sandboxes with a decent size, no need to spend a dime just to experiment.

If you have mongoDB installed, to serve it locally (in Windows) just run:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mongod}\PYG{o}{.}\PYG{n}{exe} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{dbpath}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{database\PYGZus{}path}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}


\section{Regarding tests}
\label{\detokenize{index:regarding-tests}}
\begin{sphinxadmonition}{warning}{Warning:}
To be able to run tests, we need a mongoDB server to connect to (I know of no better way. If there is, please let me know). The tests are written assuming that a local server is running.
\end{sphinxadmonition}

Then, a client is created that connects to it, creates testing databases/collections, fills them, accesses information stored, and wipes them all in the end.


\section{Information safety}
\label{\detokenize{index:information-safety}}
The mongoDBs created are essential to be able to recover contents from the backup.

\begin{sphinxadmonition}{warning}{Warning:}
If they were lost, in the volumes you won't see proper filenames or extensions. Therefore although the content is indeed there, finding what you need would be, at the very least, awefully painful, if not utterly infeasable.
\end{sphinxadmonition}

For that reason it is reasonable to make sure the mongoDB databases are safe,
and backed-up as frequently and redundantly as possible. I am using mongoDB hosting, and keep a local copy as well. Even periodically storing a copy with its
timestamp might be interesting, if you want to play it safe.


\section{License}
\label{\detokenize{index:license}}
This software is released under MIT license, with no warranty implied or otherwise. That said, on the sunny side a unittest is included that performs the complete backup cycle and
makes sure that the checkout is identical to the original filesystem. And \sphinxcode{integrityCheck} command is available, which actually compares each backed-up file with its
counterpart in the filesystem.


\chapter{TODO}
\label{\detokenize{index:todo}}\begin{enumerate}
\item {} 
Currently only Windows is supported.

\end{enumerate}
\begin{description}
\item[{There are several aspects in this process than are very OS-dependent. For instance:}] \leavevmode\begin{itemize}
\item {} 
Copying files

\item {} 
The systax for absolute paths

\item {} 
Extraction of volume id

\end{itemize}

So far I had only Windows in mind, and even had to implement at least an ugly hack (to handle +260 chars absolute paths, which
surprisingly causes problems in Windows). I wish \sphinxcode{fsbackup} worked for Linux as well, at least, that is the very first thing I'd like to do.

\end{description}
\begin{enumerate}
\setcounter{enumi}{1}
\item {} 
It seems not all filesystems have volume serialNumber. For that reason it seems that using disk serial numbers instead might be an improvement.
I chose volume serialnumbers because it was easy to extract, while the drive serial number containing a volume seemed hard to get (Googled for a while,
found no easy path).

\item {} 
For now, the only way to retrieve information from the volumes is the \sphinxcode{checkout} command, which rebuilds a folder/subfolder recursively. However, it would be
easy to add filters to recover only files that match a given regular expression, or filter them for timestamp or other features, etc.

Truth be told, this kind of operation is what I implemented for the case in which something \sphinxstyleemphasis{goes wrong}: content was deleted unwantingly, or the disk just crashed.
Fortunately those events happen pretty rarely, so little effort was dedicated to the recovery of information.

\end{enumerate}


\chapter{Release History}
\label{\detokenize{index:release-history}}

\section{0.1.2 (2017-11-09)}
\label{\detokenize{index:id6}}
\sphinxstylestrong{Improvements}
\begin{itemize}
\item {} 
New safe file copy: deletes target file if the writting process failed.

\item {} 
New \sphinxquotedblleft{}How do I start?\sphinxquotedblright{} section in README.

\item {} 
New \sphinxquotedblleft{}Release History\sphinxquotedblright{}.

\item {} 
Replace deprecated pymongo collections \sphinxcode{remove} with \sphinxcode{delete\_many}.

\end{itemize}

\sphinxstylestrong{Bugfixes}
\begin{itemize}
\item {} 
Fixed typo in setup \sphinxcode{tests\_require} argument.

\end{itemize}


\section{0.1.1 (2017-11-05)}
\label{\detokenize{index:id7}}\begin{itemize}
\item {} 
First version made available

\end{itemize}


\chapter{Code documentation}
\label{\detokenize{index:code-documentation}}

\section{Main Commands Module}
\label{\detokenize{index:module-fsbackup.commands}}\label{\detokenize{index:main-commands-module}}\index{fsbackup.commands (module)}\phantomsection\label{\detokenize{index:module-commands}}\index{commands (module)}\index{backupStatus() (in module fsbackup.commands)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.commands.backupStatus}}\pysiglinewithargsret{\sphinxcode{fsbackup.commands.}\sphinxbfcode{backupStatus}}{\emph{fDB}, \emph{volDB}, \emph{reportPref}}{}
Generates the status report.
\begin{description}
\item[{Several files are created:}] \leavevmode\begin{itemize}
\item {} 
summary.txt: global summary.

\item {} 
missing.txt: list of files not yet backed-up.

\item {} 
content\_\textless{}vol\textgreater{}.txt: the list of files backed-up in each volume.

\end{itemize}

\end{description}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- the information regarding files

\item {} 
\sphinxstyleliteralstrong{volDB} (\sphinxstyleliteralemphasis{permanent-dict class}) -- the informating regarading volumes

\item {} 
\sphinxstyleliteralstrong{reportPref} (\sphinxstyleliteralemphasis{str}) -- prefix that tells where to create reporting

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{extractVolumeInfo() (in module fsbackup.commands)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.commands.extractVolumeInfo}}\pysiglinewithargsret{\sphinxcode{fsbackup.commands.}\sphinxbfcode{extractVolumeInfo}}{\emph{hashVol}}{}
Regenerates the DDBB information regarding the files contained in the present volume.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{hashVol} ({\hyperref[\detokenize{index:fsbackup.hashVolume.HashVolume}]{\sphinxcrossref{\sphinxstyleliteralemphasis{HashVolume}}}}) -- the information regarding volumes

\end{description}\end{quote}

\end{fulllineitems}

\index{cleanVolume() (in module fsbackup.commands)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.commands.cleanVolume}}\pysiglinewithargsret{\sphinxcode{fsbackup.commands.}\sphinxbfcode{cleanVolume}}{\emph{fDB}, \emph{hashVol}}{}
Removes files from the volume that are not necessary anymore.

Returns the number of deleted files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- the information regarding files

\item {} 
\sphinxstyleliteralstrong{hashVol} ({\hyperref[\detokenize{index:fsbackup.hashVolume.HashVolume}]{\sphinxcrossref{\sphinxstyleliteralemphasis{HashVolume}}}}) -- the information regarding volumes

\end{itemize}

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{updateVolume() (in module fsbackup.commands)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.commands.updateVolume}}\pysiglinewithargsret{\sphinxcode{fsbackup.commands.}\sphinxbfcode{updateVolume}}{\emph{fDB}, \emph{hashVol}}{}
Deletes useless files in the volume, and copies new files that need to be backed-up.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- the information regarding files

\item {} 
\sphinxstyleliteralstrong{hashVol} ({\hyperref[\detokenize{index:fsbackup.hashVolume.HashVolume}]{\sphinxcrossref{\sphinxstyleliteralemphasis{HashVolume}}}}) -- the information regarding volumes

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{refreshFileInfo() (in module fsbackup.commands)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.commands.refreshFileInfo}}\pysiglinewithargsret{\sphinxcode{fsbackup.commands.}\sphinxbfcode{refreshFileInfo}}{\emph{fDB}, \emph{forceRecalc}}{}
Updates the filename collection in the database, reflecting changes in the filesystem.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- the information regarding files

\item {} 
\sphinxstyleliteralstrong{forceRecalc} (\sphinxstyleliteralemphasis{bool}) -- flag that tells if hashes \& timestamps should be recalculated from the file always.
If False (the default), recalculation happens always when the timestamp of the file is more recent than that
in the database, or for new files. If True, we recalculate for every file.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{createDatabase() (in module fsbackup.commands)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.commands.createDatabase}}\pysiglinewithargsret{\sphinxcode{fsbackup.commands.}\sphinxbfcode{createDatabase}}{\emph{database}, \emph{forceFlag}, \emph{logger}}{}
Creates database collections from scratch.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- the information regarding files

\item {} 
\sphinxstyleliteralstrong{forceFlag} (\sphinxstyleliteralemphasis{bool}) -- tells whether to remove info, if collections already exist

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{integrityCheck() (in module fsbackup.commands)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.commands.integrityCheck}}\pysiglinewithargsret{\sphinxcode{fsbackup.commands.}\sphinxbfcode{integrityCheck}}{\emph{fDB}, \emph{hashVol}}{}
Performs an integrity check for the volume.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- the information regarding files

\item {} 
\sphinxstyleliteralstrong{hashVol} ({\hyperref[\detokenize{index:fsbackup.hashVolume.HashVolume}]{\sphinxcrossref{\sphinxstyleliteralemphasis{HashVolume}}}}) -- the information regarding volumes

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\section{Auxiliary Modules}
\label{\detokenize{index:auxiliary-modules}}

\subsection{Module \sphinxstyleliteralintitle{miscTools}}
\label{\detokenize{index:module-misctools}}\label{\detokenize{index:module-fsbackup.miscTools}}\index{fsbackup.miscTools (module)}\phantomsection\label{\detokenize{index:module-miscTools}}\index{miscTools (module)}\index{buildVolumeInfoList() (in module fsbackup.miscTools)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.miscTools.buildVolumeInfoList}}\pysiglinewithargsret{\sphinxcode{fsbackup.miscTools.}\sphinxbfcode{buildVolumeInfoList}}{\emph{container}}{}
Returns, for each volume, the association \{file-hash: file-size\}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{container} (\sphinxstyleliteralemphasis{MongoAsDict}) -- a MongoAsDict with the volume information

\item[{Return type}] \leavevmode
list of pairs (volId, \{sha:size\})

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Module \sphinxstyleliteralintitle{fileTools}}
\label{\detokenize{index:module-filetools}}\label{\detokenize{index:module-fsbackup.fileTools}}\index{fsbackup.fileTools (module)}\phantomsection\label{\detokenize{index:module-fileTools}}\index{fileTools (module)}\index{sizeof\_fmt() (in module fsbackup.fileTools)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileTools.sizeof_fmt}}\pysiglinewithargsret{\sphinxcode{fsbackup.fileTools.}\sphinxbfcode{sizeof\_fmt}}{\emph{num}, \emph{suffix='B'}}{}
Returns a human-readable string for a file size.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{num} (\sphinxstyleliteralemphasis{int}) -- size of the file, in units

\item {} 
\sphinxstyleliteralstrong{suffix} (\sphinxstyleliteralemphasis{str}) -- the unit. Use `B' for bytes, the default.

\end{itemize}

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

Stolen from:
\begin{quote}

\sphinxurl{http://stackoverflow.com/questions/1094841/reusable-library-to-get-human-readable-version-of-file-size}
\end{quote}

\end{fulllineitems}

\index{abspath2longabspath() (in module fsbackup.fileTools)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileTools.abspath2longabspath}}\pysiglinewithargsret{\sphinxcode{fsbackup.fileTools.}\sphinxbfcode{abspath2longabspath}}{\emph{abspath}}{}
Returns an absolute filepath than works for longer than 260 chars in Windows.

In Windows there is seems to be no support for paths longer than 260 chrs. Files that exist are not found, cannot
be open, etc. However, using this trick I seem to be able to access them.

Post with the trick description:
\begin{quote}

\sphinxurl{https://msdn.microsoft.com/en-us/library/aa365247.aspx\#maxpath}
\end{quote}

\end{fulllineitems}



\subsection{Module \sphinxstyleliteralintitle{diskTools}}
\label{\detokenize{index:module-disktools}}\label{\detokenize{index:module-fsbackup.diskTools}}\index{fsbackup.diskTools (module)}\phantomsection\label{\detokenize{index:module-diskTools}}\index{diskTools (module)}\index{genDrivesInfo() (in module fsbackup.diskTools)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.diskTools.genDrivesInfo}}\pysiglinewithargsret{\sphinxcode{fsbackup.diskTools.}\sphinxbfcode{genDrivesInfo}}{}{}
Generator for drives information.

\end{fulllineitems}

\index{genVolumesInfo() (in module fsbackup.diskTools)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.diskTools.genVolumesInfo}}\pysiglinewithargsret{\sphinxcode{fsbackup.diskTools.}\sphinxbfcode{genVolumesInfo}}{}{}
Generator for volumes information.

\end{fulllineitems}

\index{getVolumeInfo() (in module fsbackup.diskTools)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.diskTools.getVolumeInfo}}\pysiglinewithargsret{\sphinxcode{fsbackup.diskTools.}\sphinxbfcode{getVolumeInfo}}{\emph{driveLetter}}{}
Returns volume info for the given driveLetter.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{driveLetter} (\sphinxstyleliteralemphasis{str}) -- the drive letter, for instance `C'

\item[{Return type}] \leavevmode
dict

\end{description}\end{quote}

\end{fulllineitems}

\index{getAvailableLetter() (in module fsbackup.diskTools)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.diskTools.getAvailableLetter}}\pysiglinewithargsret{\sphinxcode{fsbackup.diskTools.}\sphinxbfcode{getAvailableLetter}}{}{}
Returns the first drive letter available.

\end{fulllineitems}



\section{Class \sphinxstyleliteralintitle{HashVolume}}
\label{\detokenize{index:module-fsbackup.hashVolume}}\label{\detokenize{index:class-hashvolume}}\index{fsbackup.hashVolume (module)}\phantomsection\label{\detokenize{index:module-hashVolume}}\index{hashVolume (module)}\index{HashVolume (class in fsbackup.hashVolume)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume}}\pysiglinewithargsret{\sphinxstrong{class }\sphinxcode{fsbackup.hashVolume.}\sphinxbfcode{HashVolume}}{\emph{logger}, \emph{locationPath}, \emph{container}, \emph{volId=None}}{}
Class that handles a backup volume.
\index{allVolumesHashes() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.allVolumesHashes}}\pysiglinewithargsret{\sphinxbfcode{allVolumesHashes}}{}{}
Returns the set of all hashes in any volume, according to the DDBB.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
set

\end{description}\end{quote}

\end{fulllineitems}

\index{augmentWithFiles() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.augmentWithFiles}}\pysiglinewithargsret{\sphinxbfcode{augmentWithFiles}}{\emph{fDB}}{}
Include in the volume backup for the files that need it.

It is done until all files are backed-up, on until the volume is full.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- filesystem information in DDBB.

\item[{Return type}] \leavevmode

a pair (isFinished, hashList)
\begin{itemize}
\item {} 
isFinished tells whether the backup is complete. It is False if there are still
files that are not backed-up in any volume.

\item {} 
hashList is the list of hashes of the created files.

\end{itemize}


\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}
The strategy to choose which file to backup next is the following, but there are no
strong reasons for this, it should be changed if another is found better.
\begin{itemize}
\item {} 
While there is plenty of room in the volume (threshold currently set to 20GB) and there is room
for the biggest file that requires backup, files are chosen randomly.
The reason is that usually there are folders with huge files, others with only tiny files.
If files were processed by their folder order, a volume could end up with millions
of small files, while another could contain just hundreds of heavy files. Not that it would
be a problem in principle, but I thought it might be better to balance volumes, and
a simple strategy is the random choice.

\item {} 
When the previous condition fails, choose the biggest file that fits, until none does.

\end{itemize}
\end{sphinxadmonition}

\end{fulllineitems}

\index{checkout() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.checkout}}\pysiglinewithargsret{\sphinxbfcode{checkout}}{\emph{fDB}, \emph{sourcePath}, \emph{destPath}}{}
Rebuilds the filesystem, or a subfolder, from the backup content.

Returns a list of the filenames (in the original filesystem) that were restored.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{fDB} ({\hyperref[\detokenize{index:fsbackup.fileDB.FileDB}]{\sphinxcrossref{\sphinxstyleliteralemphasis{FileDB}}}}) -- filesystem information in DDBB.

\item {} 
\sphinxstyleliteralstrong{sourcePath} (\sphinxstyleliteralemphasis{str}) -- path in the filesystem that you want restored

\item {} 
\sphinxstyleliteralstrong{destPath} (\sphinxstyleliteralemphasis{str}) -- location where you want the files created

\end{itemize}

\item[{Return type}] \leavevmode
list of str

\end{description}\end{quote}

\end{fulllineitems}

\index{cleanOldHashes() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.cleanOldHashes}}\pysiglinewithargsret{\sphinxbfcode{cleanOldHashes}}{\emph{totalHashesNeeded}}{}
Removes files that are no longer necessary.

Returns the number of files removed.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{totalHashesNeeded} (\sphinxstyleliteralemphasis{set}) -- hashes of files that need to be backed-up.

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{fnForHash() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.fnForHash}}\pysiglinewithargsret{\sphinxbfcode{fnForHash}}{\emph{sha}}{}
Returns the absolute path of the file for a given hash.

The first three letters in the hash are used to create a 3-levels folder system,
for instance hash \sphinxcode{4c07766937a4d241fafd3104426766f07c3ce9de7e577a76ad61eba512433cea}
corresponds to file
\begin{quote}

\sphinxcode{self.locationPath/4/c/0/4c07766937a4d241fafd3104426766f07c3ce9de7e577a76ad61eba512433cea}
\end{quote}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{sha} (\sphinxstyleliteralemphasis{str}) -- any valid SHA

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{getAvailableSpace() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.getAvailableSpace}}\pysiglinewithargsret{\sphinxbfcode{getAvailableSpace}}{}{}
Returns the available free space in the volume drive, in bytes.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{recalculateContainer() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.recalculateContainer}}\pysiglinewithargsret{\sphinxbfcode{recalculateContainer}}{}{}
Rebuilds the DDBB volume information, traversing the files in the volume.

\begin{sphinxadmonition}{note}{Note:}
This is something ordinarily you don't need to do, because the DDBB
is kept synchronized with the files in the volume. This method is to be used
in case for some reason the synchronization was broken.
\end{sphinxadmonition}

\end{fulllineitems}

\index{remove() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.remove}}\pysiglinewithargsret{\sphinxbfcode{remove}}{\emph{sha}}{}
Deletes the file with a given hash.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{sha} (\sphinxstyleliteralemphasis{str}) -- the given hash

\end{description}\end{quote}

\end{fulllineitems}

\index{retrieveFilename() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.retrieveFilename}}\pysiglinewithargsret{\sphinxbfcode{retrieveFilename}}{\emph{sha}, \emph{filename}}{}
Extracts a file from the volume, given its hash.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{sha} (\sphinxstyleliteralemphasis{str}) -- the given hash

\item {} 
\sphinxstyleliteralstrong{filename} (\sphinxstyleliteralemphasis{str}) -- the filename of the file to be created

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{storeFilename() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.storeFilename}}\pysiglinewithargsret{\sphinxbfcode{storeFilename}}{\emph{filename}, \emph{size}, \emph{sha=None}}{}
Creates a file in the volume.

The filename in the volume is the sha, not the original filename.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{filename} (\sphinxstyleliteralemphasis{str}) -- location of the original file

\item {} 
\sphinxstyleliteralstrong{size} (\sphinxstyleliteralemphasis{int}) -- size in bytes of the original file

\item {} 
\sphinxstyleliteralstrong{sha} -- the hash for the file. If not provided, it is calculated now

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{traverseFiles() (fsbackup.hashVolume.HashVolume method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.hashVolume.HashVolume.traverseFiles}}\pysiglinewithargsret{\sphinxbfcode{traverseFiles}}{}{}
Iterator over pairs (hash, size) for the present volume, checking which actual files are stored in it.

\end{fulllineitems}


\end{fulllineitems}



\section{Class \sphinxstyleliteralintitle{FileDB}}
\label{\detokenize{index:module-fsbackup.fileDB}}\label{\detokenize{index:class-filedb}}\index{fsbackup.fileDB (module)}\phantomsection\label{\detokenize{index:module-fileDB}}\index{fileDB (module)}\index{FileDB (class in fsbackup.fileDB)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileDB.FileDB}}\pysiglinewithargsret{\sphinxstrong{class }\sphinxcode{fsbackup.fileDB.}\sphinxbfcode{FileDB}}{\emph{logger}, \emph{fsPaths}, \emph{container}}{}
Class that handles the DDBB filesystem information.

Specifically, which files need to be backed-up, their location, size and hash.
\index{checkout() (fsbackup.fileDB.FileDB method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileDB.FileDB.checkout}}\pysiglinewithargsret{\sphinxbfcode{checkout}}{\emph{vol}, \emph{sourcePath}, \emph{destPath}}{}
Rebuilds the filesystem, or a subfolder, from the backup content.

We just invoke the chekout method of the volume.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{vol} ({\hyperref[\detokenize{index:fsbackup.hashVolume.HashVolume}]{\sphinxcrossref{\sphinxstyleliteralemphasis{HashVolume}}}}) -- the volume from which information is to be restored.

\item {} 
\sphinxstyleliteralstrong{sourcePath} (\sphinxstyleliteralemphasis{str}) -- path in the filesystem that you want restored

\item {} 
\sphinxstyleliteralstrong{destPath} (\sphinxstyleliteralemphasis{str}) -- location where you want the files created

\end{itemize}

\item[{Return type}] \leavevmode
list of str

\end{description}\end{quote}

\end{fulllineitems}

\index{hashesSet() (fsbackup.fileDB.FileDB method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileDB.FileDB.hashesSet}}\pysiglinewithargsret{\sphinxbfcode{hashesSet}}{}{}
Returns the set of hashes in the DDBB.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
set

\end{description}\end{quote}

\end{fulllineitems}

\index{reportStatusToFile() (fsbackup.fileDB.FileDB method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileDB.FileDB.reportStatusToFile}}\pysiglinewithargsret{\sphinxbfcode{reportStatusToFile}}{\emph{volHashesInfo}, \emph{fnBase}}{}
Creates backup-status report files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{volHashesInfo} (\sphinxstyleliteralemphasis{dict \{vol: \{hash: size\}\}}) -- for each volume, associates the hash of each file with its size.

\item {} 
\sphinxstyleliteralstrong{fnBase} (\sphinxstyleliteralemphasis{str}) -- prefix of the report files to be created

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{update() (fsbackup.fileDB.FileDB method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileDB.FileDB.update}}\pysiglinewithargsret{\sphinxbfcode{update}}{\emph{forceRecalc=False}}{}
Updates the DDBB info traversing the actual filesystem.

After execution, the DDBB reflects exactly the files currently in the filesystem,
with their correct hash and size.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{forceRecalc} (\sphinxstyleliteralemphasis{bool}) -- flag that tells if hashes \& timestamps should be recalculated from the file always.
If \sphinxcode{False} (the default), recalculation happens only when the timestamp of the file is more recent than that
in the database, or for new files. If \sphinxcode{True}, recalculation takes place for every file.

\end{description}\end{quote}

\end{fulllineitems}

\index{volumeIntegrityCheck() (fsbackup.fileDB.FileDB method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.fileDB.FileDB.volumeIntegrityCheck}}\pysiglinewithargsret{\sphinxbfcode{volumeIntegrityCheck}}{\emph{vol}}{}
Performs a volume integrity check.

For each file that according to the DDBB is in this volume, a full comparison
is performed between the file in the filesystem and the file in the backup volume.
Of course, only when the file exists yet in the filesystem.

A final report with errors is generated, a list of errors returned.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{vol} ({\hyperref[\detokenize{index:fsbackup.hashVolume.HashVolume}]{\sphinxcrossref{\sphinxstyleliteralemphasis{HashVolume}}}}) -- the volume from which information is to be restored.

\item[{Return type}] \leavevmode
list of str

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Class \sphinxstyleliteralintitle{MountPathInDrive}}
\label{\detokenize{index:class-mountpathindrive}}\label{\detokenize{index:module-fsbackup.mountPathInDrive}}\index{fsbackup.mountPathInDrive (module)}\phantomsection\label{\detokenize{index:module-mountPathInDrive}}\index{mountPathInDrive (module)}\index{MountPathInDrive (class in fsbackup.mountPathInDrive)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{index:fsbackup.mountPathInDrive.MountPathInDrive}}\pysiglinewithargsret{\sphinxstrong{class }\sphinxcode{fsbackup.mountPathInDrive.}\sphinxbfcode{MountPathInDrive}}{\emph{path}, \emph{driveLetter}}{}
Simple context manager for temporaly mounting a path in a Windows drive.

Usage example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{with} \PYG{n}{MountPathInDrive}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+sa}{r}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F:}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{sources}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{driveLetter}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{J}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{print}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{listdir}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{J:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}



\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{c}
\item {\sphinxstyleindexentry{commands}}\sphinxstyleindexextra{Windows}\sphinxstyleindexpageref{index:\detokenize{module-commands}}
\indexspace
\bigletter{d}
\item {\sphinxstyleindexentry{diskTools}}\sphinxstyleindexextra{Windows}\sphinxstyleindexpageref{index:\detokenize{module-diskTools}}
\indexspace
\bigletter{f}
\item {\sphinxstyleindexentry{fileDB}}\sphinxstyleindexextra{Windows}\sphinxstyleindexpageref{index:\detokenize{module-fileDB}}
\item {\sphinxstyleindexentry{fileTools}}\sphinxstyleindexextra{Windows}\sphinxstyleindexpageref{index:\detokenize{module-fileTools}}
\item {\sphinxstyleindexentry{fsbackup.commands}}\sphinxstyleindexpageref{index:\detokenize{module-fsbackup.commands}}
\item {\sphinxstyleindexentry{fsbackup.diskTools}}\sphinxstyleindexpageref{index:\detokenize{module-fsbackup.diskTools}}
\item {\sphinxstyleindexentry{fsbackup.fileDB}}\sphinxstyleindexpageref{index:\detokenize{module-fsbackup.fileDB}}
\item {\sphinxstyleindexentry{fsbackup.fileTools}}\sphinxstyleindexpageref{index:\detokenize{module-fsbackup.fileTools}}
\item {\sphinxstyleindexentry{fsbackup.hashVolume}}\sphinxstyleindexpageref{index:\detokenize{module-fsbackup.hashVolume}}
\item {\sphinxstyleindexentry{fsbackup.miscTools}}\sphinxstyleindexpageref{index:\detokenize{module-fsbackup.miscTools}}
\item {\sphinxstyleindexentry{fsbackup.mountPathInDrive}}\sphinxstyleindexpageref{index:\detokenize{module-fsbackup.mountPathInDrive}}
\indexspace
\bigletter{h}
\item {\sphinxstyleindexentry{hashVolume}}\sphinxstyleindexextra{Windows}\sphinxstyleindexpageref{index:\detokenize{module-hashVolume}}
\indexspace
\bigletter{m}
\item {\sphinxstyleindexentry{miscTools}}\sphinxstyleindexextra{Windows}\sphinxstyleindexpageref{index:\detokenize{module-miscTools}}
\item {\sphinxstyleindexentry{mountPathInDrive}}\sphinxstyleindexextra{Windows}\sphinxstyleindexpageref{index:\detokenize{module-mountPathInDrive}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}