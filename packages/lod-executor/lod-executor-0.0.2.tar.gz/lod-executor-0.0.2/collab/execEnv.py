import collections
import datetime
import dateutil.parser
import docker
import json
import logging
import os
import requests
import shutil
import sys
import threading
import time

from .exceptions import ProgrammerFuckedUp
from . import basics
from . import utilities


###############################################################################################
# helper classes
###############################################################################################


class CurrentlyDisplayedStatus:
    """
    Context manager for changing the current status of an ExecEnv object.
    """
    def __init__(self, exec_env, msg):
        self.exec_env = exec_env
        self.msg = msg
    def __enter__(self):
        with self.exec_env.lock:
            self.old_msg = self.exec_env.current_status_message
            self.exec_env.current_status_message = self.msg
    def __exit__(self, etype, value, traceback):
        with self.exec_env.lock:
            self.exec_env.current_status_message = self.old_msg


###############################################################################################
# helper functions
###############################################################################################


_SOURCE_OF_TRUTH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'TRUTH.txt')
_truth = None
def _get_truth():
    """
    load constants from a file that is autogenerated from the outside when this module is compiled.
    This is a convenient way to share constants between different applications during development.
    Uses a cache.
    """
    global _truth
    if _truth is None:
        with open(_SOURCE_OF_TRUTH, 'r') as f:
            _truth = json.load(f)
    return _truth

def _get_json_encoding_of_server():
    """
    get the type of encoding that the server uses for encoding JSON strings
    """
    res = _get_truth()['json_encoding']
    return res


###############################################################################################
# helper functions - folders
###############################################################################################


def get_step_folder(execution_id, step_num):
    """
    return the path representing the folder of a given step of a given execution
    """
    return os.path.join(_the_manager.root_folder, 'exec%d/step%d' % (execution_id, step_num))


def get_step_explanation_file_in(execution_id, step_num):
    """
    return the path to the txt file that describes the input used for an execution step, which can be read by the program being executed.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'in.txt')


def get_step_explanation_file_out(execution_id, step_num):
    """
    return the path to the txt file that describes the output generated by an execution step, which should be created by the program being executed.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'out.txt')


def get_step_file_in(execution_id, step_num, arg_name):
    """
    return the path to the file of a given object used as input in a given step of a given execution
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'arg_%s' % (arg_name,))


def get_step_file_out(execution_id, step_num, file_index):
    """
    return the path to the file of a given object used as output in a given step of a given execution
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'out_%d' % (file_index,))


def get_step_file_error(execution_id, step_num):
    """
    return the path to the error file created by a program execution, if one exists.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'error.txt')


def get_step_file_parsing_error(execution_id, step_num):
    """
    return the path to the error file created after a program execution if the parsing of that step's output failed, if one exists.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'output_parsing_error.txt')


def get_step_file_log(execution_id, step_num):
    """
    return the path to the lig file of a program execution, if one exists.
    """
    path = get_step_folder(execution_id, step_num)
    return os.path.join(path, 'log.txt')


###############################################################################################
# helper functions - Docker
###############################################################################################


def get_docker_client(version='auto'):
    return docker.from_env(version=version)


def generate_container_name(execution_id, step_num):
    """
    generates a unique name to be used for the container of an execution
    """
    res = "exec-%d-step-%d" % (execution_id, step_num)
    return res


def check_if_container_is_active(container_name):
    """
    returns a boolean indicating whether or not a RUNNING container of the given name exists.
    TODO:
    this functions is a crutch. Theoretically, the field container.status should just tell us the status.
    But it seems to be bugged.
    So I use the console to figure out the status instead.
    """
    cmd = ['docker', 'ps', '--no-trunc', '--filter', 'name=^/%s$' % container_name]
    res = utilities.execute_terminal_command(cmd, get_output=True)
    res = (container_name in res)
    return res


def execute_image(exec_env, image_name, path, execution_id, step_num, max_execution_duration):
    """
    executes an existing Docker Image, optionally giving it access to a path to read and write from/to.
    The path should be specified in its entirety, not as a relative path.
    Instead of specifying the path directly, the ID of the execution (execution) and the number of the step within that execution (step) can be given,
    in which case the path is constructed from these parameters and the _the_manager.root_folder.
    Takes an optional time limit, measured in seconds.
    returns an error type as a string (or None if the program executed successfully), along with an error message.
    """
    # prepare parameters
    if path is None and execution_id is not None and step_num is not None:
        path = get_step_folder(execution_id, step_num)
    # connect to Docker
    client = get_docker_client()
    # define the folder mapping
    folder_mapping = {
        path : {
            'bind' : "/collab",
            'mode' : 'rw',
        },
    }
    # give the container a name
    container_name = generate_container_name(execution_id, step_num)
    # verify that a container with this name doesn't already exist
    # (this is mostly for debugging)
    try:
        client.containers.get(container_name)
        DebugFriendlyException("this container already exists:\n%s" % container_name)
    except docker.errors.NotFound:
        pass
    # run the container in detached mode
    try:
        client.images.get(image_name)
    except docker.errors.ImageNotFound:
        with CurrentlyDisplayedStatus(exec_env, "pulling image %s" % image_name):
            client.images.pull(image_name)
    with CurrentlyDisplayedStatus(exec_env, "starting container %s of image %s" % (container_name, image_name)):
        container = client.containers.run(image=image_name, volumes=folder_mapping, name=container_name, detach=True)
        # wait until either the time runs out or the container stops on its own or an external interrupt happens
        end_time = datetime.datetime.now() + datetime.timedelta(seconds=max_execution_duration)
        container_is_active = check_if_container_is_active(container_name)
        while datetime.datetime.now() < end_time and container_is_active \
                and exec_env.interrupt_requested_for_program_execution_step != step_num:
            time.sleep(0.02)
            container_is_active = check_if_container_is_active(container_name)
    # if the container did not stop on its own, kill it
    error_type = None
    error_message = None
    if container_is_active:
        with CurrentlyDisplayedStatus(exec_env, "timeout: interrupting current task..."):
            utilities.debugging_message('docker', "timeout: interrupting container %s of image %s" % (container_name, image_name,))
            try:
                container.kill()
            except Exception:
                pass
            if exec_env.interrupt_requested_for_program_execution_step == step_num:
                error_type = 'program_interrupted_from_outside'
                error_message = "program was interrupted."
            else:
                error_type = 'program_timeout'
                error_message = "program timed out after %s seconds." % (max_execution_duration,)
    # clean up by deleting the container, forcibly stopping it if that hasn't happened yet
    container.remove(force=True)
    # return a code
    return error_type, error_message


###############################################################################################
# communication functions
###############################################################################################


# these are helper variables for temporarily storing uploaded files
_tmp_file_counter_lock = threading.Lock()
_tmp_file_counter = 0

def process_message_from_scenario(request_data, request_files):
    """
    processes a message from a scenario and tells the ExecEnvManager about it.
    """
    message_type = request_data['message_type']
    message_dict = request_data['message_dict']
    execution_environment_id = request_data['execution_environment_id']
    # get the ExecEnvManager
    server_url = _get_truth()['debug_server_url']
    server_contact_url = "%s%s" % (server_url, reverse('talk_to_execution_environment'),)
    serverside_exec_env_recognition_key = SERVERSIDE_EXEC_ENV_RECONITION_KEY
    exec_env_manager = executionEnvironmentLocal.get_execution_environment_manager(None, DEBUG, EXEC_ENV_ROOT_FOLDER, server_contact_url,
        profile_email=None, profile_password=None, serverside_exec_env_recognition_key=serverside_exec_env_recognition_key)
    # perform the right operation depending on the received message
    if message_type == 'get_update':
        next_io_event_index = message_dict['next_io_event_index']
        response_data = exec_env_manager.get_status_updates(execution_environment_id, next_io_event_index)
    elif message_type == 'user_command':
        files_dict = request_files
        # save the uploaded files in temporary storage
        global _tmp_file_counter_lock
        global _tmp_file_counter
        processed_dict = {}
        for file_name, file_stream in files_dict.items():
            with _tmp_file_counter_lock:
                c = _tmp_file_counter
                _tmp_file_counter += 1
            tmp_uploaded_file = os.path.join(exec_env_manager.get_outer_tmp_file_storage_folder(), '%d' % c)
            with open(tmp_uploaded_file, 'wb') as f:
                for chunk in file_stream.chunks():
                    f.write(chunk)
            processed_dict[file_name] = tmp_uploaded_file
        # add the files to the command
        input_dict = message_dict
        if len(processed_dict) == 0:
            processed_dict = None
        input_dict['files_dict'] = processed_dict
        # tell the ExecEnvManager to handle the user command
        response_data = exec_env_manager.submit_user_event(execution_environment_id, 'user_command', input_dict)
    elif message_type == 'select_option_for_execution':
        # tell the ExecEnvManager to handle the selected option
        response_data = exec_env_manager.submit_user_event(execution_environment_id, 'execute_option', message_dict)
    elif message_type == 'interrupt-program-execution':
        response_data = exec_env_manager.handle_control_command(execution_environment_id, 'interrupt-program-execution', message_dict)
    elif message_type == 'pause':
        response_data = exec_env_manager.handle_control_command(execution_environment_id, 'pause', message_dict)
    elif message_type == 'resume':
        response_data = exec_env_manager.handle_control_command(execution_environment_id, 'resume', message_dict)
    elif message_type == 'initialize_exec_env':
        exec_env_config = message_dict['exec_env_config']
        exec_env_manager.initialize_execution_environment(exec_env_config)
        response_data = {
            'success' : True,
        }
    elif message_type == 'shutdown_exec_env':
        params = {
            'execution_environment_id' : execution_environment_id,
        }
        response_data = exec_env_manager.shut_down_execution_environment(params)
    else:
        response_data = {
            'success' : False,
            'error_message' : "unknown message_type: '%s'" % message_type,
        }
    return True, response_data


###############################################################################################
# a manager, to handle multiple execution environments in parallel
# and let them all communicate with the outside
###############################################################################################


_the_manager = None
def start_execution_environment_manager(*args, **kwargs):
    """
    returns the manager for handling all execution environments.
    """
    global _the_manager
    _the_manager = ExecEnvManager(*args, **kwargs)
    _the_manager.start()


class ExecEnvManager(threading.Thread):
    """
    a manager, to handle multiple execution environments in parallel
    and let them all communicate with the outside.
    (NOTE: this is not very important so long as this file is in fact run on the same server as the main website,
    but it will be important once this is moved into a VM)
    """
    def __init__(self, own_address, debug_mode, root_folder, root_folder_from_outside, server_contact_url,
            profile_email=None, profile_password=None, serverside_exec_env_recognition_key=None):
        threading.Thread.__init__(self)
        self.execution_environments = {}
        self.own_address = own_address
        self.debug_mode = debug_mode
        self.root_folder = root_folder
        self.root_folder_from_outside = root_folder_from_outside
        self.server_contact_url = server_contact_url
        self.profile_email = profile_email
        self.profile_password = profile_password
        self.serverside_exec_env_recognition_key = serverside_exec_env_recognition_key
        # threading
        self.lock = threading.RLock()
        self.has_finished = threading.Event()
        self.has_error = threading.Event()
        self.error = None
    def get_tmp_file_storage_folder(self):
        return os.path.join(self.root_folder, 'tmpFileStorage')
    def run(self):
        """
        keep running in an endless loop.
        """
        try:
            while True:
                # TODO
                pass
        except Exception:
            with self.lock:
                self.error = sys.exc_info()
            self.has_error.set()
        finally:
            self.has_finished.set()
    ###############################################################################################
    # multithreading - these functions should be called from outside this thread
    ###############################################################################################
    def print_error_if_there_was_one(self):
        """
        DEBUGGING FUNCTION
        if there was an error, prints and returns it.
        This can be used to inspect this Thread from the outside.
        """
        with self.lock:
            if self.error is not None:
                error_msg = "exception inside ExecEnvManager Thread:\n"
                error_msg += utilities.get_error_message_details(self.error)
                utilities.debugging_message('local', "%s" % error_msg)
                # log
                logging.error(error_msg)
                return self.error
    def initialize_execution_environment(self, exec_env_config):
        """
        This is called by the server.
        Creates a new ExecEnv locally, using the parameters received from the server.
        """
        utilities.debugging_message('local-exec-env-management', 'started')
        utilities.debugging_message('local-exec-env-management', exec_env_config)
        execution_environment_id = exec_env_config['execution_environment_id']
        owner_id = exec_env_config['owner_id']
        time_of_creation = dateutil.parser.parse(exec_env_config['time_of_creation'])
        cutoff_time = dateutil.parser.parse(exec_env_config['cutoff_time'])
        starting_events = exec_env_config['starting_events']
        # log
        logging.info('create_new_execution_environment id=%d' % execution_environment_id)
        # create the ExecEnv and add it to the list
        exec_env = ExecEnv(execution_environment_id, owner_id, time_of_creation, cutoff_time, starting_events)
        with self.lock:
            if execution_environment_id in self.execution_environments:
                # the ExecEnv already exists or still exists, so there is no need to instantiate it a second time
                utilities.debugging_message('local-exec-env-management', "exec-env already exists: %d" % execution_environment_id)
                res = {
                    'success' : True,
                }
                return res
            self.execution_environments[execution_environment_id] = exec_env
            utilities.debugging_message('local-exec-env-management', "number of active ExecEnv threads: %d" % len(self.execution_environments.items()))
        # start it
        utilities.debugging_message('local-exec-env-management', "is alive: %s" % exec_env.isAlive())
        exec_env.start()
        utilities.debugging_message('local-exec-env-management', "is alive: %s" % exec_env.isAlive())
        utilities.debugging_message('local-exec-env-management', "has error: %s" % exec_env.has_error.isSet())
        exec_env.print_error_if_there_was_one()
        # response
        res = {
            'success' : True,
        }
        return res
    def shut_down_execution_environment(self, params_message):
        """
        requests the controlled shut down of an ExecEnv.
        Waits until this is done.
        TODO: add a timeout here. if it doesn't shut down fast enough, kill it.
        (note that waiting until the shutdown is complete is not otherwise harmful, since this method will be called in a separate thread anyway)
        (so there is nothing that is waiting for this method to complete, except the sending of the shutdown confirmation message)
        """
        try:
            params = json.loads(params_message)
            execution_environment_id = params['execution_environment_id']
            utilities.debugging_message('local-exec-env-management', 'shut down')
            utilities.debugging_message('local-exec-env-management', params)
            with self.lock:
                exec_env = self.execution_environments.get(execution_environment_id, None)
            if exec_env is None:
                res = {
                    'success' : False,
                    'message' : "the requested execution environment's Thread is no longer available. Presumably it has been shut down already."
                }
                return res
            # log
            logging.info('create_new_execution_environment id=%d' % execution_environment_id)
            # request a shut down and wait until this is done
            utilities.debugging_message('local-exec-env-management', "is alive: %s" % exec_env.isAlive())
            utilities.debugging_message('local-exec-env-management', 'waiting for shut down of %d...' % execution_environment_id)
            exec_env.request_controlled_shutdown(join=True)
            utilities.debugging_message('local-exec-env-management', "is alive: %s" % exec_env.isAlive())
            utilities.debugging_message('local-exec-env-management', 'shut down complete.')
            # remove the reference tp this ExecEnv, since it is no longer needed.
            # (garbage collection should remove the ExecEnv thread after this)
            with self.lock:
                del self.execution_environments[execution_environment_id]
                utilities.debugging_message('local-exec-env-management', "number of active ExecEnv threads: %d" % len(self.execution_environments.items()))
            # for debugging purposes, print any errors that occurred in the ExecEnv
            error = exec_env.print_error_if_there_was_one()
            # respond
            res = {
                'success' : True,
            }
            return res
        except Exception:
            # make the exception available for retrieval
            with self.lock:
                self.error = sys.exc_info()
            # respond
            res = {
                'success' : False,
                'error_message' : "an error occurred trying to shut down the execution environment."
            }
            return res
    def get_status_updates(self, execution_environment_id, *args, **kwargs):
        """
        ask the ExecEnv for a status update
        """
        with self.lock:
            exec_env = self.execution_environments.get(execution_environment_id, None)
        if exec_env is None:
            # if exec_env is None, the ExecEnv must have been shut down and removed already
            shut_down_notification_event = {
                'is_extraordinary_event' : True,
                'event_type' : 'shut_down',
            }
            res = {
                'event_list' : [shut_down_notification_event],
                'current_status' : "the scenario has been shut down.",
            }
        else:
            # get a list of all status updates matching the parameters and return them
            res = exec_env.get_status_updates(*args, **kwargs)
        return res
    def submit_user_event(self, execution_environment_id, event_type=None, args={}):
        """
        tell the ExecEnv that a new event has been submitted by the user.
        Returns a dictionary denoting success or failure.
        """
        with self.lock:
            exec_env = self.execution_environments.get(execution_environment_id, None)
        if exec_env is None:
            response_data = {
                'success' : False,
                'error_message' : "the execution environment %d has already been shut down" % execution_environment_id,
            }
        else:
            exec_env.submit_user_event(event_type=event_type, args=args)
            response_data = {
                'success' : True,
            }
        return response_data
    def handle_control_command(self, execution_environment_id, cmd, args):
        """
        tell the ExecEnv to process a command that changes the control flow of the ExecEnv
        or performs other changes that do not involve creating an Event for the server.
        Returns a dictionary denoting success or failure.
        """
        with self.lock:
            exec_env = self.execution_environments.get(execution_environment_id, None)
        if exec_env is None:
            response_data = {
                'success' : False,
                'error_message' : "the execution environment %d has already been shut down" % execution_environment_id,
            }
        else:
            response_data = exec_env.handle_control_command(cmd, args)
        return response_data


###############################################################################################
# the execution environment class
###############################################################################################


class ExecEnv(threading.Thread):
    """
    this class corresponds to the models.ExecutionEnvironment class on the server.
    It runs on its own thread, in an endless loop, and communicates with the server.
    It performs Docker executions locally when the server requests it, and provides the server with event requests from the outside.
    """
    def __init__(self, execution_environment_id, owner_id, time_of_creation, cutoff_time, starting_events):
        threading.Thread.__init__(self)
        # constants
        self.id = execution_environment_id
        self.owner_id = owner_id # the user who created ExecEnv
        self.time_of_creation = time_of_creation
        self.cutoff_time = cutoff_time # all server data newer than this is ignored, to make things reproducible
        self.incoming_user_event_requests = []
        self.status_updates = []
        self.number_of_objects_registered_for_status_updates = 0
        self.number_of_steps_registered_for_status_updates = 0
        self.current_status_message = "starting..."
        self.current_local_event = None
        # threading
        self.lock = threading.RLock()
        self.interrupt_requested_for_program_execution_step = -1
        self.wait_for_resume_command_from_outside = threading.Event()
        self.wait_for_resume_command_from_outside.set()
        self.wait_for_input_from_outside = threading.Event()
        self.stop_request = threading.Event()
        self.has_finished = threading.Event()
        self.has_error = threading.Event()
        self.error = None
        # initialize
        for starting_event in starting_events:
            self.submit_user_event(starting_event['event_type'], starting_event['args'])
    ###############################################################################################
    # multithreading - these functions should be called from outside this thread
    ###############################################################################################
    def run(self):
        """
        keep running in an endless loop, until you are requested to stop
        """
        try:
            with CurrentlyDisplayedStatus(self, "running..."):
                while not self.stop_request.isSet():
                    self._next_iteration()
            with self.lock:
                self.current_status_message = "shut down."
        except Exception:
            with self.lock:
                self.error = sys.exc_info()
            self.has_error.set()
            utilities.debugging_message('local-exec-env-management-error', "ERROR")
            self.print_error_if_there_was_one()
        finally:
            self.has_finished.set()
    def submit_user_event(self, event_type, args):
        """
        add a new event to the ExecEnv.
        Returns a dictionary denoting success or failure.
        """
        event = basics.Event(basics.create_preliminary_identifier('event') , event_type, args=args, priority=False).to_json()
        with self.lock:
            self.incoming_user_event_requests.append(event)
        # if this thread is waiting for a signal from outside, give that signal
        self.wait_for_input_from_outside.set()
    def handle_control_command(self, cmd, args):
        """
        process a command that changes the control flow of the ExecEnv
        or performs other changes that do not involve creating an Event for the server.
        Returns a dictionary denoting success or failure.
        """
        if cmd == 'interrupt-program-execution':
            step_of_execution_event = args['step_of_execution_event']
            self.interrupt_requested_for_program_execution_step = step_of_execution_event
            res = {
                'success' : True,
            }
        elif cmd == 'pause':
            self.wait_for_resume_command_from_outside.clear()
            # this res can be ignored. The actual status_update denoting the pause/resume will be created when the ExecEnv actually starts/stops waiting.
            res = {
                'success' : True,
            }
        elif cmd == 'resume':
            self.wait_for_resume_command_from_outside.set()
            # this res can be ignored. The actual status_update denoting the pause/resume will be created when the ExecEnv actually starts/stops waiting.
            res = {
                'success' : True,
            }
        else:
            res = {
                'success' : False,
                'error_message' : "a control command of this type does not exist: '%s'" % cmd,
            }
        return res
    def request_controlled_shutdown(self, join=False):
        """
        requests this execution environment to shut down.
        Optionally, joins on this and waits until it is done.
        NOTE: The ExecEnv will still finish its current iteration first, which could take a while depending on what it is currently doing.
        """
        self.stop_request.set()
        self.wait_for_resume_command_from_outside.set()
        self.wait_for_input_from_outside.set()
        if join:
            self.join(timeout=None)
    def get_status_updates(self, next_io_event_index):
        """
        get a list of status updates, starting at next_io_event_index,
        as well as the current status, as a text.
        """
        with self.lock:
            if len(self.status_updates) <= next_io_event_index:
                event_list = []
            else:
                event_list = self.status_updates[next_io_event_index:]
            current_status = self.current_status_message
            current_local_event = self.current_local_event
            res = {
                'success' : True,
                'event_list' : event_list,
                'current_status' : current_status,
                'current_local_event' : current_local_event,
            }
            return res
    def print_error_if_there_was_one(self):
        """
        DEBUGGING FUNCTION
        if there was an error, prints and returns it.
        This can be used to inspect this Thread from the outside.
        """
        with self.lock:
            if self.error is not None:
                error_msg = "exception inside ExecEnv Thread %s:\n" % (self.id,)
                error_msg += utilities.get_error_message_details(self.error)
                utilities.debugging_message('local - error', error_msg)
                # log
                logging.error(error_msg)
                return self.error
    ###############################################################################################
    # actual logic
    ###############################################################################################
    def _add_status_update(self, update_dict):
        """
        update the list of status updates, which can be queried from the outside.
        Adds one item to the list.
        """
        with self.lock:
            update_dict['status_index'] = len(self.status_updates)
            self.status_updates.append(update_dict)
    def _add_new_status_updates_of_object_manager(self, object_manager):
        """
        update the list of status updates, which can be queried from the outside.
        This works by creating one status_update per step header and one per object in the object_manager.
        """
        all_objects = object_manager.get_all_objects()
        new_status_updates = []
        current_object_index = 0
        self.number_of_objects_registered_for_status_updates
        self.number_of_steps_registered_for_status_updates
        # add a step header
        if len(object_manager._statistics_at_beginning_of_step) > self.number_of_steps_registered_for_status_updates + 1:
            raise ProgrammerFuckedUp("skipped a step. This function should be called (at least) once per step.")
        if len(object_manager._statistics_at_beginning_of_step) == self.number_of_steps_registered_for_status_updates + 1:
            step_header_statistics = object_manager._statistics_at_beginning_of_step[self.number_of_steps_registered_for_status_updates]
            step_header_status_update = {
                'event_type' : 'step_header',
                'step' : self.number_of_steps_registered_for_status_updates,
                'step_header_statistics' : step_header_statistics,
            }
            self.number_of_steps_registered_for_status_updates += 1
            new_status_updates.append(step_header_status_update)
        step = self.number_of_steps_registered_for_status_updates - 1 # this number is zero-based
        # add all new objects
        while self.number_of_objects_registered_for_status_updates < len(all_objects):
            obj = all_objects[self.number_of_objects_registered_for_status_updates]
            obj_step = object_manager.get_step_number_of_addition_for_identifier(obj.identifier)
            if step != obj_step:
                raise ProgrammerFuckedUp("""an object was added that had a different step number than the most recent step.
                    This function should be called (at least) once per step, so this shouldn't be possible.""")
            object_status_update = {
                'event_type' : 'object_generated',
                'step_that_generated_this_object' : step,
                'object_type' : obj.identifier.type,
                'status_object' : obj.to_json(),
            }
            self.number_of_objects_registered_for_status_updates += 1
            new_status_updates.append(object_status_update)
        # update the list
        with self.lock:
            for status_update in new_status_updates:
                self._add_status_update(status_update)
    def _next_iteration(self):
        # if no event was given, use the default event
        event = self.current_local_event
        if event is None:
            event = {
                'local_event_type' : 'request_next_iteration',
                'args' : {},
            }
        elif event['local_event_type'] == 'request_next_iteration':
            raise ProgrammerFuckedUp("a new iteration should only be requested when the event queue is empty, not for any other reason.")
        # note that the selected event is currently being executed
        # but only report the arguments that are actually needed, since this can be a lot of data to transfer
        local_event_type = event['local_event_type']
        args = event['args']
        if local_event_type == 'execute_program':
            reported_args = {
                'step' : basics.parse_object_manager(args['object_manager']).get_current_step(),
                'program_identifier' : args['program_identifier'],
            }
        else:
            reported_args = {}
        self.current_local_event = {
            'type' : local_event_type,
            'args' : reported_args,
        }
        # if necessary, wait
        if not self.wait_for_resume_command_from_outside.is_set():
            utilities.debugging_message('local - wait', "start waiting for resume-command from user")
            with CurrentlyDisplayedStatus(self, "paused. Press resume button to continue."):
                # tell the website about the new state of things being paused or resumed.
                status_update = {
                    'event_type' : 'pause_or_resume',
                    'pause' : True,
                    'resume' : False,
                }
                self._add_status_update(status_update)
                # wait
                self.wait_for_resume_command_from_outside.wait()
                # tell the website about the new state of things being paused or resumed.
                status_update = {
                    'event_type' : 'pause_or_resume',
                    'pause' : False,
                    'resume' : True,
                }
                self._add_status_update(status_update)
            utilities.debugging_message('local - wait', "end waiting for resume-command from user")
        # execute the selected event
        utilities.debugging_message('local-event', "ExecEnv %d is starting event: %s" % (self.id, local_event_type,))
        if local_event_type == 'request_next_iteration':
            with CurrentlyDisplayedStatus(self, "requesting next step from server..."):
                # ask the server for input
                server_response = self.message_to_server('requesting_next_iteration', {})
                self.process_server_response(server_response)
        elif local_event_type == 'wait_for_input':
            with CurrentlyDisplayedStatus(self, "waiting for input..."):
                results = self._event_wait_for_input()
                # tell the server
                server_response = self.message_to_server('done_waiting_for_input', results)
                self.process_server_response(server_response)
        elif local_event_type == 'execute_program':
            with CurrentlyDisplayedStatus(self, "executing program..."):
                # execute a specified program
                object_manager = basics.parse_object_manager(args['object_manager'])
                event_identifier = basics.parse_identifier(args['event_identifier'])
                program_identifier = basics.parse_identifier(args['program_identifier'])
                docker_image_name = args['docker_image_name']
                input_arguments_file_dict = {k:object_manager.get_object_for_identifier(basics.parse_identifier(v)) for k,v in args['argument_dict'].items()}
                max_execution_duration = args['max_execution_duration']
                # execute
                results = self._event_program_execution(object_manager, event_identifier, program_identifier,
                    docker_image_name, input_arguments_file_dict, max_execution_duration)
                # tell the server about the results
                server_response = self.message_to_server('results_of_execution', results)
                self.process_server_response(server_response)
        elif local_event_type == 'confirm_file_upload':
            with CurrentlyDisplayedStatus(self, "processing uploaded data..."):
                current_step = args['current_step']
                command_text = args['command_text']
                files_dict = args['files_dict']
                if files_dict is None:
                    files_dict = {}
                # make uploaded files available
                results = self._event_make_uploaded_files_available(command_text, files_dict, current_step)
                # tell the server about the results
                server_response = self.message_to_server('finished_uploading_files', results)
                self.process_server_response(server_response)
        else:
            raise ProgrammerFuckedUp("an event of this type does not exist or is not handled yet: %s" % local_event_type)
    def _event_wait_for_input(self):
        """
        wait for user input
        """
        self.wait_for_input_from_outside.clear()
        # to avoid race conditions, verify that no user input has arrived in the meantime
        with self.lock:
            if len(self.incoming_user_event_requests) != 0:
                self.wait_for_input_from_outside.set()
        utilities.debugging_message('local - wait', "start waiting for input from user")
        self.wait_for_input_from_outside.wait()
        utilities.debugging_message('local - wait', "end waiting for input from user")
        return {}
    def _event_program_execution(self, object_manager, event_identifier, program_identifier, docker_image_name, input_arguments_file_dict, max_execution_duration):
        """
        get a program to execute and a list of arguments to use from an event and execute them.
        """
        if program_identifier.type != 'program':
            raise ProgrammerFuckedUp("""only program identifiers should be used here. This exception should never happen:
                this scenario should have been filtered out at an earlier point.""")
        # prepare the new step for its execution
        utilities.debugging_message('local-execution', "preparing step %d" % object_manager.get_current_step())
        with CurrentlyDisplayedStatus(self, "preparation..."):
            self._prepare_step_for_execution(object_manager, event_identifier, program_identifier, input_arguments_file_dict)
        # execute the image
        utilities.debugging_message('local-execution', "executing Docker Image '%s'" % docker_image_name)
        with CurrentlyDisplayedStatus(self, "docker execution..."):
            try:
                error_type, error_message = execute_image(self, docker_image_name, None, self.id,
                    object_manager.get_current_step(), max_execution_duration)
                if error_type is not None:
                    results_of_iteration = {
                        'error' : {
                            'error_type' : error_type,
                            'error_message' : error_message,
                        },
                    }
                    return results_of_iteration
            except Exception:
                error_message = utilities.get_error_message_details()
                results_of_iteration = {
                    'error' : {
                        'error_type' : 'program_docker_execution_failed',
                        'error_message' : error_message,
                    },
                }
                return results_of_iteration
        # attempt to parse the results
        utilities.debugging_message('local-execution', "parsing results of step %d" % object_manager.get_current_step())
        with CurrentlyDisplayedStatus(self, "parsing results..."):
            try:
                execution_encountered_error, execution_output_dictionary_or_error_file_content = self._parse_results_of_step_after_execution(object_manager)
                if execution_encountered_error:
                    error_file_content = execution_output_dictionary_or_error_file_content
                    results_of_iteration = {
                        'error' : {
                            'error_type' : 'program_failed_with_error_file',
                            'error_message' : "content of error file generated by the program:\n%s" % error_file_content,
                        },
                    }
                    return results_of_iteration
            except Exception:
                error_message = utilities.get_error_message_details()
                results_of_iteration = {
                    'error' : {
                        'error_type' : 'program_result_parsing_failed',
                        'error_message' : error_message,
                    },
                }
                return results_of_iteration
        # return the information you want to send to the server
        execution_output_dictionary = execution_output_dictionary_or_error_file_content
        results_of_iteration = {
            'execution_output_dictionary' : execution_output_dictionary,
        }
        return results_of_iteration
    def _prepare_step_for_execution(self, object_manager, event_identifier, program_identifier, input_arguments_file_dict):
        """
        creates a folder to run a container from and prepares it with the correct data for input.
        the input_arguments_file_dict are a dict mapping argument names to FileObjects.
        the input is:
        -one file called in.txt
        -one file per input, named "in_<output_index>"
        Also changes the input_file_objects by calling change_file_name_for_use_as_input() on them to change their file names.
        """
        step_folder = get_step_folder(self.id, object_manager.get_current_step())
        # recreate the folder if it already exists
        # TODO LATER: remove this. outside of testing, this actually should never happen. There should be a new folder for each ExecEnv and each step.
        if os.path.exists(step_folder):
            shutil.rmtree(step_folder)
        os.makedirs(step_folder)
        with open(get_step_explanation_file_in(self.id, object_manager.get_current_step()), 'w') as f:
            input_description = {}
            input_description['object_manager'] = object_manager.to_json()
            input_description['event_identifier'] = event_identifier.to_json()
            input_description['program_identifier'] = program_identifier.to_json()
            for arg_name, file_object in input_arguments_file_dict.items():
                file_object._change_file_name_for_use_as_input(arg_name)
            input_description['inputs'] = {k:v.to_json() for k,v in input_arguments_file_dict.items()}
            json.dump(input_description, f, indent=4)
        for arg_name, file_object in input_arguments_file_dict.items():
            if file_object.creation_step >= object_manager.get_current_step():
                DebugFriendlyException("objects used in an execution must be from an earlier step")
            from_file = get_step_file_out(self.id, file_object.creation_step, file_object.creation_index)
            to_file = get_step_file_in(self.id, object_manager.get_current_step(), arg_name)
            shutil.copyfile(from_file, to_file)
    def _parse_results_of_step_after_execution(self, object_manager):
        """
        reads a folder that has been operated on by an execute_image() operation.
        Returns an object describing the results of that operation.
        """
        error_file = get_step_file_error(self.id, object_manager.get_current_step())
        if os.path.exists(error_file):
            with open(error_file, 'r') as f:
                execution_output_dictionary_or_error_file_content = f.read()
            utilities.debugging_message('local', "WARNING: step %d generated an error file!" % object_manager.get_current_step())
            execution_encountered_error = True
        else:
            execution_encountered_error = False
            with open(get_step_explanation_file_out(self.id, object_manager.get_current_step()), 'r') as f:
                execution_output_dictionary_or_error_file_content = json.load(f)
        return execution_encountered_error, execution_output_dictionary_or_error_file_content
    def _event_make_uploaded_files_available(self, command_text, files_dict, current_step):
        """
        process a command from the user
        """
        # create files
        step_folder = get_step_folder(self.id, current_step)
        # recreate the folder if it already exists
        # TODO LATER: remove this. outside of testing, this actually should never happen. There should be a new folder for each ExecEnv and each step.
        if os.path.exists(step_folder):
            shutil.rmtree(step_folder)
        os.makedirs(step_folder)
        creation_index = 0
        created_file_object_for_command = None
        if command_text is not None:
            # create the file and write the text into it
            full_file_name = get_step_file_out(self.id, current_step, creation_index)
            with open(full_file_name, 'w') as f:
                f.write(command_text)
            # create a preliminary file object for it
            preliminary_identifier = basics.create_preliminary_identifier('file')
            creation_step = None # dummy value, to be ignored by the server
            file_name = "user_command.txt"
            created_file_object_for_command = basics.FileObject(preliminary_identifier, file_name, creation_step, creation_index)
            creation_index += 1
        created_file_objects_for_files = []
        for file_name, uploaded_file_temporary_storage_name in files_dict.items():
            # move the file from its temporary storage to its new destination
            full_file_name = get_step_file_out(self.id, current_step, creation_index)
            shutil.move(uploaded_file_temporary_storage_name, full_file_name)
            # create a preliminary file object for it
            preliminary_identifier = basics.create_preliminary_identifier('file')
            creation_step = None # dummy value, to be ignored by the server
            created_file_objects_for_files.append(basics.FileObject(preliminary_identifier, file_name, creation_step, creation_index))
            creation_index += 1
        # return
        results = {
            'command_text' : command_text,
            'created_file_object_for_command' : None if created_file_object_for_command is None else created_file_object_for_command.to_json(),
            'created_file_objects_for_files' : [a.to_json() for a in created_file_objects_for_files],
        }
        return results
    def process_server_response(self, server_response):
        """
        process the decisions made by the server by adding new objects to this ExecEnv.
        """
        if server_response['success']:
            self.current_local_event = server_response['next_local_event']
            # process any new status updates to display
            object_manager = basics.parse_object_manager(server_response['object_manager'])
            self._add_new_status_updates_of_object_manager(object_manager)
        else:
            # DEBUG
            # add a status message informing the user of the error
            # this is only for debugging and should not be enabled in a production setting
            error_message = server_response['error_message']
            if _the_manager.debug_mode:
                status_update = {
                    'event_type' : 'server_error',
                    'error_message' : "error occurred on server:\n%s" % (error_message,),
                }
                self._add_status_update(status_update)
            # shut down the ExecEnv
            raise ProgrammerFuckedUp("encountered an unexpected error on the server:\n%s" % error_message)
###############################################################################################
# functions for communicating with the server
###############################################################################################
    def message_to_server(self, message_type, args):
        """
        tells the server what this local ExecEnv has done.
        """
        with self.lock:
            message = {
                'email' : _the_manager.profile_email,
                'password' : _the_manager.profile_password,
                'serverside_exec_env_recognition_key' : _the_manager.serverside_exec_env_recognition_key,
                'execution_environment_id' : self.id,
                'message_type' : message_type,
                'message_args' : args,
                'incoming_user_event_requests' : self.incoming_user_event_requests,
            }
            self.incoming_user_event_requests = []
        data = {
            'message' : json.dumps(message),
        }
        resp = requests.post(_the_manager.server_contact_url, data=data)
        res = json.loads(resp._content.decode(_get_json_encoding_of_server()))
        return res


