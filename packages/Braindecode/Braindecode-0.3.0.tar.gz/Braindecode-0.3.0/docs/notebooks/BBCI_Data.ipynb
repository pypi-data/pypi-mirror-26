{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Decode BBCI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to read and decode BBCI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup logging to see outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set the filename and the sensors you want to load. If you set\n",
    "\n",
    "```python\n",
    "load_sensor_names=None\n",
    "```\n",
    "\n",
    "or just remove the parameter from the function call, all sensors will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=3451320\n",
      "    Range : 0 ... 3451319 =      0.000 ...  6902.638 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "train_filename = '/home/schirrmr/data/BBCI-without-last-runs/BhNoMoSc1S001R01_ds10_1-12.BBCI.mat'\n",
    "cnt = BBCIDataset(train_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing on continous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First remove the stimulus channel, than apply any preprocessing you like. There are some very few directions available from Braindecode, such as resample_cnt. But you can apply any function on the chan x time matrix of the mne raw object (`cnt` in the code) by calling `mne_apply` with two arguments:\n",
    "\n",
    "1. Your function (2d-array-> 2darray), that transforms the channel x timesteps data array\n",
    "2. the Raw data object from mne itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-18 14:40:02,301 WARNING : This is not causal, uses future data....\n",
      "2017-10-18 14:40:02,303 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=1725660\n",
      "    Range : 0 ... 1725659 =      0.000 ...  6902.636 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.mne_ext.signalproc import resample_cnt, mne_apply\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "# mne apply will apply the function to the data (a 2d-numpy-array)\n",
    "# have to transpose data back and forth, since\n",
    "# exponential_running_standardize expects time x chans order\n",
    "# while mne object has chans x time order\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to epoched dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braindecode supplies the `create_signal_target_from_raw_mne` function, which will transform the mne raw object into a `SignalAndTarget` object for use in Braindecode.\n",
    "`name_to_code` should be an `OrderedDict` that maps class names to either one or a list of marker codes for that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-18 14:40:04,600 INFO : Trial per class:\n",
      "Counter({'Feet': 225, 'Right': 224, 'Rest': 224, 'Left': 224})\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "from collections import OrderedDict\n",
    "# can also give lists of marker codes in case a class has multiple marker codes...\n",
    "name_to_code = OrderedDict([('Right', 1), ('Left', 2), ('Rest', 3), ('Feet', 4)])\n",
    "segment_ival_ms = [-500,4000]\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=3, n_times=617090\n",
      "    Range : 0 ... 617089 =      0.000 ...  1234.178 secs\n",
      "Ready.\n",
      "2017-10-18 14:40:05,669 WARNING : This is not causal, uses future data....\n",
      "2017-10-18 14:40:05,670 INFO : Resampling from 500.000000 to 250.000000 Hz.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=308545\n",
      "    Range : 0 ... 308544 =      0.000 ...  1234.176 secs\n",
      "Ready.\n",
      "2017-10-18 14:40:06,236 INFO : Trial per class:\n",
      "Counter({'Feet': 40, 'Left': 40, 'Rest': 40, 'Right': 40})\n"
     ]
    }
   ],
   "source": [
    "test_filename = '/home/schirrmr/data/BBCI-only-last-runs/BhNoMoSc1S001R13_ds10_1-2BBCI.mat'\n",
    "cnt = BBCIDataset(test_filename, load_sensor_names=['C3', 'CPz', 'C4']).load()\n",
    "# Remove stimulus channel\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "cnt = resample_cnt(cnt, 250)\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "    a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "    cnt)\n",
    "test_set = create_signal_target_from_raw_mne(cnt, name_to_code, segment_ival_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "In case of start and stop markers, provide a `name_to_stop_codes` dictionary (same as for the start codes in this example) as a final argument to `create_signal_target_from_raw_mne`. See [Read and Decode BBCI Data with Start-Stop-Markers Tutorial](BBCI_Data_Start_Stop.html)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split off a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup optimizer and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 predictions per input/trial\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Monitors, Loss function, Stop Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "\n",
    "\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2).squeeze(), targets)\n",
    "\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-18 14:40:09,782 INFO : Run until first stop...\n",
      "2017-10-18 14:40:10,646 INFO : Epoch 0\n",
      "2017-10-18 14:40:10,648 INFO : train_loss                7.89184\n",
      "2017-10-18 14:40:10,649 INFO : valid_loss                7.72731\n",
      "2017-10-18 14:40:10,650 INFO : test_loss                 7.75617\n",
      "2017-10-18 14:40:10,650 INFO : train_sample_misclass     0.75013\n",
      "2017-10-18 14:40:10,651 INFO : valid_sample_misclass     0.74856\n",
      "2017-10-18 14:40:10,652 INFO : test_sample_misclass      0.75115\n",
      "2017-10-18 14:40:10,653 INFO : train_misclass            0.75070\n",
      "2017-10-18 14:40:10,654 INFO : valid_misclass            0.74860\n",
      "2017-10-18 14:40:10,655 INFO : test_misclass             0.75000\n",
      "2017-10-18 14:40:10,656 INFO : runtime                   0.00000\n",
      "2017-10-18 14:40:10,657 INFO : \n",
      "2017-10-18 14:40:10,659 INFO : New best valid_misclass: 0.748603\n",
      "2017-10-18 14:40:10,659 INFO : \n",
      "2017-10-18 14:40:11,871 INFO : Time only for training updates: 0.98s\n",
      "2017-10-18 14:40:12,700 INFO : Epoch 1\n",
      "2017-10-18 14:40:12,701 INFO : train_loss                0.79613\n",
      "2017-10-18 14:40:12,702 INFO : valid_loss                0.79320\n",
      "2017-10-18 14:40:12,703 INFO : test_loss                 0.83718\n",
      "2017-10-18 14:40:12,704 INFO : train_sample_misclass     0.36969\n",
      "2017-10-18 14:40:12,705 INFO : valid_sample_misclass     0.37399\n",
      "2017-10-18 14:40:12,706 INFO : test_sample_misclass      0.42988\n",
      "2017-10-18 14:40:12,707 INFO : train_misclass            0.30362\n",
      "2017-10-18 14:40:12,707 INFO : valid_misclass            0.26257\n",
      "2017-10-18 14:40:12,708 INFO : test_misclass             0.34375\n",
      "2017-10-18 14:40:12,709 INFO : runtime                   2.08686\n",
      "2017-10-18 14:40:12,710 INFO : \n",
      "2017-10-18 14:40:12,712 INFO : New best valid_misclass: 0.262570\n",
      "2017-10-18 14:40:12,713 INFO : \n",
      "2017-10-18 14:40:13,897 INFO : Time only for training updates: 0.96s\n",
      "2017-10-18 14:40:14,757 INFO : Epoch 2\n",
      "2017-10-18 14:40:14,758 INFO : train_loss                0.68158\n",
      "2017-10-18 14:40:14,759 INFO : valid_loss                0.65896\n",
      "2017-10-18 14:40:14,760 INFO : test_loss                 0.74194\n",
      "2017-10-18 14:40:14,761 INFO : train_sample_misclass     0.29305\n",
      "2017-10-18 14:40:14,762 INFO : valid_sample_misclass     0.30232\n",
      "2017-10-18 14:40:14,762 INFO : test_sample_misclass      0.37349\n",
      "2017-10-18 14:40:14,763 INFO : train_misclass            0.22563\n",
      "2017-10-18 14:40:14,764 INFO : valid_misclass            0.21229\n",
      "2017-10-18 14:40:14,765 INFO : test_misclass             0.30000\n",
      "2017-10-18 14:40:14,765 INFO : runtime                   2.02668\n",
      "2017-10-18 14:40:14,766 INFO : \n",
      "2017-10-18 14:40:14,768 INFO : New best valid_misclass: 0.212291\n",
      "2017-10-18 14:40:14,769 INFO : \n",
      "2017-10-18 14:40:15,936 INFO : Time only for training updates: 0.95s\n",
      "2017-10-18 14:40:16,797 INFO : Epoch 3\n",
      "2017-10-18 14:40:16,799 INFO : train_loss                0.65480\n",
      "2017-10-18 14:40:16,800 INFO : valid_loss                0.68446\n",
      "2017-10-18 14:40:16,801 INFO : test_loss                 0.81616\n",
      "2017-10-18 14:40:16,802 INFO : train_sample_misclass     0.27871\n",
      "2017-10-18 14:40:16,803 INFO : valid_sample_misclass     0.32106\n",
      "2017-10-18 14:40:16,804 INFO : test_sample_misclass      0.43491\n",
      "2017-10-18 14:40:16,806 INFO : train_misclass            0.20613\n",
      "2017-10-18 14:40:16,807 INFO : valid_misclass            0.26257\n",
      "2017-10-18 14:40:16,808 INFO : test_misclass             0.35625\n",
      "2017-10-18 14:40:16,809 INFO : runtime                   2.03825\n",
      "2017-10-18 14:40:16,810 INFO : \n",
      "2017-10-18 14:40:18,070 INFO : Time only for training updates: 0.97s\n",
      "2017-10-18 14:40:18,902 INFO : Epoch 4\n",
      "2017-10-18 14:40:18,907 INFO : train_loss                0.61354\n",
      "2017-10-18 14:40:18,910 INFO : valid_loss                0.60043\n",
      "2017-10-18 14:40:18,913 INFO : test_loss                 0.75597\n",
      "2017-10-18 14:40:18,914 INFO : train_sample_misclass     0.25810\n",
      "2017-10-18 14:40:18,915 INFO : valid_sample_misclass     0.25493\n",
      "2017-10-18 14:40:18,916 INFO : test_sample_misclass      0.36066\n",
      "2017-10-18 14:40:18,917 INFO : train_misclass            0.18106\n",
      "2017-10-18 14:40:18,918 INFO : valid_misclass            0.18994\n",
      "2017-10-18 14:40:18,919 INFO : test_misclass             0.28750\n",
      "2017-10-18 14:40:18,919 INFO : runtime                   2.13345\n",
      "2017-10-18 14:40:18,920 INFO : \n",
      "2017-10-18 14:40:18,923 INFO : New best valid_misclass: 0.189944\n",
      "2017-10-18 14:40:18,924 INFO : \n",
      "2017-10-18 14:40:20,194 INFO : Time only for training updates: 0.95s\n",
      "2017-10-18 14:40:21,020 INFO : Epoch 5\n",
      "2017-10-18 14:40:21,021 INFO : train_loss                0.60302\n",
      "2017-10-18 14:40:21,022 INFO : valid_loss                0.59346\n",
      "2017-10-18 14:40:21,024 INFO : test_loss                 0.66137\n",
      "2017-10-18 14:40:21,025 INFO : train_sample_misclass     0.25216\n",
      "2017-10-18 14:40:21,026 INFO : valid_sample_misclass     0.27284\n",
      "2017-10-18 14:40:21,027 INFO : test_sample_misclass      0.31283\n",
      "2017-10-18 14:40:21,028 INFO : train_misclass            0.18245\n",
      "2017-10-18 14:40:21,030 INFO : valid_misclass            0.20670\n",
      "2017-10-18 14:40:21,031 INFO : test_misclass             0.24375\n",
      "2017-10-18 14:40:21,032 INFO : runtime                   2.12412\n",
      "2017-10-18 14:40:21,033 INFO : \n",
      "2017-10-18 14:40:22,241 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:23,181 INFO : Epoch 6\n",
      "2017-10-18 14:40:23,182 INFO : train_loss                0.60229\n",
      "2017-10-18 14:40:23,183 INFO : valid_loss                0.63080\n",
      "2017-10-18 14:40:23,184 INFO : test_loss                 0.71621\n",
      "2017-10-18 14:40:23,185 INFO : train_sample_misclass     0.24383\n",
      "2017-10-18 14:40:23,185 INFO : valid_sample_misclass     0.27576\n",
      "2017-10-18 14:40:23,186 INFO : test_sample_misclass      0.34279\n",
      "2017-10-18 14:40:23,187 INFO : train_misclass            0.17409\n",
      "2017-10-18 14:40:23,188 INFO : valid_misclass            0.18994\n",
      "2017-10-18 14:40:23,188 INFO : test_misclass             0.26875\n",
      "2017-10-18 14:40:23,189 INFO : runtime                   2.04816\n",
      "2017-10-18 14:40:23,190 INFO : \n",
      "2017-10-18 14:40:23,192 INFO : New best valid_misclass: 0.189944\n",
      "2017-10-18 14:40:23,193 INFO : \n",
      "2017-10-18 14:40:24,406 INFO : Time only for training updates: 0.92s\n",
      "2017-10-18 14:40:25,179 INFO : Epoch 7\n",
      "2017-10-18 14:40:25,180 INFO : train_loss                0.56260\n",
      "2017-10-18 14:40:25,181 INFO : valid_loss                0.55011\n",
      "2017-10-18 14:40:25,182 INFO : test_loss                 0.62833\n",
      "2017-10-18 14:40:25,183 INFO : train_sample_misclass     0.22230\n",
      "2017-10-18 14:40:25,184 INFO : valid_sample_misclass     0.24589\n",
      "2017-10-18 14:40:25,184 INFO : test_sample_misclass      0.30966\n",
      "2017-10-18 14:40:25,185 INFO : train_misclass            0.15599\n",
      "2017-10-18 14:40:25,186 INFO : valid_misclass            0.15642\n",
      "2017-10-18 14:40:25,187 INFO : test_misclass             0.21875\n",
      "2017-10-18 14:40:25,188 INFO : runtime                   2.16420\n",
      "2017-10-18 14:40:25,189 INFO : \n",
      "2017-10-18 14:40:25,191 INFO : New best valid_misclass: 0.156425\n",
      "2017-10-18 14:40:25,192 INFO : \n",
      "2017-10-18 14:40:26,348 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:27,275 INFO : Epoch 8\n",
      "2017-10-18 14:40:27,278 INFO : train_loss                0.57974\n",
      "2017-10-18 14:40:27,279 INFO : valid_loss                0.57122\n",
      "2017-10-18 14:40:27,280 INFO : test_loss                 0.69269\n",
      "2017-10-18 14:40:27,281 INFO : train_sample_misclass     0.24353\n",
      "2017-10-18 14:40:27,283 INFO : valid_sample_misclass     0.26349\n",
      "2017-10-18 14:40:27,284 INFO : test_sample_misclass      0.33418\n",
      "2017-10-18 14:40:27,285 INFO : train_misclass            0.21727\n",
      "2017-10-18 14:40:27,286 INFO : valid_misclass            0.18994\n",
      "2017-10-18 14:40:27,288 INFO : test_misclass             0.26250\n",
      "2017-10-18 14:40:27,289 INFO : runtime                   1.94213\n",
      "2017-10-18 14:40:27,290 INFO : \n",
      "2017-10-18 14:40:28,524 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:29,504 INFO : Epoch 9\n",
      "2017-10-18 14:40:29,505 INFO : train_loss                0.53458\n",
      "2017-10-18 14:40:29,506 INFO : valid_loss                0.55970\n",
      "2017-10-18 14:40:29,507 INFO : test_loss                 0.68392\n",
      "2017-10-18 14:40:29,508 INFO : train_sample_misclass     0.22152\n",
      "2017-10-18 14:40:29,509 INFO : valid_sample_misclass     0.26032\n",
      "2017-10-18 14:40:29,509 INFO : test_sample_misclass      0.33941\n",
      "2017-10-18 14:40:29,510 INFO : train_misclass            0.15877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-18 14:40:29,511 INFO : valid_misclass            0.17318\n",
      "2017-10-18 14:40:29,512 INFO : test_misclass             0.23125\n",
      "2017-10-18 14:40:29,512 INFO : runtime                   2.17661\n",
      "2017-10-18 14:40:29,513 INFO : \n",
      "2017-10-18 14:40:30,665 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:31,539 INFO : Epoch 10\n",
      "2017-10-18 14:40:31,540 INFO : train_loss                0.47951\n",
      "2017-10-18 14:40:31,541 INFO : valid_loss                0.52164\n",
      "2017-10-18 14:40:31,542 INFO : test_loss                 0.62324\n",
      "2017-10-18 14:40:31,543 INFO : train_sample_misclass     0.19307\n",
      "2017-10-18 14:40:31,543 INFO : valid_sample_misclass     0.24082\n",
      "2017-10-18 14:40:31,544 INFO : test_sample_misclass      0.29183\n",
      "2017-10-18 14:40:31,545 INFO : train_misclass            0.12674\n",
      "2017-10-18 14:40:31,546 INFO : valid_misclass            0.15084\n",
      "2017-10-18 14:40:31,546 INFO : test_misclass             0.18750\n",
      "2017-10-18 14:40:31,547 INFO : runtime                   2.14039\n",
      "2017-10-18 14:40:31,548 INFO : \n",
      "2017-10-18 14:40:31,550 INFO : New best valid_misclass: 0.150838\n",
      "2017-10-18 14:40:31,551 INFO : \n",
      "2017-10-18 14:40:32,703 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:33,676 INFO : Epoch 11\n",
      "2017-10-18 14:40:33,677 INFO : train_loss                0.50087\n",
      "2017-10-18 14:40:33,679 INFO : valid_loss                0.55365\n",
      "2017-10-18 14:40:33,680 INFO : test_loss                 0.62265\n",
      "2017-10-18 14:40:33,682 INFO : train_sample_misclass     0.19965\n",
      "2017-10-18 14:40:33,683 INFO : valid_sample_misclass     0.25457\n",
      "2017-10-18 14:40:33,685 INFO : test_sample_misclass      0.31138\n",
      "2017-10-18 14:40:33,686 INFO : train_misclass            0.12813\n",
      "2017-10-18 14:40:33,688 INFO : valid_misclass            0.16201\n",
      "2017-10-18 14:40:33,689 INFO : test_misclass             0.18125\n",
      "2017-10-18 14:40:33,691 INFO : runtime                   2.03829\n",
      "2017-10-18 14:40:33,693 INFO : \n",
      "2017-10-18 14:40:34,847 INFO : Time only for training updates: 0.92s\n",
      "2017-10-18 14:40:35,597 INFO : Epoch 12\n",
      "2017-10-18 14:40:35,598 INFO : train_loss                0.49504\n",
      "2017-10-18 14:40:35,599 INFO : valid_loss                0.53939\n",
      "2017-10-18 14:40:35,600 INFO : test_loss                 0.63364\n",
      "2017-10-18 14:40:35,601 INFO : train_sample_misclass     0.20725\n",
      "2017-10-18 14:40:35,602 INFO : valid_sample_misclass     0.23704\n",
      "2017-10-18 14:40:35,603 INFO : test_sample_misclass      0.30615\n",
      "2017-10-18 14:40:35,603 INFO : train_misclass            0.12396\n",
      "2017-10-18 14:40:35,604 INFO : valid_misclass            0.15642\n",
      "2017-10-18 14:40:35,605 INFO : test_misclass             0.21875\n",
      "2017-10-18 14:40:35,606 INFO : runtime                   2.14446\n",
      "2017-10-18 14:40:35,607 INFO : \n",
      "2017-10-18 14:40:36,738 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:37,547 INFO : Epoch 13\n",
      "2017-10-18 14:40:37,549 INFO : train_loss                0.54827\n",
      "2017-10-18 14:40:37,550 INFO : valid_loss                0.58870\n",
      "2017-10-18 14:40:37,551 INFO : test_loss                 0.77067\n",
      "2017-10-18 14:40:37,552 INFO : train_sample_misclass     0.22621\n",
      "2017-10-18 14:40:37,553 INFO : valid_sample_misclass     0.26329\n",
      "2017-10-18 14:40:37,554 INFO : test_sample_misclass      0.36799\n",
      "2017-10-18 14:40:37,555 INFO : train_misclass            0.16574\n",
      "2017-10-18 14:40:37,555 INFO : valid_misclass            0.16760\n",
      "2017-10-18 14:40:37,556 INFO : test_misclass             0.26250\n",
      "2017-10-18 14:40:37,557 INFO : runtime                   1.88977\n",
      "2017-10-18 14:40:37,558 INFO : \n",
      "2017-10-18 14:40:38,745 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:39,481 INFO : Epoch 14\n",
      "2017-10-18 14:40:39,482 INFO : train_loss                0.47308\n",
      "2017-10-18 14:40:39,483 INFO : valid_loss                0.49712\n",
      "2017-10-18 14:40:39,484 INFO : test_loss                 0.59435\n",
      "2017-10-18 14:40:39,484 INFO : train_sample_misclass     0.18130\n",
      "2017-10-18 14:40:39,485 INFO : valid_sample_misclass     0.22477\n",
      "2017-10-18 14:40:39,486 INFO : test_sample_misclass      0.28175\n",
      "2017-10-18 14:40:39,487 INFO : train_misclass            0.11560\n",
      "2017-10-18 14:40:39,488 INFO : valid_misclass            0.12849\n",
      "2017-10-18 14:40:39,488 INFO : test_misclass             0.20625\n",
      "2017-10-18 14:40:39,489 INFO : runtime                   2.00779\n",
      "2017-10-18 14:40:39,490 INFO : \n",
      "2017-10-18 14:40:39,492 INFO : New best valid_misclass: 0.128492\n",
      "2017-10-18 14:40:39,493 INFO : \n",
      "2017-10-18 14:40:40,631 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:41,476 INFO : Epoch 15\n",
      "2017-10-18 14:40:41,478 INFO : train_loss                0.58251\n",
      "2017-10-18 14:40:41,479 INFO : valid_loss                0.52298\n",
      "2017-10-18 14:40:41,479 INFO : test_loss                 0.63706\n",
      "2017-10-18 14:40:41,480 INFO : train_sample_misclass     0.20874\n",
      "2017-10-18 14:40:41,481 INFO : valid_sample_misclass     0.23188\n",
      "2017-10-18 14:40:41,482 INFO : test_sample_misclass      0.30828\n",
      "2017-10-18 14:40:41,483 INFO : train_misclass            0.15181\n",
      "2017-10-18 14:40:41,484 INFO : valid_misclass            0.13966\n",
      "2017-10-18 14:40:41,485 INFO : test_misclass             0.23750\n",
      "2017-10-18 14:40:41,485 INFO : runtime                   1.88534\n",
      "2017-10-18 14:40:41,486 INFO : \n",
      "2017-10-18 14:40:42,621 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:43,360 INFO : Epoch 16\n",
      "2017-10-18 14:40:43,361 INFO : train_loss                0.51947\n",
      "2017-10-18 14:40:43,362 INFO : valid_loss                0.52912\n",
      "2017-10-18 14:40:43,363 INFO : test_loss                 0.65570\n",
      "2017-10-18 14:40:43,364 INFO : train_sample_misclass     0.21667\n",
      "2017-10-18 14:40:43,364 INFO : valid_sample_misclass     0.22596\n",
      "2017-10-18 14:40:43,365 INFO : test_sample_misclass      0.32556\n",
      "2017-10-18 14:40:43,366 INFO : train_misclass            0.17549\n",
      "2017-10-18 14:40:43,367 INFO : valid_misclass            0.16201\n",
      "2017-10-18 14:40:43,367 INFO : test_misclass             0.26250\n",
      "2017-10-18 14:40:43,368 INFO : runtime                   1.99022\n",
      "2017-10-18 14:40:43,369 INFO : \n",
      "2017-10-18 14:40:44,505 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:45,266 INFO : Epoch 17\n",
      "2017-10-18 14:40:45,267 INFO : train_loss                0.61627\n",
      "2017-10-18 14:40:45,269 INFO : valid_loss                0.72442\n",
      "2017-10-18 14:40:45,270 INFO : test_loss                 0.79277\n",
      "2017-10-18 14:40:45,271 INFO : train_sample_misclass     0.25805\n",
      "2017-10-18 14:40:45,273 INFO : valid_sample_misclass     0.31176\n",
      "2017-10-18 14:40:45,274 INFO : test_sample_misclass      0.37623\n",
      "2017-10-18 14:40:45,275 INFO : train_misclass            0.23677\n",
      "2017-10-18 14:40:45,276 INFO : valid_misclass            0.30726\n",
      "2017-10-18 14:40:45,277 INFO : test_misclass             0.36875\n",
      "2017-10-18 14:40:45,278 INFO : runtime                   1.88364\n",
      "2017-10-18 14:40:45,279 INFO : \n",
      "2017-10-18 14:40:46,463 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:47,312 INFO : Epoch 18\n",
      "2017-10-18 14:40:47,314 INFO : train_loss                0.44648\n",
      "2017-10-18 14:40:47,315 INFO : valid_loss                0.51410\n",
      "2017-10-18 14:40:47,316 INFO : test_loss                 0.63797\n",
      "2017-10-18 14:40:47,316 INFO : train_sample_misclass     0.18323\n",
      "2017-10-18 14:40:47,317 INFO : valid_sample_misclass     0.23506\n",
      "2017-10-18 14:40:47,318 INFO : test_sample_misclass      0.32704\n",
      "2017-10-18 14:40:47,319 INFO : train_misclass            0.11560\n",
      "2017-10-18 14:40:47,319 INFO : valid_misclass            0.15642\n",
      "2017-10-18 14:40:47,320 INFO : test_misclass             0.21875\n",
      "2017-10-18 14:40:47,321 INFO : runtime                   1.95898\n",
      "2017-10-18 14:40:47,322 INFO : \n",
      "2017-10-18 14:40:48,542 INFO : Time only for training updates: 0.93s\n",
      "2017-10-18 14:40:49,364 INFO : Epoch 19\n",
      "2017-10-18 14:40:49,366 INFO : train_loss                0.48791\n",
      "2017-10-18 14:40:49,366 INFO : valid_loss                0.54664\n",
      "2017-10-18 14:40:49,367 INFO : test_loss                 0.66950\n",
      "2017-10-18 14:40:49,368 INFO : train_sample_misclass     0.19900\n",
      "2017-10-18 14:40:49,369 INFO : valid_sample_misclass     0.24619\n",
      "2017-10-18 14:40:49,370 INFO : test_sample_misclass      0.32750\n",
      "2017-10-18 14:40:49,371 INFO : train_misclass            0.11560\n",
      "2017-10-18 14:40:49,372 INFO : valid_misclass            0.14525\n",
      "2017-10-18 14:40:49,372 INFO : test_misclass             0.21875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-18 14:40:49,373 INFO : runtime                   2.07842\n",
      "2017-10-18 14:40:49,374 INFO : \n",
      "2017-10-18 14:40:50,524 INFO : Time only for training updates: 0.94s\n",
      "2017-10-18 14:40:51,298 INFO : Epoch 20\n",
      "2017-10-18 14:40:51,300 INFO : train_loss                0.46299\n",
      "2017-10-18 14:40:51,300 INFO : valid_loss                0.50097\n",
      "2017-10-18 14:40:51,301 INFO : test_loss                 0.58244\n",
      "2017-10-18 14:40:51,302 INFO : train_sample_misclass     0.18410\n",
      "2017-10-18 14:40:51,303 INFO : valid_sample_misclass     0.22857\n",
      "2017-10-18 14:40:51,304 INFO : test_sample_misclass      0.27696\n",
      "2017-10-18 14:40:51,304 INFO : train_misclass            0.12396\n",
      "2017-10-18 14:40:51,305 INFO : valid_misclass            0.12291\n",
      "2017-10-18 14:40:51,306 INFO : test_misclass             0.16875\n",
      "2017-10-18 14:40:51,307 INFO : runtime                   1.98218\n",
      "2017-10-18 14:40:51,308 INFO : \n",
      "2017-10-18 14:40:51,310 INFO : New best valid_misclass: 0.122905\n",
      "2017-10-18 14:40:51,311 INFO : \n",
      "2017-10-18 14:40:51,311 INFO : Setup for second stop...\n",
      "2017-10-18 14:40:51,314 INFO : Train loss to reach 0.46299\n",
      "2017-10-18 14:40:51,315 INFO : Run until second stop...\n",
      "2017-10-18 14:40:52,184 INFO : Epoch 21\n",
      "2017-10-18 14:40:52,186 INFO : train_loss                0.47057\n",
      "2017-10-18 14:40:52,186 INFO : valid_loss                0.50097\n",
      "2017-10-18 14:40:52,187 INFO : test_loss                 0.58244\n",
      "2017-10-18 14:40:52,188 INFO : train_sample_misclass     0.19298\n",
      "2017-10-18 14:40:52,189 INFO : valid_sample_misclass     0.22857\n",
      "2017-10-18 14:40:52,190 INFO : test_sample_misclass      0.27696\n",
      "2017-10-18 14:40:52,190 INFO : train_misclass            0.12375\n",
      "2017-10-18 14:40:52,191 INFO : valid_misclass            0.12291\n",
      "2017-10-18 14:40:52,192 INFO : test_misclass             0.16875\n",
      "2017-10-18 14:40:52,193 INFO : runtime                   0.79050\n",
      "2017-10-18 14:40:52,194 INFO : \n",
      "2017-10-18 14:40:53,673 INFO : Time only for training updates: 1.16s\n",
      "2017-10-18 14:40:54,609 INFO : Epoch 22\n",
      "2017-10-18 14:40:54,610 INFO : train_loss                0.50080\n",
      "2017-10-18 14:40:54,611 INFO : valid_loss                0.51211\n",
      "2017-10-18 14:40:54,611 INFO : test_loss                 0.61159\n",
      "2017-10-18 14:40:54,612 INFO : train_sample_misclass     0.21165\n",
      "2017-10-18 14:40:54,613 INFO : valid_sample_misclass     0.22513\n",
      "2017-10-18 14:40:54,614 INFO : test_sample_misclass      0.29023\n",
      "2017-10-18 14:40:54,615 INFO : train_misclass            0.14381\n",
      "2017-10-18 14:40:54,615 INFO : valid_misclass            0.16201\n",
      "2017-10-18 14:40:54,616 INFO : test_misclass             0.20000\n",
      "2017-10-18 14:40:54,617 INFO : runtime                   2.35849\n",
      "2017-10-18 14:40:54,618 INFO : \n",
      "2017-10-18 14:40:56,030 INFO : Time only for training updates: 1.16s\n",
      "2017-10-18 14:40:56,891 INFO : Epoch 23\n",
      "2017-10-18 14:40:56,892 INFO : train_loss                0.45834\n",
      "2017-10-18 14:40:56,893 INFO : valid_loss                0.46922\n",
      "2017-10-18 14:40:56,894 INFO : test_loss                 0.60646\n",
      "2017-10-18 14:40:56,895 INFO : train_sample_misclass     0.19857\n",
      "2017-10-18 14:40:56,896 INFO : valid_sample_misclass     0.21943\n",
      "2017-10-18 14:40:56,896 INFO : test_sample_misclass      0.29484\n",
      "2017-10-18 14:40:56,897 INFO : train_misclass            0.12040\n",
      "2017-10-18 14:40:56,898 INFO : valid_misclass            0.14525\n",
      "2017-10-18 14:40:56,899 INFO : test_misclass             0.20625\n",
      "2017-10-18 14:40:56,900 INFO : runtime                   2.35727\n",
      "2017-10-18 14:40:56,900 INFO : \n",
      "2017-10-18 14:40:58,307 INFO : Time only for training updates: 1.16s\n",
      "2017-10-18 14:40:59,276 INFO : Epoch 24\n",
      "2017-10-18 14:40:59,278 INFO : train_loss                0.53020\n",
      "2017-10-18 14:40:59,279 INFO : valid_loss                0.50777\n",
      "2017-10-18 14:40:59,279 INFO : test_loss                 0.70897\n",
      "2017-10-18 14:40:59,280 INFO : train_sample_misclass     0.22222\n",
      "2017-10-18 14:40:59,281 INFO : valid_sample_misclass     0.21075\n",
      "2017-10-18 14:40:59,282 INFO : test_sample_misclass      0.34517\n",
      "2017-10-18 14:40:59,283 INFO : train_misclass            0.16276\n",
      "2017-10-18 14:40:59,283 INFO : valid_misclass            0.14525\n",
      "2017-10-18 14:40:59,284 INFO : test_misclass             0.25000\n",
      "2017-10-18 14:40:59,285 INFO : runtime                   2.27696\n",
      "2017-10-18 14:40:59,286 INFO : \n",
      "2017-10-18 14:41:00,697 INFO : Time only for training updates: 1.15s\n",
      "2017-10-18 14:41:01,554 INFO : Epoch 25\n",
      "2017-10-18 14:41:01,556 INFO : train_loss                0.43575\n",
      "2017-10-18 14:41:01,557 INFO : valid_loss                0.41160\n",
      "2017-10-18 14:41:01,558 INFO : test_loss                 0.55808\n",
      "2017-10-18 14:41:01,559 INFO : train_sample_misclass     0.17470\n",
      "2017-10-18 14:41:01,560 INFO : valid_sample_misclass     0.18220\n",
      "2017-10-18 14:41:01,560 INFO : test_sample_misclass      0.25350\n",
      "2017-10-18 14:41:01,561 INFO : train_misclass            0.10591\n",
      "2017-10-18 14:41:01,562 INFO : valid_misclass            0.12291\n",
      "2017-10-18 14:41:01,563 INFO : test_misclass             0.13750\n",
      "2017-10-18 14:41:01,564 INFO : runtime                   2.38963\n",
      "2017-10-18 14:41:01,564 INFO : \n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arrive at ca. 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do trialwise decoding instead of cropped decoding, perform the following changes:\n",
    "\n",
    "\n",
    "Change:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 800\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=30).create_network()\n",
    "```\n",
    "\n",
    "to:\n",
    "```python\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = train_set.X.shape[2]\n",
    "in_chans = 3\n",
    "n_classes = 4\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length='auto').create_network()\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "```python\n",
    "to_dense_prediction_model(model)\n",
    "```\n",
    "\n",
    "Remove:\n",
    "\n",
    "\n",
    "```python\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, 3, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
    "iterator = BalancedBatchSizeIterator(batch_size=32)\n",
    "```\n",
    "\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "loss_function = F.nll_loss\n",
    "```\n",
    "\n",
    "Change:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='misclass'), \n",
    "            RuntimeMonitor(),]\n",
    "```\n",
    "\n",
    "Resulting code can be seen at [BBCI Data Epoched](BBCI_Data_Epoched.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
